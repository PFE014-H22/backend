Id,AcceptedAnswerId,CreationDate,Title,Body,Tags,AnswerBody,Params
3138738,3139627,2010-06-29 07:39:11,is there any trick to do wildcards search on apache cassandra?,"<p>i need to do something like this on apache cassandra,
SELECT * FROM mytable where address = ""%indonesia%""</p>

<p>any idea how to do it on cassandra?</p>
",<database><nosql><cassandra>,"<p>Its not supported out of the box. You must maintain your own indices. </p>

<p>I would recommend to use ""Supercolumn index"" or use a order preserving partitioner (e.g. org.apache.cassandra.dht.OrderPreservingPartioner) in conjunction with range queries. </p>

<p>Take a look at <a href=""http://www.slideshare.net/benjaminblack/cassandra-basics-indexing"" rel=""nofollow noreferrer"">the slides</a> from Benjamin Black's excellent talk about cassandra and index</p>
",['partitioner']
5100782,5102518,2011-02-24 05:35:31,cassandra upgrade from 0.6 to 0.7.2,"<p>I followed the instructions in NEWS.txt to upgrade cassandra 0.6 to 0.7.2. 
The instructions are: 
    The process to upgrade is: 
    1) run ""nodetool drain"" on <em>each</em> 0.6 node.  When drain finishes (log 
       message ""Node is drained"" appears), stop the process. 
    2) Convert your storage-conf.xml to the new cassandra.yaml using 
       ""bin/config-converter"". 
    3) Rename any of your keyspace or column family names that do not adhere 
       to the '^\w+' regex convention. 
    4) Start up your cluster with the 0.7 version. 
    5) Initialize your Keyspace and ColumnFamily definitions using 
       ""bin/schematool   import"".  <em>You only need to do 
       this to one node</em>. </p>

<p>I did the first three steps. drain node, stop cassandra 0.6, convert old storage-conf.xml to cassandra.yaml. 
I start cassandra 0.7.2 using: ""bin/cassandra -f"". But it always complains the following errors. I am wondering whether I followed the right instructions. If so, how could i fix this problem?</p>

<p>""Fatal configuration error 
org.apache.cassandra.config.ConfigurationException: saved_caches_directory missing"" </p>
",<upgrade><cassandra>,"<p>Default location for saved_caches_directory is /var/lib/cassandra/saved_caches (From <a href=""http://wiki.apache.org/cassandra/StorageConfiguration"" rel=""nofollow"">wiki</a>). Try to create that manually (dont forget user permissions)</p>
",['saved_caches_directory']
5534713,5539325,2011-04-04 04:57:55,Cassandra startup problem: Attempt to assign id to existing column family,"<p>I'm using <strong>cassandra 0.7.4</strong> on centos5.5 x86_64 with jdk-1.6.0_24 64-Bit.
 When I restart it , it throw out:</p>

<hr>

<pre><code>ERROR 11:37:32,009 Exception encountered during startup.
java.io.IOError: org.apache.cassandra.config.ConfigurationException: Attempt to assign id to existing column family.
    at org.apache.cassandra.config.DatabaseDescriptor.loadSchemas(DatabaseDescriptor.java:476)
    at org.apache.cassandra.service.AbstractCassandraDaemon.setup(AbstractCassandraDaemon.java:138)
    at org.apache.cassandra.service.AbstractCassandraDaemon.activate(AbstractCassandraDaemon.java:314)
    at org.apache.cassandra.thrift.CassandraDaemon.main(CassandraDaemon.java:79)
Caused by: org.apache.cassandra.config.ConfigurationException: Attempt to assign id to existing column family.
    at org.apache.cassandra.config.CFMetaData.map(CFMetaData.java:223)
    at org.apache.cassandra.config.DatabaseDescriptor.loadSchemas(DatabaseDescriptor.java:472)
    ... 3 more    
</code></pre>

<hr>

<p>I try to location the problem: when I delete the file of the system keyspace ,It can restart <strong>sucess</strong>!
 So I think this problem is cause by system Keyspace,even at the CF <strong>Scheam</strong>.</p>

<p>Then I build a new test environment, I know this proble is cause by this opeartion</p>

<pre><code>update keyspace system with replication_factor=3;
</code></pre>

<p>But now how can i repair it ?!
  There are many data on this cluster,and I <strong><em>couldn't</em></strong> lose data.</p>

<p>I have already do <code>update keyspace system with replication_factor=1;</code> ,but the problem <em>still exist</em>.
 I try to use nodetool to repair after or befor flush, all no effect.</p>

<p>How can I restart cassandra <strong>without lose data</strong> ? Who can help me?</p>
",<cassandra><startup>,"<p>You should never modify the system keyspace unless you really, really know what you are doing. (If you have to ask, you don't. :)</p>

<p>So, the answer is: don't do that.</p>

<p>To recover, you should set initial_token in cassandra.yaml to your node's current token (which you can see with ""nodetool ring""), then delete the system keyspace and restart. Then you'll need to recreate your columnfamily definitions, but your data will not be affected.</p>
",['initial_token']
6292734,6307553,2011-06-09 12:25:02,Fetching key range with common prefix in Cassandra,"<p>I want to fetch all rows having a common prefix using hector API. I played with RangeSuperSlicesQuery a bit but didn't find a way to get it working properly. Does key range parameters work with wild cards etc? </p>

<p>Update: I used ByteOrderedPartitioner instead of RandomPartitioner and it works fine with that. Is this the expected behavior?</p>
",<cassandra><hector>,"<p>Yes, that's the expected behavior. In RandomPartitioner, rows are stored in the order of the MD5 hash of their keys, so to get a meaningful range of keys, you need to use an order preserving partitioner like ByteOrderedPartitioner.</p>

<p>However, there are downsides to using <a href=""http://ria101.wordpress.com/2010/02/22/cassandra-randompartitioner-vs-orderpreservingpartitioner/"" rel=""noreferrer"">ByteOrderedPartitioner or OrderPreservingPartitioner</a> that you can usually avoid with a slightly different data model and RandomPartitioner.  </p>
",['partitioner']
6433842,6436258,2011-06-22 01:14:33,"Cassandra 0.8 = What kind of ""Row Count"" features are provided?","<p>are ""Row Counts"" (in a CF) in Cassandra meanwhile supported for </p>

<p>a) RAndomPartitioner ?</p>

<p>b) OrderPreservingPartitioner?</p>

<p><a href=""http://www.datastax.com/dev/blog/whats-new-in-cassandra-0-8-part-2-counters"" rel=""nofollow noreferrer"">http://www.datastax.com/dev/blog/whats-new-in-cassandra-0-8-part-2-counters</a> implies this is easily possible? Quote: "" “counting,” we mean here to provide an atomic increment operation in a single column value, as opposed to counting the number of columns in a row, or rows in a column family, both of which were already supported.""</p>

<p>Two years ago it was defenitely not supported for RP:
<a href=""https://stackoverflow.com/questions/1951843/row-count-of-a-column-family-in-cassandra"">Row count of a column family in Cassandra</a></p>

<p>Furthermoe even with OrderPreservingPartitioner, it was(??) a very heavy Operation (as far as I understood i have to retrieve all objects, this is/was not only a lightweight count operation to the row-count, but rather read also all data (rows?) ?)</p>

<p>Update: I am absolutely aware of, that the new counting feature is completely different to row-counts. But the text above implies row-counts are also easily possible and supported quote ""...both of which are supported...""? Is this marketing language meaning it is only possible as an extremely heaving operation using get_range_slice? Or is there something new that I am completly missing, that does this lightweight for both partitioniers? </p>

<p>Thanks</p>

<p>Markus</p>
",<cassandra>,"<p>Counters and counting the number of rows / columns are two different topics.  </p>

<p><a href=""http://cassandra-user-incubator-apache-org.3065146.n2.nabble.com/Count-rows-td5420889.html"" rel=""nofollow"">http://cassandra-user-incubator-apache-org.3065146.n2.nabble.com/Count-rows-td5420889.html</a></p>

<p>I would suggest, as you add new rows to a column family, simply increment +1 a counter CF/row/key and you wont have to page through all of the rows (as the link above says, what if you have billions?) -- This also allows you to not care which partitioner you use ... </p>
",['partitioner']
6909826,6910417,2011-08-02 09:22:05,Sort by key in Cassandra,"<p>Let's assume I have a keyspace with a column family that stores user objects and the key of these objects is the username.</p>

<p>How can I use Hector to get a list of users sorted by username?</p>

<p>I tried to use a RangeSlicesQuery, paging works fine with this query, but the results are not sorted in any way.</p>

<p>I'm an absolute Cassandra beginner, can anyone point me to a simple example that shows how to sort a column family by key? Please ask if you need more details on my efforts.</p>

<p>Edit:</p>

<p>The result was not sorted because I used the default RandomPartitioner instead of the OrderPreseveringPartitioner in cassandra.yaml.</p>

<p>Probably it's better not to rely on the sorting by key but to use a secondary index.</p>
",<sorting><cassandra><hector>,"<p>Quoting <a href=""https://rads.stackoverflow.com/amzn/click/com/1449390412"" rel=""nofollow noreferrer"" rel=""nofollow noreferrer"">Cassandra - The Definitive Guide</a></p>

<blockquote>
  <p>Column names are stored in sorted order according to the value of compare_with. Rows,
  on the other hand, are stored in an order defined by the partitioner (for example,
  with RandomPartitioner, they are in random order, etc.)</p>
</blockquote>

<p>I guess you are using <code>RandomPartitioner</code> which </p>

<blockquote>
  <p>... return data in an essentially random order. </p>
</blockquote>

<p>You should probably use <code>OrderPreservingPartitioner (OPP)</code> where</p>

<blockquote>
  <p>Rows are therefore stored
  by  key  order,  aligning  the  physical  structure  of  the  data  with  your  sort  order.</p>
</blockquote>

<p>Be aware of inefficiency of OPP.</p>

<hr>

<p>(edit on Mar 07, 2014)<br>
<strong>Important:</strong></p>

<p>This answer is very old now.</p>

<p>It is a system-wide setting. You can set in <code>cassandra.yaml</code>. See <a href=""http://www.datastax.com/docs/1.1/configuration/node_configuration#partitioner"" rel=""nofollow noreferrer"">this doc</a>. Again, OPP is highly discouraged. This document is for version 1.1, and you can see <em>it is deprecated</em>. It is likely that it is removed from latest version. If you do want to use OPP, you may want to revisit the architecture the architecture.</p>
",['partitioner']
7237271,7251868,2011-08-29 23:46:12,Large scale data processing Hbase vs Cassandra,"<p>I am nearly landed at Cassandra after my research on large scale data storage solutions. But its generally said that Hbase is better solution for large scale data processing and analysis. </p>

<p>While both are same key/value storage and both are/can run (Cassandra recently) Hadoop layer then what makes Hadoop a better candidate when processing/analysis is required on large data.</p>

<p>I also found good details about both at
<a href=""http://ria101.wordpress.com/2010/02/24/hbase-vs-cassandra-why-we-moved/"">http://ria101.wordpress.com/2010/02/24/hbase-vs-cassandra-why-we-moved/</a> </p>

<p>but I'm still looking for concrete advantages of Hbase.</p>

<p>While I am more convinced about Cassandra because its simplicity for adding nodes and seamless replication and no point of failure features. And it also keeps secondary index feature so its a good plus.</p>
",<nosql><hadoop><cassandra><hbase><data-processing>,"<p>Trying to determine which is best for you really depends on what you are going to use it for, they each have their advantages and without any more details it becomes more of a religious war. That post you referenced is also more than a year old and both have gone through many changes since then. Please also keep in mind I am not familiar with the more recent Cassandra developments.</p>

<p>Having said that, I'll paraphrase HBase committer Andrew Purtell and add some of my own experiences:</p>

<ul>
<li><p>HBase is in larger production environments (1000 nodes) although that is still in the ballpark of Cassandra's ~400 node installs so its really a marginal difference.</p></li>
<li><p>HBase and Cassandra both supports replication between clusters/datacenters. I believe HBase's exposes more to the user so it appears more complicated but then you also get more flexibility.</p></li>
<li><p>If strong consistency is what your application needs then HBase is likely a better fit. It is designed from the ground up to be consistent. For example it allows for simpler implementation of atomic counters (I think Cassandra just got them) as well as Check and Put operations.</p></li>
<li><p>Write performance is great, from what I understand that was one of the reasons Facebook went with HBase for their messenger.</p></li>
<li><p>I'm not sure of the current state of Cassandra's ordered partitioner, but in the past it required manual rebalancing. HBase handles that for you if you want. The ordered partitioner is important for Hadoop style processing.</p></li>
<li><p>Cassandra and HBase are both complex, Cassandra just hides it better. HBase exposes it more via using HDFS for its storage, if you look at the codebase Cassandra is just as layered. If you compare the Dynamo and Bigtable papers you can see that Cassandra's theory of operation is actually more complex.</p></li>
<li><p>HBase has more unit tests FWIW.</p></li>
<li><p>All Cassandra RPC is Thrift, HBase has a Thrift, REST and native Java. The Thrift and REST do only offer a subset of the total client API but if you want pure speed the native Java client is there.</p></li>
<li><p>There are advantages to both peer to peer and master to slave. The master - slave setup generally makes it easier to debug and reduces quite a bit of complexity.</p></li>
<li><p>HBase is not tied to only traditional HDFS, you can change out your underlying storage depending on your needs. <a href=""http://www.mapr.com/"" rel=""noreferrer"">MapR</a> looks quite interesting and I have heard good things although I have not used it myself.</p></li>
</ul>
",['partitioner']
7578609,7587875,2011-09-28 05:11:18,"cassandra secondary index return results in lexical rowkey order, even with RandomPartitioner?","<p>As far as I understand, a Cassandra secondary index is stored as an internal CF, where the rowkeys are the values within the index, and the columns are rowkeys back to the original CF being indexed.</p>

<p>Is it possible to have the columns of the index store the original CF rowkey values? Then, since columns within the index row are sorted, a query for a particular value in the index theoretically could return rowkeys in sorted value order.</p>

<p>This is how I would do it if I was to manually maintain my own index CF (I'd have my manual index CF sort its columns as strings), I'm curious if the same can be done with built-in secondary indexes.</p>

<hr>

<p>A hopefully clarifying example... I have 5 rows with 2 columns each (<code>identifier</code> is to easily distinguish the rows, <code>birth_date</code> is being indexed), each row with a UTF8 key (in this case a single char string):</p>

<pre><code>[default@demo] create column family users with comparator=UTF8Type
...     and column_metadata=
...     [{column_name: identifier, validation_class: LongType}
...     ,{column_name: birth_date, validation_class: LongType, index_type: KEYS}];
86518c00-e9f7-11e0-0000-242d50cf1fde
Waiting for schema agreement...
... schemas agree across the cluster
[default@demo] set users['a']['identifier'] = 1;
Value inserted.
[default@demo] set users['a']['birth_date'] = 1975;
Value inserted.
[default@demo] set users['c']['identifier'] = 3;
Value inserted.
[default@demo] set users['c']['birth_date'] = 1975;
Value inserted.
[default@demo] set users['b']['identifier'] = 2;
Value inserted.
[default@demo] set users['b']['birth_date'] = 1975;
Value inserted.
[default@demo] set users['x']['identifier'] = 5;
Value inserted.
[default@demo] set users['x']['birth_date'] = 1975;
Value inserted.
[default@demo] set users['f']['identifier'] = 4;
Value inserted.
[default@demo] set users['f']['birth_date'] = 1975;
Value inserted.
</code></pre>

<p>Now when I make an index query, I get the users rows back in what appears to be reverse order of their rowkeys' md5 hashes (looking at the <code>identifier</code>, the result order is x,b,f,c,a):</p>

<pre><code>[default@demo] get users where birth_date = 1975;
-------------------
RowKey: ff
=&gt; (column=birth_date, value=1975, timestamp=1317231030507000)
=&gt; (column=identifier, value=5, timestamp=1317231030504000)
-------------------
RowKey: 0b
=&gt; (column=birth_date, value=1975, timestamp=1317231030502000)
=&gt; (column=identifier, value=2, timestamp=1317231030500000)
-------------------
RowKey: 0f
=&gt; (column=birth_date, value=1975, timestamp=1317231031992000)
=&gt; (column=identifier, value=4, timestamp=1317231030509000)
-------------------
RowKey: 0c
=&gt; (column=birth_date, value=1975, timestamp=1317231030498000)
=&gt; (column=identifier, value=3, timestamp=1317231030494000)
-------------------
RowKey: 0a
=&gt; (column=birth_date, value=1975, timestamp=1317231030491000)
=&gt; (column=identifier, value=1, timestamp=1317231030476000)

5 Rows Returned.
</code></pre>

<p>My question is, is there a way to have the internal index CF use 'a', 'b', 'c', 'f', 'x' as its column names, so that when I make an index query, I get back the users rows in lexical rowkey order.</p>
",<cassandra>,"<p>The reason you can't do this is, the index ordering has to match the partitioner ordering, or you couldn't ""page"" through resultsets across multiple nodes (without having to do scatter/gather for each query, anyway).</p>

<p>We do have <a href=""https://issues.apache.org/jira/browse/CASSANDRA-1599"" rel=""nofollow"">https://issues.apache.org/jira/browse/CASSANDRA-1599</a> open to allow custom ordering, so you should watch that issue for updates.</p>
",['partitioner']
8793430,8834951,2012-01-09 18:41:04,"For Cassandra, how should the historical data be taken care of?","<p>Say I have a dozen CF/SCF and have the write traffic keeps coming (might have spikes). Over the time, a few of them will growing much faster (due to their own nature) than others and data table could be huge. At that stage, should they still be sitting on the same disk as the other CF/SCF? what if the disk is almost full due to the large amount of store data? or should we consider introducing additional CF/SCF for storing historical data?</p>

<p>In general, what's the best practices that we need follow to take care of the historical data? </p>
",<cassandra><database-backups><historical-db>,"<p>The size of the CF isn't really the issue, as the keys are replicated and spread based on the # of nodes, the token selection per node, the partitioner selected and the replication strategy -- all configurable for a keyspace.  </p>
",['partitioner']
10407072,10407149,2012-05-02 02:49:50,Cassandra seed nodes and clients connecting to nodes,"<p>I'm a little confused about Cassandra seed nodes and how clients are meant to connect to the cluster. I can't seem to find this bit of information in the documentation.</p>

<p>Do the clients only contain a list of the seed node and each node delegates a new host for the client to connect to? Are seed nodes only really for node to node discovery, rather than a special node for clients?</p>

<p>Should each client use a small sample of random nodes in the DC to connect to?</p>

<p>Or, should each client use all the nodes in the DC?</p>
",<cassandra>,"<p>Answering my own question:</p>

<p><strong>Seeds</strong></p>

<p>From the <a href=""http://cassandra.apache.org/doc/latest/faq/index.html#what-are-seeds"" rel=""noreferrer"">FAQ</a>:</p>

<blockquote>
  <p>Seeds are used during startup to discover the cluster.</p>
</blockquote>

<p>Also from the <a href=""http://www.datastax.com/docs/1.0/cluster_architecture/gossip"" rel=""noreferrer"">DataStax documentation</a> on ""Gossip"":</p>

<blockquote>
  <p>The seed node designation has no purpose other than bootstrapping the gossip process
  for new nodes joining the cluster. Seed nodes are not a single
  point of failure, nor do they have any other special purpose in
  cluster operations beyond the bootstrapping of nodes.</p>
</blockquote>

<p>From these details it seems that a seed is nothing special to clients.</p>

<p><strong>Clients</strong></p>

<p>From the <a href=""http://www.datastax.com/docs/1.0/cluster_architecture/about_client_requests"" rel=""noreferrer"">DataStax documentation</a> on client requests:</p>

<blockquote>
  <p>All nodes in Cassandra are peers. A client read or write request can
  go to any node in the cluster. When a client connects to a node and
  issues a read or write request, that node serves as the coordinator
  for that particular client operation.</p>
  
  <p>The job of the coordinator is to act as a proxy between the client
  application and the nodes (or replicas) that own the data being
  requested. The coordinator determines which nodes in the ring should
  get the request based on the cluster configured partitioner and
  replica placement strategy.</p>
</blockquote>

<p>I gather that the pool of nodes that a client connects to can just be a handful of (random?) nodes in the DC to allow for potential failures.</p>
",['partitioner']
11014014,11019631,2012-06-13 11:34:47,get column position,"<p>In CassandraDB, using an ordered column family. I know you can get slices, but can you get the position. For example, in this datamodel I save scores like this:</p>

<pre><code>""Scores"":
{
   ""1000"": ""bob, lucas"",
   ""900"": ""tim""
   ""800"": ""mario""
}
</code></pre>

<p>Is it possible, knowing that the user has a score of ""900"" and his nick is ""tim"", to know that he is at position 2 of the ordered column family?</p>
",<nosql><cassandra>,"<p>Cassandra does not provide this functionality out of the box, but you could implement this yourself using three separate CFs.  Consider this scenario:</p>

<pre><code>""Scores"":
{
   ""1000"": ""bob, lucas""
   ""900"": ""tim""
   ""800"": ""mario""
}

""PlayerScores"":
{
   ""bob"": ""1000""
   ""lucas"": ""1000""
   ""tim"": ""900""
   ""mario"": ""800""
}

""ScoreTotals"":
{
   ""1000"": 
   {
      ""1000"":2
   }
   ""900"": 
   {
      ""900"":1
   }
   ""800"": 
   {
      ""800"":1
   }
}
</code></pre>

<p>The ScoreTotals CF would be used with counter columns to increment/decrement the value each time a user achieves that score.  If you have additional granularity in your scores (like 910 vs an even 900) you can consider the keys as buckets with column names as specific scores. PlayerScores obviously exists so you can query a score for a player.</p>

<p>You can then determine ranking by simply summing the totals of all scores greater than that of the player.  Since scores are stored in column names, you can use a standard slice query to get your range without needing to use an order-preserving partitioner (which has some negative side effects).</p>
",['partitioner']
11659001,11659796,2012-07-25 21:35:50,Cassandra-cli cant connect to remote cassandra server,"<p>I have a cassandra server running on a server(serv1). cassandra-cli can connect to it when run on serv1. However, when i try to connect to it through some other server(serv2), i get the following exception:</p>

<pre><code>org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection refused
    at org.apache.thrift.transport.TSocket.open(TSocket.java:183)
    at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
    at org.apache.cassandra.cli.CliMain.connect(CliMain.java:80)
    at org.apache.cassandra.cli.CliMain.main(CliMain.java:256)
Caused by: java.net.ConnectException: Connection refused
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:351)
    at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:213)
    at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:200)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
    at java.net.Socket.connect(Socket.java:529)
    at org.apache.thrift.transport.TSocket.open(TSocket.java:178)
    ... 3 more
Exception connecting to jckstore/9160. Reason: Connection refused.
</code></pre>

<p>I looked in cassandra.yaml and found that the property ""listen_address"" is configured to ""localhost"" and using 0.0.0.0 is severely discouraged. I tried to change localhost to serv2, ip address of serv1 but nothing worked. Even commenting out didnt help. </p>

<p>Is there a way i can make my cassandra server listen on all the ip's without using 0.0.0.0</p>
",<java><nosql><cassandra><thrift><thrift-protocol>,"<p>I was able to solve the problem as following:</p>

<ol>
<li>changing the rpc_address property in cassandra.yaml to 0.0.0.0 instead of localhost. </li>
<li>set the broadcast_rpc_address property in cassandra.yaml to a value other than 0.0.0.0</li>
</ol>

<p>Then I can access.</p>
","['rpc_address', 'broadcast_rpc_address']"
11707073,11716462,2012-07-29 06:03:24,how to efficiently manage cassandra initial token?,"<p>I'm new cassandra user. I know that there is initial token configuration and how to generate it.
The question is if I have an existen cluster with x nodes and I want to add additional node (one or more) should I reconfigure all the nodes to the new tokens (according to new  generated values)?  </p>

<p>Or is there more efficient way to manage this?</p>
",<cassandra>,"<p>If you're looking for what the best practices are for handling such tasks, take a look at this section of the Cassandra 1.0 docs dedicated to <a href=""http://www.datastax.com/docs/1.0/operations/cluster_management#calculating-tokens-for-the-new-nodes"">token strategy</a>.</p>

<p>Shortened version of your options, from the documentation:</p>

<blockquote>
  <ul>
  <li><strong>Add capacity by doubling the cluster size</strong> -- <em>[..]</em> nodes can keep their existing token assignments, and new nodes are assigned tokens that bisect (or trisect) the existing token ranges.</li>
  <li><strong>Recalculate new tokens for all nodes and move nodes</strong> -- <em>[..]</em> you will have to recalculate tokens for the entire cluster. Existing nodes will have to have their new tokens assigned using nodetool move.</li>
  <li><strong>Add one node at a time and leave initial_token empty</strong> -- <em>[..]</em> splits the token range of the heaviest loaded node and places the new node into the ring at that position. <em>[..]</em> not result in a perfectly balanced ring, but it will alleviate hot spots.
  link</li>
  </ul>
</blockquote>

<p>If you were seeking a management solution <a href=""https://github.com/netflix/priam"">Priam (from Netflix)</a> might be worth looking at. It's open source and Apache-licensed, but requires some amount of configuration and is probably only worth investing [time] in for larger clusters.</p>
",['initial_token']
13110363,13121756,2012-10-28 15:52:30,One to Many equivalent in Cassandra and data model optimization,"<p>I am modeling my database in Cassandra, coming from RDBMS. I want to know how can I create a one-to-many relationship which is embedded in the same Column Name and model my table to fit the following query needs.</p>

<p>For example:</p>

<pre><code>Boxes:{
  23442:{
    belongs_to_user: user1,
    box_title: 'the box title',
    items:{
      1: {
         name: 'itemname1',
         size: 44
      },
      2: {
        name: 'itemname2',
        size: 24
      }
    }
  },

 { ... }
}
</code></pre>

<p>I read that its preferable to use composite columns instead of super columns, so I need an example of the best way to implement this. My queries are like:</p>

<ul>
<li>Get items for box by Id</li>
<li>get top 20 boxes with their items (for displaying a range of boxes with their items on the page)</li>
<li>update items size by item id (increment size by a number)</li>
<li>get all boxes by userid (all boxes that belongs to a specific user)</li>
</ul>

<p>I am expecting lots of writes to change the size of each item in the box. I want to know the best way to implement it without the need to use super columns. Furthermore, I don't mind getting a solution that takes Cassandra 1.2 new features into account, because I will use that in production. </p>

<p>Thanks</p>
",<nosql><cassandra>,"<p>This particular model is somewhat challenging, for a number of reasons.</p>

<p>For example, with the box ID as a row key, querying for a range of boxes will require a range query in Cassandra (as opposed to a column slice), which means the use of an ordered partitioner.  An ordered partitioner is almost always a <em>Bad Idea</em>.</p>

<p>Another challenge comes from the need to increment the item size, as this calls for the use of a counter column family.  Counter column families store counter values <em>only</em>.</p>

<p>Setting aside the need for a range of box IDs for a moment, you could model this using multiple tables in CQL3 as follows:</p>

<pre><code>CREATE TABLE boxes (                                                                       
   id int PRIMARY KEY,                                                                 
   belongs_to_user text,                                                               
   box_title text,                                                                     
);
CREATE INDEX useridx on boxes (belongs_to_user);

CREATE TABLE box_items (                                                                   
   id int,                                                                             
   item int,                                                                           
   size counter,                                                                       
   PRIMARY KEY(id, item)                                                               
);

CREATE TABLE box_item_names (
    id int PRIMARY KEY,
    item int,
    name text
);

BEGIN BATCH
  INSERT INTO boxes (id, belongs_to_user, box_title) VALUES (23442, 'user1', 'the box title');
  INSERT INTO box_items (id, item, name) VALUES (23442, 1, 'itemname1');
  INSERT INTO box_items (id, item, name) VALUES (23442, 1, 'itemname2');
  UPDATE box_items SET size = size + 44 WHERE id = 23442 AND item = 1;                       
  UPDATE box_items SET size = size + 24 WHERE id = 23442 AND item = 2;
APPLY BATCH

-- Get items for box by ID                                                               
SELECT size FROM box_items WHERE id = 23442 AND item = 1;

-- Boxes by user ID
SELECT * FROM boxes WHERE belongs_to_user = 'user1';
</code></pre>

<p>It's important to note that the BATCH mutation above is both atomic, and isolated.</p>

<p>Technically speaking, you could also denormalize all of this into a single table.  For example:</p>

<pre><code>CREATE TABLE boxes (
   id int,
   belongs_to_user text,
   box_title text,
   item int,
   name text,
   size counter,
   PRIMARY KEY(id, item, belongs_to_user, box_title, name)
);

UPDATE boxes set size = item_size + 44 WHERE id = 23442 AND belongs_to_user = 'user1'
    AND box_title = 'the box title' AND name = 'itemname1' AND item = 1;

SELECT item, name, size FROM boxes WHERE id = 23442;
</code></pre>

<p><em>However, this provides no guarantees of correctness</em>.  For example, this model makes it possible for items of the same box to have different users, or titles.  And, since this makes <code>boxes</code> a counter column family, it limits how you can evolve the schema in the future.</p>
",['partitioner']
13219270,13270710,2012-11-04 14:09:40,Dynamically adding new nodes in Cassandra,"<p>Is it possible to add new hosts to a Cassandra cluster dynamically?</p>

<p>What I'm trying to do is set up a program that can:</p>

<ul>
<li>Set up a local version of the database for each user</li>
<li>Each user's machine will become part of the cluster (the machines will be hosts)</li>
<li>Data will be replicated across all the clusters</li>
</ul>

<p>Building a cluster of multiple hosts usually entails <a href=""http://www.datastax.com/docs/0.7/getting_started/configuring"" rel=""noreferrer"">configuring the cassandra.yaml</a> to store the seeds, listen_address and rpc_address of each host.</p>

<p>My idea is to edit these files through java and insert the new host addresses as required but making sure that data is accurate across each users's cassandra.yaml files would be challenging. </p>

<p>I'm wondering if someone has done something similar or has any advice on a better way to achieve this.</p>
",<cassandra>,"<p>Yes is possible. Look at <a href=""https://github.com/Netflix/Priam/wiki"" rel=""nofollow"">Netflix's Priam</a> for an complete example of a dynamic cassandra cluster management (but designed to work with Amazon EC2).</p>

<p>For rpc_address and listen_address, you can setup a startup script that configures the cassandra.yaml if it's not ok.</p>

<p>For seeds you can configure a custom seed provider. Look at the <a href=""https://github.com/Netflix/Priam/blob/master/priam-cass-extensions/src/main/java/com/netflix/priam/cassandra/extensions/NFSeedProvider.java"" rel=""nofollow"">seed provider used for Netflix's Priam</a> for some ideas how to implement it</p>

<p>The most difficult part will be managing the tokens assigned to each node in a efficient way. Cassandra 1.2 is around the corner and will include a feature called virtual nodes that, IMO, will work well in your case. See the <a href=""http://www.youtube.com/watch?v=GddZ3pXiDys"" rel=""nofollow"">Acunu presentation about it</a></p>
",['rpc_address']
13838990,13842356,2012-12-12 11:41:59,Implementing FIFO read in Cassandra,"<p>Given a Cassandra database, is there a mechanism for fetching records in a FIFO manner such that records can be read in the ascending order of their insertion time. I basically need to read N oldest rows in batches, process them and delete the batch once it is processed. </p>

<p>As far as my understanding goes, Columns are sorted by their type (as specified by CompareWith), and rows are sorted by their partitioner. </p>

<p>Can I use OrderPreservingPartitioner to sort my rows in the ascending order of insertion time? I am running Cassandra on a single node so I am not really worried about the distribution of keys. If OrderPreservingPartitioner can be used, how do I configure the sort criteria for my keys so that the records are maintained in the ascending order of insertion?</p>

<p>Alternately, does Hector provide a mechanism to always fetch rows such that the oldest rows are fetched first?</p>

<p><strong>Edit :</strong> </p>

<p>After reading rs_atl's post, I have some more doubts : </p>

<ol>
<li><p>If I have understood this correctly, I will create a column family with TimeUUIDType as the comparator. I will then have to use timestamps for column names. The immediate question that comes to my mind is how do I define the sort order for the column names as ascending or descending? Can I do this at column family creation time or I have to do this through the client API?</p></li>
<li><p>If I decide to use 'hours' as my shard interval i.e, if I append hours to my keys, how do I retrieve the row for the oldest hour? </p></li>
</ol>
",<java><sorting><cassandra><hector>,"<p>There are a number of things to consider when attempting such a solution with Cassandra:</p>

<ol>
<li>Always use RandomPartitioner, because you'll get hot spots if you don't.</li>
<li>Your keys should be buckets of time (like days or hours), so you can know them in advance for a given time period.</li>
<li>Your column names should be timestamps that sort in time order (either lexicographically or numerically).  This will allow you to query for ranges.</li>
<li>Make sure to use at least QUORUM (or LOCAL_QUORUM) reads and writes, so you don't end up with consistency issues.</li>
<li>You'll need to find a way in your app to make sure you don't process the same data more than once, because someone else could pick up the record between the time that you read it for processing and then delete it (i.e., it's not a like a queue).</li>
</ol>

<p>Hector doesn't determine ordering at all; this happens on insert and is based on the comparator you've chosen.  If you want a specific ordering you have to write the data that way (see point 3 above).</p>

<p>Regarding the additional information in your edit:</p>

<ol>
<li><p>I wouldn't use TimeUUIDType as your comparator, just a long value that's either the Unix epoch or a numeric representation of time in the form of YYYYMMDDxx to the level of precision you need.  You can decide at query time whether you want the values in normal (ascending) or reversed (descending) order.</p></li>
<li><p>You can ask for all keys and simply take the smallest one, which could work fine or be a terrible idea depending on how many you have and your latency requirements.  Alternatively (and certainly more efficient), you could actually write the oldest key somewhere (a file, another CF, in memory, whatever makes sense).</p></li>
</ol>
",['precision']
13882313,13883307,2012-12-14 16:09:30,Cassandra - Understanding Rack Concept on PropertyFileSnitch example,"<p>I am working on multi DC deployment and one thing is not clear to me - this is the rack concept interpretation from Cassandra perspective.</p>

<p>I can enforce replication order by defining proper key ranges. Why do I need to specify racks additionally in <code>cassandra-topology.properties</code> ? </p>

<p>Lets take as example Cassandra documentation: <a href=""http://www.datastax.com/docs/1.1/cluster_architecture/replication"" rel=""nofollow"">http://www.datastax.com/docs/1.1/cluster_architecture/replication</a></p>

<p>If I have replication factor 3, and my row key is stored on Node 1, than replicas will be stored on Node 2 and 3 - this is obvious when we look on ring structure, so... why do I need to duplicate this information in rack configuration?</p>
",<cassandra>,"<p>The rack configuration allows cassandra to optimize replica placement so you have better fault tolerance properties.  If you have all your replicas in rack 1, and that rack goes down, you'll lose the data.  If you tell Cassandra about your rack configuration it will keep replicas on different racks.</p>
",['rack']
14105992,14106468,2012-12-31 20:54:40,Hadoop and Cassandra processing rows in sorted order,"<p>I want to fill a Cassandra database with a list of strings that I then process using Hadoop. What I want to do it run through all the strings in order using a Hadoop cluster and record how much overlap there is between each string in order to find the Longest Common Substring. </p>

<p>My question is, will the InputFormat object allow me to read out the data in a sorted order or will my strings be read out ""randomly"" (according to how Cassandra decides to distribute them) throughout every machine in the cluster? Is the MapReduce process designed to process each row by itself w/out the intent of looking at two rows consecutively like I'm asking for?</p>
",<hadoop><cassandra>,"<p>First of all, the Mappers will read the data in whatever order they get it from the InputFormat. I'm not a Cassandra expert, but I don't expect that will be in sorted order.</p>

<p>If you want sorted order, you should use an identity mapper (one that does nothing) whose output key is the string itself. Then they will be sorted before passed to the reduce step. But it gets a little more complicated since you can have more than one reducer. With only one reducer, everything is globally sorted. With more than one, each reducer's input is sorted, but the input across reducers might not be sorted. That is, adjacent strings might not go to the same reducer. You would need a custom partitioner to handle that.</p>

<p>Lastly, you mentioned that you're doing longest common substring- are you looking for the longest substring among each pair of strings? Among consecutive pairs of strings? Among all strings? Each of these possibilities will affect how you need to structure your MapReduce job.</p>
",['partitioner']
14407468,14408108,2013-01-18 20:55:11,Cassandra CQL time range query,"<p>I have a Cassandra column family where I am storing a large number (hundreds of thousands) of events per month with timestamp (“Ymdhisu”) as the row key. It has multiple columns capturing some data for each event. I tried retrieving events data for a specific time range. For example for the month of Jan, I used the following CQL query:</p>

<p>a) Query between range Jan 1- Jan 15, 2013</p>

<blockquote>
  <p>select count(*) from Test where Key > 20130101070100000000 and Key &lt;
  20130115070100000000 limit 100000; Bad Request: Start key's md5 sorts
  after end key's md5. This is not allowed; you probably should not
  specify end key at all, under RandomPartitioner</p>
</blockquote>

<p>b) Query between range Jan 1- Jan 10, 2013</p>

<blockquote>
  <p>select count(*) from Test where Key > 20130101070100000000 and Key &lt;
  20130110070100000000 limit 100000; count - 73264</p>
</blockquote>

<p>c) Query between range Jan 1- Jan 2, 2013 </p>

<blockquote>
  <p>select count(*) from Test where Key > 20130101070100000000 and Key &lt;
  20130102070100000000 limit 100000; count - 78328</p>
</blockquote>

<p>It appears as though the range search simply is not working! The schema of my Columnfamily is:</p>

<pre><code>Create column family Test with comparator=UTF8Type and default_validation_class=UTF8Type and key_validation_class=UTF8Type AND compression_options={sstable_compression:SnappyCompressor, chunk_length_kb:64};
</code></pre>

<p>To extract data, what are the suggestions? Do I need to redefine my schema with key validation class as TimeUUID type? Is there any other way to query efficiently without changing the schema?
I am dealing with at least 100-200K rows of data monthly in this column family. If this schema does not work for this purpose, what would be an appropriate Cassandra schema to store and retrieve the kind of data described here?</p>
",<nosql><cassandra><bigdata><cql>,"<p>You can create secondary indexes such as ""Date"" and ""Month"", and store each event's Date and Month in those columns along with other data. When querying data, you can fetch all rows for specified months or days.</p>

<p>I dont think range query on Keys will work. Perhaps if you change your partitioner from RandomPartitioner to ByteOrderedPartitioner?</p>
",['partitioner']
15865710,15875434,2013-04-07 17:50:58,Cassandra RandomPartitioner on version 1.2.3,"<p>Im installing Cassandra 1.2.3 on debian using apt, I was previously using a tarball 1.1.7 install.  After install i'm changing the partitioner from Murmur3Partitioner to RandomPartitioner in cassandra.yaml as follows:</p>

<p>partitioner: org.apache.cassandra.dht.RandomPartitioner</p>

<p>Then on starting i'm seeing incompatible system keyspace errors as follows:</p>

<p>ERROR 18:22:11,465 Cannot open /var/lib/cassandra/data/system/schema_keyspaces/system-schema_keyspaces-ib-1; partitioner org.apache.cassandra.dht.Murmur3Partitioner does not match system partitioner org.apache.cassandra.dht.RandomPartitioner.  Note that the default partitioner starting with Cassandra 1.2 is Murmur3Partitioner, so you will need to edit that to match your old partitioner if upgrading.
Service exit with a return value of 1</p>

<p>How can I set the system keyspace to be RandomPartitioner? I have tried purging the data folder, apt-get remove, also apt-get purge then re-installing, changing to RandomPartitioner then starting cassandra but it is still failing.  I've also replicated this on my ubuntu desktop so im thinking im doing something wrong here.</p>

<p>Any help is appreciated!</p>

<p>Cheers</p>

<p>Sam</p>
",<cassandra>,"<p>The partitioner cannot be changed once Cassandra has started for the first time.  This error is showing that the data directory was initialized with Murmur3Partitioner but you're starting it using RandomPartitioner.</p>

<p>If you're trying to upgrade your data from your 1.1 install, Cassandra isn't reading from the right place.  Adjust your data directory to use your 1.1 directory and it should start with partitioner set to RandomPartitioner.</p>

<p>If you're trying to start with no data, stop Cassandra, remove /var/lib/cassandra/* and start it again.  Note you need to remove the commitlog directory as well as the data directory.</p>
",['partitioner']
15925549,22273466,2013-04-10 12:16:23,How does cassandra split keyspace data when multiple directories are configured?,"<p>I have configured three separate data directories in cassandra.yaml file as given below:</p>

<pre>
data_file_directories:
    - E:/Cassandra/data/var/lib/cassandra/data
    - K:/Cassandra/data/var/lib/cassandra/data
</pre>

<p>when I create keyspace and insert data my key space got created in both two directories and data got scattered. what I want to know is how cassandra splits the data between multiple directories?. And what is the rule behind this?</p>
",<cassandra>,"<p>You are using the JBOD feature of Cassandra when you add multiple entries under data_file_directories. Data is spread evenly over the configured drives proportionate to their available space. </p>

<p>This also let's you take advantage of the disk_failure_policy setting. You can read about the details here:
<a href=""http://www.datastax.com/dev/blog/handling-disk-failures-in-cassandra-1-2"" rel=""noreferrer"">http://www.datastax.com/dev/blog/handling-disk-failures-in-cassandra-1-2</a></p>

<p>In short, you can configure Cassandra to keep going, doing what it can if the disk becomes full or fails completely. This has advantages over RAID0 (where you would effectively have the same capacity as JBOD) in that you do not have to replace the whole data set from backup (or full repair) but just run a repair for the missing data. On the other hand, RAID0 provides higher throughput (depending how well you know how to tune RAID arrays to match filesystem and drive geometry). </p>

<p>If you have the resources for fault-tolerant/more performant RAID setup (like RAID10 for example), you may want to just use a single directory for simplicity. Most deployments are starting to lean towards the density route, using JBOD rather than systems-level tolerance though. </p>

<p>You can read about the thought process behind the development of this issue here:
<a href=""https://issues.apache.org/jira/browse/CASSANDRA-4292"" rel=""noreferrer"">https://issues.apache.org/jira/browse/CASSANDRA-4292</a></p>
",['disk_failure_policy']
16204066,16234121,2013-04-24 23:40:12,Increasing of used space while rebalancing Cassandra cluster,"<p>Just an example: I have 2 Cassandra nodes, 1Gb data per each node, replication factor is 1. I use single column family with Leveled compaction with 100Mb sstable size, like this:</p>

<pre><code>create column family ColFamily with key_validation_class=UTF8Type 
  and compaction_strategy=LeveledCompactionStrategy 
  and compaction_strategy_options={sstable_size_in_mb: 100};
</code></pre>

<p>I want to add additional node. The data will be rebalanced across 3 nodes: ~0,667 Mb per node. Right?</p>

<p>But how the used space will be increased on each node while the process of rebalancing is being in progress? What will be the peak?</p>
",<cassandra>,"<p>Before Cassandra 1.2 and virtual nodes, you have to do the redistribution of data yourself after adding a new node.</p>

<p>If your two nodes are currently balanced i.e. have 50% of the ring each, then the tokens will be</p>

<pre><code>node1: 0
node2: 85070591730234615865843651857942052864
</code></pre>

<p>(or shifted, but I'll assume node1 has token 0).  The token for node2 is 2^127/2.  You want to end up with</p>

<pre><code>node1: 0
node2: 56713727820156410577229101238628035242
node3: 113427455640312821154458202477256070484
</code></pre>

<p>where the token for node2 is 2^127/3, and for node3 is (2^127/3)*2.  What you need to do is bootstrap node3 with initial_token set to the token above.  This copies data from node1, since node3's token precedes to node1's (the token ring is wrapped around).</p>

<p>Now node3 will have 1/6 of the data, node2 will still have 1/2 and node1 will store 1/2 but only be responsible for 1/3.  You could now run 'nodetool cleanup' on node1 to remove the data that it copied over to node3.  This will reduce node1's data to approx 677MB.</p>

<p>Now you need to move node2's token to its final place.  This copies data from node2 to node3, bringing node3 up to its quota of 1/3 of the data, approx 667 MB.  Now you can run 'nodetool cleanup' on node2 to remove the data it has just copied to node3.  Now the rebalancing is complete.</p>

<p>This means no node ever stores more than 1 GB of data during the rebalancing.</p>

<p>In general, if you had more nodes or higher replication factor, you can always do the rebalancing without increasing the data stored on any existing nodes if you run cleanup after each move on the node just moved.</p>

<p>Finally, if you had Cassandra 1.2 and virtual nodes, the tokens can be chosen randomly which gives even load as soon as you add a new node, with no need for any rebalancing (manual or automatic).  This is not only easier, it saves copying a constant fraction of your data around the cluster just to add one node.</p>
",['initial_token']
16453411,16471860,2013-05-09 02:32:35,What's the meaning of NodeDiscoveryType as TOKEN_AWARE in Astyanax client?,"<p>I found <code>TOKEN_AWARE</code> enum value in Astyanax client for Cassandra in <a href=""https://github.com/Netflix/astyanax/blob/master/astyanax-core/src/main/java/com/netflix/astyanax/connectionpool/NodeDiscoveryType.java"" rel=""nofollow"">com.netflix.astyanax.connectionpool.NodeDiscoveryType</a> and am trying to understand what it does?</p>

<pre><code>package com.netflix.astyanax.connectionpool;

public enum NodeDiscoveryType {
    /**
     * Discover nodes exclusively from doing a ring describe
     */
    RING_DESCRIBE,

    /**
     * Discover nodes exclusively from an external node discovery service
     */
    DISCOVERY_SERVICE,

    /**
     * Intersect ring describe and nodes from an external service. This solve
     * the multi-region ring describe problem where ring describe returns nodes
     * from other regions.
     */
    TOKEN_AWARE,

    /**
     * Use only nodes in the list of seeds
     */
    NONE
}
</code></pre>

<p>Suppose if I have 24 nodes <code>cross colo cluster</code> with 12 nodes in PHX <code>colo/datacenter</code> and 12 nodes in SLC <code>colo/datacenter</code>.</p>

<p>And I am connecting to Cassandra using Astyanax client as follows:</p>

<pre><code>private CassandraAstyanaxConnection() {
    context = new AstyanaxContext.Builder()
                .forCluster(ModelConstants.CLUSTER)
                .forKeyspace(ModelConstants.KEYSPACE)
    .withConnectionPoolConfiguration(new ConnectionPoolConfigurationImpl(""MyConnectionPool"")
        .setPort(9160)
        .setMaxConnsPerHost(40)
        .setSeeds(""cdb03.vip.phx.host.com:9160,cdb04.vip.phx.host.com:9160"")
    )
    .withAstyanaxConfiguration(new AstyanaxConfigurationImpl()      
        .setCqlVersion(""3.0.0"")
        .setTargetCassandraVersion(""1.2"")
        .setDiscoveryType(NodeDiscoveryType.TOKEN_AWARE))
    .withConnectionPoolMonitor(new CountingConnectionPoolMonitor())
    .buildKeyspace(ThriftFamilyFactory.getInstance());

    context.start();
    keyspace = context.getEntity();

    emp_cf = ColumnFamily.newColumnFamily(
        ModelConstants.COLUMN_FAMILY, 
        StringSerializer.get(), 
        StringSerializer.get());
}
</code></pre>

<p>Can anyone explain me what the difference between <code>TOKEN_AWARE</code> of <code>NodeDiscoveryType</code> vs <code>TOKEN_AWARE</code> of <code>ConnectionPoolType</code> is?</p>

<p>Thanks for the help.</p>

<p><strong>Updated Code</strong></p>

<p>Below is the code I am using so far after making changes-</p>

<pre><code>private CassandraAstyanaxConnection() {

    context = new AstyanaxContext.Builder()
    .forCluster(ModelConstants.CLUSTER)
    .forKeyspace(ModelConstants.KEYSPACE)
    .withConnectionPoolConfiguration(new ConnectionPoolConfigurationImpl(""MyConnectionPool"")
        .setPort(9160)
        .setMaxConnsPerHost(40)
        .setSeeds(""cdb03.vip.phx.host.com:9160,cdb04.vip.phx.host.com:9160"")
        .setLocalDatacenter(""phx"")
    )
    .withAstyanaxConfiguration(new AstyanaxConfigurationImpl()
        .setCqlVersion(""3.0.0"")
        .setTargetCassandraVersion(""1.2"")
        .setConnectionPoolType(ConnectionPoolType.TOKEN_AWARE))
    .withConnectionPoolMonitor(new CountingConnectionPoolMonitor())
    .buildKeyspace(ThriftFamilyFactory.getInstance());

    context.start();
    keyspace = context.getEntity();

    emp_cf = ColumnFamily.newColumnFamily(
        ModelConstants.COLUMN_FAMILY, 
        StringSerializer.get(), 
        StringSerializer.get());
}
</code></pre>

<p>You mentioned in your example that you will be using-</p>

<pre><code>    .setDiscoveryType(NodeDiscoveryType.RING_DESCRIBE)
    .setConnectionPoolType(ConnectionPoolType.TOKEN_AWARE)
</code></pre>

<p>these two together right? But I believe <code>TOKEN_AWARE ConnectionPoolType</code> by default uses <code>RING_DESCRIBE</code> so it doesn't make sense to add it again. Am I right?</p>

<p>Correct me if I am wrong?</p>
",<java><cassandra><astyanax>,"<p>When it comes to ""node discovery"" the relationship between TOKEN_AWARE for NodeDiscoveryType and TOKEN_AWARE for ConnectionPoolType is interrelated and somewhat confusing.</p>

<h2>NodeDiscoveryType is <a href=""https://github.com/Netflix/astyanax/blob/master/astyanax-cassandra/src/main/java/com/netflix/astyanax/AstyanaxContext.java#L91"">determined</a> as follows (and it -usually- isn't via setDiscoveryType()):</h2>

<ul>
<li><strong>If</strong> you've provided Seeds via setSeeds and ConnectionPoolType is
TOKEN_AWARE <strong>then</strong> NodeDiscoveryType is RING_DESCRIBE.</li>
<li><strong>If</strong> you've provided Seeds via setSeeds and ConnectionPoolType is
anything other than TOKEN_AWARE <strong>then</strong> your configured setDiscoveryType will be used.  <em>This is the only case in which your configured NodeDiscoveryType (via setDiscoveryType) will be used.</em></li>
<li><strong>If</strong> you did not provide Seeds via setSeeds AND ConnectionPoolType is
TOKEN_AWARE <strong>then</strong> NodeDiscoveryType is TOKEN_AWARE. </li>
<li><strong>If</strong> you did not provide Seeds via setSeeds AND ConnectionPoolType is
anything other than TOKEN_AWARE <strong>then</strong> NodeDiscoveryType is
DISCOVERY_SERVICE.</li>
</ul>

<h2>Node Discovery</h2>

<p>Now that we've determined how NodeDiscoveryType is set, let's <a href=""https://github.com/Netflix/astyanax/blob/master/astyanax-cassandra/src/main/java/com/netflix/astyanax/AstyanaxContext.java#L142"">see</a> how it impacts actually discovering nodes.  Node discovery boils down to which implementation of HostSupplier (i.e. <code>Supplier&lt;List&lt;Host&gt;&gt;</code>) is used.</p>

<ul>
<li><strong>If</strong> NodeDiscoveryType (from above) is DISCOVERY_SERVICE <strong>then</strong> must use HostSupplier (via <code>withHostSupplier</code>).</li>
<li><strong>If</strong> NodeDiscoveryType (from above) is RING_DESCRIBE <strong>then</strong> use RingDescribeHostSupplier.</li>
<li><strong>If</strong> NodeDiscoveryType (from above) is TOKEN_AWARE and HostSupplier is set (via <code>withHostSupplier</code>) <strong>then</strong> use FilteringHostSupplier with RingDescribeHostSupplier.</li>
<li><strong>If</strong> NodeDiscoveryType (from above) is TOKEN_AWARE and no HostSupplier is set <strong>then</strong> use RingDescribeHostSupplier.</li>
</ul>

<h2>RingDescribe and using the local DC</h2>

<p>Based on the configuration you've supplied you'll end up with RingDescribeHostSupplier.  RingDescribeHostSupplier allows connections to all nodes in the ring unless you've specified a datacenter.  So, when setting up your AstyanaxContext using ConnectionPoolConfigurationImpl you might want to setLocalDatacenter with the desired DC. That will ensure that hosts from the other dc's are not in the connection pool and that your requests are local.</p>

<pre><code>.withConnectionPoolConfiguration(new ConnectionPoolConfigurationImpl(""MyConnectionPool"")
        .setPort(9160)
        .setMaxConnsPerHost(40)
        .setLocalDatacenter(""phx"")
        .setSeeds(""cdb03.vip.phx.host.com:9160,cdb04.vip.phx.host.com:9160"")
    )
</code></pre>

<h2>ConnectionPoolType</h2>

<p>You also might want to set ConnectionPoolType to TOKEN_AWARE.  When that value is left unset, it will default to ROUND_ROBIN (using the nodes from the node discovery work described above).  TOKEN_AWARE ConnectionPoolType will ""keep track of which hosts have which tokens and attempt to direct traffic intelligently"".  </p>

<p>I'd do something like this for Astyanax configuration, unless you are providing a HostSupplier.</p>

<pre><code>.withAstyanaxConfiguration(new AstyanaxConfigurationImpl()      
        .setDiscoveryType(NodeDiscoveryType.RING_DESCRIBE)
        .setConnectionPoolType(ConnectionPoolType.TOKEN_AWARE)
    )
</code></pre>

<h2>Pool Optimizations</h2>

<p>Another consideration would be optimizing the pool usage with Astyanax ""latency awareness"" on ConnectionPoolConfigurationImpl, but YMMV on the settings.  e.g. :</p>

<pre><code>.setLatencyScoreStrategy(new SmaLatencyScoreStrategyImpl(10000,10000,100,0.50))
// The constructor takes:
//  UpdateInterval: 10000 : Will resort hosts per token partition every 10 seconds
//  ResetInterval: 10000 : Will clear the latency every 10 seconds
//  WindowSize: 100 : Uses last 100 latency samples
//  BadnessThreshold: 0.50 : Will sort hosts if a host is more than 100% 
</code></pre>

<p>See Astyanax <a href=""https://github.com/Netflix/astyanax/wiki/Configuration"">Configuration</a></p>

<h2>TLDR;</h2>

<p>In summary, set NodeDiscoveryType to RING_DESCRIBE (if you aren't using a HostSupplier) and ConnectionPoolType to TOKEN_AWARE.  Additionally, use setLocalDatacenter to keep requests local to the dc and consider the latency awareness settings.</p>
",['dc']
16532566,16547891,2013-05-13 23:03:28,How to insert a datetime into a Cassandra 1.2 timestamp column,"<p><strong>IMPORTANT</strong>
If you are dealing with this problem today, use the new cassandra-driver from datastax (i.e. import cassandra) since it solves most of this common problems and don't use the old cql driver anymore, it is obsolete! This question is old from before the new driver was even in development and we had to use an incomplete old library called cql (import cql &lt;-- don't use this anymore, move to the new driver).</p>

<p><strong>Intro</strong>
I'm using the python library cql to access a Cassandra 1.2 database. In the database I have a table with a timestamp column and in my Python code I have a datetime to be inserted in the column. Example as follows:</p>

<p><strong>Table</strong></p>

<pre><code>CREATE TABLE test (
     id text PRIMARY KEY,
     last_sent timestamp
);
</code></pre>

<p><strong>The code</strong></p>

<pre><code>import cql
import datetime
...
cql_statement = ""update test set last_sent = :last_sent where id =:id""
rename_dict = {}
rename_dict['id'] = 'someid'
rename_dict['last_sent'] = datetime.datetime.now()
cursor.execute (cql_statement, rename_dict)
</code></pre>

<p><strong>The problem</strong></p>

<p>When I execute the code the actual cql statement executed is like this:</p>

<pre><code>update test set last_sent =2013-05-13 15:12:51 where id = 'someid'
</code></pre>

<p>Then it fails with an error</p>

<pre><code> Bad Request: line 1:XX missing EOF at '-05'
</code></pre>

<p>The problem seems to be that the cql library is not escaping ('') or converting the datetime before running the query.</p>

<p><strong>The question</strong>
What is the correct way of doing this without manually escaping the date and be able to store a full timestamp with more precision into a cassandra timestamp column?</p>

<p>Thanks in advance!</p>
",<python><cassandra><cql>,"<p>Has abhi already stated this can be done using the milliseconds since epoch as a long value from cqlsh, now we need to make it work in the Python code.</p>

<p>When using the cql library this conversion (from datetime to milliseconds since epoch) is not happening so in order to make the update work and still have the precision you need to convert the datetime to milliseconds since epoch.</p>

<p><strong>Source</strong>
Using this useful question: <a href=""https://stackoverflow.com/questions/6999726/python-getting-millis-since-epoch-from-datetime"">Getting millis since epoch from datetime</a> , in particular this functions(note the little change I made):</p>

<p><strong>The solution</strong></p>

<pre><code>import datetime

def unix_time(dt):
    epoch = datetime.datetime.utcfromtimestamp(0)
    delta = dt - epoch
    return delta.total_seconds()

def unix_time_millis(dt):
    return long(unix_time(dt) * 1000.0)
</code></pre>

<p>For this example the code would be:</p>

<pre><code>cql_statement = ""update test set last_sent = :last_sent where id =:id""
rename_dict = {}
rename_dict['id'] = 'someid'
rename_dict['last_sent'] = unix_time_millis(datetime.datetime.now())
cursor.execute (cql_statement, rename_dict)
</code></pre>

<p>You can convert the datetime to a long value containing the number of milliseconds since epoch and that's all, the update is transformed to an equivalent form using a long value for the timestamp.</p>

<p>Hope it helps somebody else</p>
",['precision']
16549833,16585376,2013-05-14 18:01:54,Cassandra Commit and Recovery on a Single Node,"<p>I am a newbie to Cassandra - I have been searching for information related to commits and crash recovery in Cassandra on a single node. And, hoping someone can clarify the details.</p>

<p>I am testing Cassandra - so, set it up on a single node. I am using stresstool on datastax to insert millions of rows. What happens if there is an electrical failure or system shutdown? Will all the data that was in Cassandra's memory get written to disk upon Cassandra restart (I guess commitlog acts as intermediary)? How long is this process?</p>

<p>Thanks!</p>
",<crash><nosql><cassandra><recovery><datastax-enterprise>,"<p>Cassandra's commit log gives Cassandra durable writes.  When you write to Cassandra, the write is appended to the commit log before the write is acknowledged to the client.  This means every write that the client receives a successful response for is guaranteed to be written to the commit log.  The write is also made to the current memtable, which will eventually be written to disk as an SSTable when large enough.  This could be a long time after the write is made.</p>

<p>However, the commit log is not immediately synced to disk for performance reasons.  The default is periodic mode (set by the commitlog_sync param in cassandra.yaml) with a period of 10 seconds (set by commitlog_sync_period_in_ms in cassandra.yaml).  This means the commit log is synced to disk every 10 seconds.  With this behaviour you could lose up to 10 seconds of writes if the server loses power.  If you had multiple nodes in your cluster and used a replication factor of greater than one you would need to lose power to multiple nodes within 10 seconds to lose any data.</p>

<p>If this risk window isn't acceptable, you can use batch mode for the commit log.  This mode won't acknowledge writes to the client until the commit log has been synced to disk.  The time window is set by commitlog_sync_batch_window_in_ms, default is 50 ms.  This will significantly increase your write latency and probably decrease the throughput as well so only use this if the cost of losing a few acknowledged writes is high.  It is especially important to store your commit log on a separate drive when using this mode.</p>

<p>In the event that your server loses power, on startup Cassandra replays the commit log to rebuild its memtable.  This process will take seconds (possibly minutes) on very write heavy servers.</p>

<p>If you want to ensure that the data in the memtables is written to disk you can run 'nodetool flush' (this operates per node).  This will create a new SSTable and delete the commit logs referring to data in the memtables flushed.</p>
",['commitlog_sync']
16922951,16927739,2013-06-04 16:27:26,Get last record in Cassandra,"<p>Have a table with about 20 million rows in Cassandra. </p>

<p>The table is ordered by a <code>primary_key</code> column, which is a string. We are using 'ByteOrderedPartitioner', so the rows are ordered by the <code>primary_key</code> and not a hash of the <code>primary_key</code> column.</p>

<p>What is a good way to get the very last record in the table?</p>

<p>Thanks so much!</p>
",<cassandra>,"<p>If for ""very last record"" you mean the one ordered as last I don't think you can do it like a ""GET"", you have to scan rows. The best you can do, afaik, is select a good range to scan (good start key) according to your primary key.</p>

<p>From datastax docs:</p>

<blockquote>
  <p>""Using the ordered partitioner allows ordered scans by primary key.
  This means you can scan rows as though you were moving a cursor
  through a traditional index. For example, if your application has user
  names as the row key, you can scan rows for users whose names fall
  between Jake and Joe. This type of query is not possible using
  randomly partitioned row keys because the keys are stored in the order
  of their MD5 hash (not sequentially).""</p>
</blockquote>

<p>If you find better solution let me know.</p>

<p>Regards,
Carlo</p>
",['partitioner']
17631473,17642791,2013-07-13 15:14:58,Cassandra 1.2: Unable to complete request: one or more nodes were unavailable,"<p>I'm having trouble setting up a new Cassandra cluster. I've set up a 3 node cluster in EC2 (Zone: eu-west-1b). When I try to insert a record into a new table I receive this error message:</p>

<pre><code>cqlsh:test&gt; insert into mytest (id, value) values(1,100);
Unable to complete request: one or more nodes were unavailable.
</code></pre>

<p>I've confirmed that the 3 nodes are up and running:</p>

<pre><code>nodetool status
UN  ***.***.***.***  68.1 KB    256     33.2%  bbf1c5e9-ac68-41a1-81a8-00c7877c4eac  rack1
UN  ***.***.***.***  81.95 KB   256     34.1%  e118e3a7-2486-4c08-8ba1-d337888ff59c  rack1
UN  ***.***.***.***   68.12 KB   256     32.7%  041cb88e-df21-4640-b7ac-7a87fd38dae6  rack1
</code></pre>

<p>The commands I used to create the keyspace and table are:</p>

<pre><code>create keyspace test with replication ={'class':'NetworkTopologyStrategy', 'eu-west-1b': 2};
use test;
create table mytest (id int primary key, value int);
insert into mytest (id, value) values(1,100);
</code></pre>

<p>Each node can see the keyspace - I used CQLSH and ran descibe keyspace and got this output from each node:</p>

<pre><code>CREATE KEYSPACE test WITH replication = {
  'class': 'NetworkTopologyStrategy',
  'eu-west-1b': '2'
};

USE test;

CREATE TABLE mytest (
  id int PRIMARY KEY,
  value int
) WITH
  bloom_filter_fp_chance=0.010000 AND
  caching='KEYS_ONLY' AND
  comment='' AND
  dclocal_read_repair_chance=0.000000 AND
  gc_grace_seconds=864000 AND
  read_repair_chance=0.100000 AND
  replicate_on_write='true' AND
  populate_io_cache_on_flush='false' AND
  compaction={'class': 'SizeTieredCompactionStrategy'} AND
  compression={'sstable_compression': 'SnappyCompressor'};
</code></pre>
",<amazon-ec2><cassandra>,"<p>I finally tracked down the problem - I had set the endpoint_snitch to Ec2Snitch, but the default Datastax was set beneath the comments (which I hadn't noticed). I commented out the DS snitch, restarted the dse service on all nodes and ran nodetool repair on each node and the problem went away.</p>
",['endpoint_snitch']
18106043,18106777,2013-08-07 14:25:38,Is there a way to discover Cassandra CQL table structure?,"<p>Let's say I use CQL to define this table.</p>

<pre><code>CREATE TABLE songs (
    id uuid PRIMARY KEY, 
    title text,
    album text, 
    artist text, 
    tags set&lt;text&gt;, 
    data blob);
</code></pre>

<p>How can other developers (or myself after a few weeks) (re)discover the layout of this table?</p>

<p>I'm thinking of an equivalent to the MySQL <code>DESCRIBE {tablename}</code> command.</p>

<p><strong>[EDIT]</strong></p>

<p>I see there is a <code>DESCRIBE</code> method in Cassandra's command line interface (CLI), but upon using it, it states that it doesn't include information on CQL tables in its results.</p>
",<cassandra><cql>,"<p>You should try the <code>cqlsh</code> tool which will show you exactly what you want:</p>

<pre><code>lyubent@vm: ~$ ./cqlsh 
cqlsh&gt; use system;
cqlsh&gt; describe columnfamily local;

CREATE TABLE local (
  key text PRIMARY KEY,
  bootstrapped text,
  cluster_name text,
  cql_version text,
  data_center text,
  gossip_generation int,
  host_id uuid,
  partitioner text,
  rack text,
  release_version text,
  schema_version uuid,
  thrift_version text,
  tokens set&lt;text&gt;,
  truncated_at map&lt;uuid, blob&gt;
) WITH
  bloom_filter_fp_chance=0.010000 AND
  caching='KEYS_ONLY' AND
  comment='information about the local node' AND
  dclocal_read_repair_chance=0.000000 AND
  gc_grace_seconds=0 AND
  read_repair_chance=0.000000 AND
  replicate_on_write='true' AND
  populate_io_cache_on_flush='false' AND
  compaction={'class': 'SizeTieredCompactionStrategy'} AND
  compression={'sstable_compression': 'SnappyCompressor'};
</code></pre>

<p><strong>EDIT</strong><br/>
Although great at the time the blog i linked is ood. To run cqlsh in windows:</p>

<ul>
<li>first install python 2.7.x (not python 3!)
<a href=""http://www.python.org/getit/""><strong>download</strong></a><br/> </li>
<li>Add python to your path (as a new environment variable)</li>
<li><p>Run the setup by navigating to
<code>C:\dir\to\cassandra\pylib</code> in a cmd prompt and executing the below
line:</p>

<pre><code>python setup.py install
</code></pre></li>
</ul>

<p>GZ. Now you have cqlsh on windows.</p>
","['partitioner', 'rack', 'cluster_name']"
18398987,20334000,2013-08-23 09:07:18,How to reset a lost Cassandra admin user's password?,"<p>I have full access to the Cassandra installation files and a PasswordAuthenticator configured in <code>cassandra.yaml</code>. What do I have to do to reset admin user's password that has been lost, while keeping the existing databases intact?</p>
",<cassandra><cassandra-2.0>,"<p>Solved with the following steps:</p>

<ol>
<li>Change authenticator in <code>cassandra.yaml</code> to AllowAllAuthenticator and restart Cassandra</li>
<li><code>cqlsh</code></li>
<li><code>update system_auth.credentials set salted_hash='$2a$10$vbfmLdkQdUz3Rmw.fF7Ygu6GuphqHndpJKTvElqAciUJ4SZ3pwquu' where username='cassandra';</code></li>
<li>Exit <code>cqlsh</code></li>
<li>Change authenticator back to PasswordAuthenticator and restart Cassandra</li>
</ol>

<p>Now you can log in with</p>

<pre><code>cqlsh -u cassandra -p cassandra
</code></pre>

<p>and change the password to something else.</p>
",['authenticator']
18712650,18729891,2013-09-10 07:10:54,Cassandra: what is the correct configuration for EC2 multi-region?,"<p>What is the correct configuration for a mulit-region setup in EC2 instances?</p>

<p>What should the listen_address, broadcast_address, rpc_address and seed ip/addresses be to work?</p>

<p>When do you use public IP address and when do you use private IP addresses?</p>
",<amazon-ec2><cassandra>,"<p>According to the <a href=""http://www.datastax.com/documentation/cassandra/1.2/webhelp/index.html?pagename=docs&amp;version=1.2&amp;file=#cassandra/configuration/configCassandra_yaml_r.html"" rel=""noreferrer"">docs</a>:</p>

<p><code>broadcast_address</code>: (Default: <code>listen_address</code>) If your Cassandra cluster is deployed across multiple Amazon EC2 regions and you use the EC2MultiRegionSnitch, set the broadcast_address to public IP address of the node and the listen_address to the private IP.</p>

<p><code>listen_address</code>: (Default: localhost) The IP address or hostname that other Cassandra nodes use to connect to this node. If left unset, the hostname must resolve to the IP address of this node using/etc/hostname, /etc/hosts, or DNS. Do not specify 0.0.0.0.</p>

<p><code>rpc_address</code>: (Default: localhost) The listen address for client connections (Thrift remote procedure calls). </p>

<p><code>seed_provider</code>: (Default: org.apache.cassandra.locator.SimpleSeedProvider) A list of comma-delimited hosts (IP addresses) to use as contact points when a node joins a cluster. Cassandra also uses this list to learn the topology of the ring. When running multiple nodes, you must change the - seeds list from the default value (127.0.0.1). In multiple data-center clusters, the - seeds list should include at least one node from each data center (replication group)</p>

<p>Trying to summarize:</p>

<ol>
<li>the <code>rpc_address</code> is used for client connections and has nothing to do with multi-region EC2</li>
<li>the <code>listen_address</code> and <code>broadcast_address</code> are the 2 important options for multi-region EC2 configuration</li>
<li><p>in general when configuring any of these answer 2 questions: </p>

<ol>
<li>who is connecting? (another nodes? clients?)</li>
<li>what IPs are accessible? (is this network interface accessible to who is connecting?)</li>
</ol></li>
</ol>
","['listen_address', 'broadcast_address']"
18842369,18850980,2013-09-17 06:05:10,Cassandra nodetool could not resolve '127.0.0.1': unknown host,"<p>I am very new to cassandra. Just started exploring.</p>

<p>I am running a single node cassandra server &amp; facing a problem in seeing status of the cassandra using nodetool command.</p>

<p>I have hostname configured on my VM as myMachineIP cass1 in /etc/hosts</p>

<p>and </p>

<p>I configured my cassandra_instal_path/conf/cassandra.yaml file with listen_address, rpc_address as localhost and clustername as casscluster</p>

<p>(also tried with my hostname which is cass1 as listen_address/rpc_address)</p>

<p>Not sure what is the reason why i am not able to get statususing nodetool command.</p>

<pre><code>$ nodetool

Cannot resolve '127.0.0.1': unknown host

$ nodetool -host 127.0.0.1

Cannot resolve '127.0.0.1': unknown host

$ nodetool -host cass1

Cannot resolve 'cass1': unknown host
</code></pre>

<p>But i am able to connect to cassandra-cli</p>

<p>console output:</p>

<pre><code>Connected to: ""casscluster"" on 127.0.0.1/9160
Welcome to Cassandra CLI version 1.2.8

Type 'help;' or '?' for help.
Type 'quit;' or 'exit;' to quit.
</code></pre>

<p>my /etc/hosts looks like:</p>

<pre><code>127.0.0.1       localhost.localdomain   localhost.localdomain   localhost4      localhost4.localdomain4 localhost       cass1

::1     localhost.localdomain   localhost.localdomain   localhost6      localhost6.localdomain6 localhost       cass1


[myMachineIP]  cass1
</code></pre>

<p>what could be the reason why i am not able to run nodetool?</p>

<p>Please help.</p>
",<cassandra><nodetool>,"<p>try setting actual IP address in  listen_address, rpc_address than localhost</p>
",['rpc_address']
18877420,18877486,2013-09-18 16:22:48,Can I have different partitioners in a multiple datacenter configuration in cassandra?,"<p>Can I have RandomPartitioner in the cluster in datacenter1 and Murmur3Partitioner in the cluster in datacenter2?  </p>
",<cassandra><partitioner>,"<p>No, you need to have the same partitioner on all nodes in the cluster.</p>

<p>If you are asking this because you want a way of migrating from RandomPartitioner to Murmur3Partitioner then it won't work unfortunately.  I don't know of a method of moving to Murmur3Partitioner  on a live cluster, but the benefit is small so it is unlikely to be worth doing.</p>
",['partitioner']
19090855,19091104,2013-09-30 09:32:23,Cassandra write strategy,"<p>I want to write 1 billions rows with 2 connected nodes in Cassandra. I use 8 threads from the clients but I don't know whether I write only in one node or both to have the max performance?
Thanks</p>
",<cassandra>,"<p>It won't matter if you write to one node or both. Whichever node is receiving the updates (called the coordinator node) will partition the data based on the partitioner and distribute the necessary section of data to the other node. So whether the updates goes to 1 node or 2, the same network latency and processing will be carried out overall.</p>

<p>With 8 threads you should see good write performance, as Cassandra is optimized for a write heavy workload.</p>

<p>Here is a good treatment of <a href=""http://www.datastax.com/docs/1.0/cluster_architecture/about_client_requests"" rel=""nofollow"">client requests</a>.</p>
",['partitioner']
19143452,19145402,2013-10-02 17:49:55,Datastax Java driver to autodiscover all the nodes for specific datacenter in its connection pool?,"<p>I have recently started using <code>Cassandra</code> in our <code>Production environment</code>. We have a <code>24 node cluster</code> with <code>replication factor of 4</code>. Meaning <code>2 copies</code> will be there in <code>each datacenter</code>. So that means we have a single cross colo cluster with <code>24 nodes</code> which means <code>12 nodes in SLC colo</code> and <code>12 nodes in PHX colo</code>.</p>

<p>I am using <code>Astyanax client</code> currently to write the data in <code>Cassandra database</code>. And I know Astyanax client has this feature to autodiscover all the nodes in PHX colo or SLC colo of cassandra in its connection pooling but not all of the nodes.</p>

<p>In Astyanax we can use something like below - </p>

<pre><code>setLocalDatacenter(""DC1"")
</code></pre>

<p>Now we are planning to use Datastax Java driver. And I am not sure whether Datastax java driver has this feature or not to autodiscover all the cassandra nodes in its connection pool only for specific datacenter and not all the datacenters?</p>
",<java><cassandra><astyanax><datastax-java-driver>,"<p>The driver will discover all the nodes in your cluster, you want to change your load balancing policy in your client code. Specifically you want to use the dc aware load balancing policy.</p>

<p><a href=""http://www.datastax.com/drivers/java/apidocs/com/datastax/driver/core/policies/DCAwareRoundRobinPolicy.html"" rel=""nofollow"">http://www.datastax.com/drivers/java/apidocs/com/datastax/driver/core/policies/DCAwareRoundRobinPolicy.html</a></p>
",['dc']
19374143,19997995,2013-10-15 05:53:22,Get rows using first component of composite key using hector client in Cassandra,"<p>I'm using composite datatype in rowkey, column family is as below</p>

<pre><code>create column family CompositeTest
with comparator = 'UTF8Type'
and key_validation_class = 'CompositeType(UTF8Type,UTF8Type)'
and default_validation_class = 'UTF8Type';
</code></pre>

<p>The sample data of this column family as below,</p>

<pre><code>RowKey: s2:2222222
=&gt; (column=param1, value=value1
=&gt; (column=param2, value=value2
=&gt; (column=param3, value=value3
-------------------
RowKey: s2:3333333
=&gt; (column=param1, value=value1
=&gt; (column=param2, value=value2
=&gt; (column=param3, value=value3
-------------------
RowKey: s2:1111111
=&gt; (column=param1, value=value1
=&gt; (column=param2, value=value2
=&gt; (column=param3, value=value3
-------------------
RowKey: s1:3333333
=&gt; (column=param1, value=value1
=&gt; (column=param2, value=value2
=&gt; (column=param3, value=value3
-------------------
RowKey: s1:2222222
=&gt; (column=param1, value=value1
=&gt; (column=param2, value=value2
=&gt; (column=param3, value=value3
-------------------
RowKey: s1:1111111
=&gt; (column=param1, value=value1
=&gt; (column=param2, value=value2
=&gt; (column=param3, value=value3
</code></pre>

<p>I want to get all the rows which first component of row key is ""s1"". Is it possible using Hector client? if not then by which cassandra client its possible?</p>

<p>I've tried by using following code, but its not working,</p>

<pre><code>Composite start = new Composite();
        start.addComponent(0, ""s1"", ComponentEquality.EQUAL);

        Composite end = new Composite();
        end.addComponent(0, ""s1"", ComponentEquality.GREATER_THAN_EQUAL);

        RangeSlicesQuery&lt;Composite, String, String&gt; rangeSlicesQuery = HFactory.createRangeSlicesQuery(keyspace, new CompositeSerializer(), StringSerializer.get(),  StringSerializer.get()); 
        rangeSlicesQuery.setKeys(start, end);
        rangeSlicesQuery.setRange(""param1"", ""param3"", false, 100);
        rangeSlicesQuery.setColumnFamily(""CompositeTest"");
        rangeSlicesQuery.setRowCount(11);
        QueryResult&lt;OrderedRows&lt;Composite, String, String&gt;&gt;  queryResult = rangeSlicesQuery.execute();

        Rows&lt;Composite, String, String&gt; rows = queryResult.get();
        Iterator&lt;Row&lt;Composite, String, String&gt;&gt; rowsIterator = rows.iterator();
</code></pre>

<p>Thanks in advance...</p>
",<java><jakarta-ee><cassandra><hector>,"<p>The problem is you are trying to perform a slice on the row keys. 
It is not possible at all if you are using in Cassandra  a random partitioner (e.g RandomPartitioner or Murmur3Partitioner).  It could be possible (but I've never tried) if you are using a order preserving partitioner. In you case should be a CompositeKeyPartitioner that unlucky doesn't exist and thus you should have to write it by yourself. Then you should also configure the cluster by calculating the right tokens in according with your data. 
As you can see, it is not the easiest way. </p>

<p>BUT, you can do the same, if you just put the composite value in the Column name instead of the key. 
You can define you CF in such way:</p>

<pre><code>create column family CompositeTest
   with comparator = 'CompositeType(UTF8Type,UTF8Type)'
   and key_validation_class = 'UTF8Type'
   and default_validation_class = 'UTF8Type';
</code></pre>

<p>And store the data like:</p>

<pre><code>RowKey: s2
=&gt; (column=2222222:param1, value=value1
=&gt; (column=2222222:param2, value=value2
=&gt; (column=2222222:param3, value=value3
=&gt; (column=3333333:param1, value=value1
=&gt; (column=3333333:param2, value=value2
=&gt; (column=3333333:param3, value=value3
=&gt; (column=1111111:param1, value=value1
=&gt; (column=1111111:param2, value=value2
=&gt; (column=1111111:param3, value=value3
-------------------
RowKey: s1:
=&gt; (column=3333333:param1, value=value1
=&gt; (column=3333333:param2, value=value2
=&gt; (column=3333333:param3, value=value3
=&gt; (column=2222222:param1, value=value1
=&gt; (column=2222222:param2, value=value2
=&gt; (column=2222222:param3, value=value3
=&gt; (column=1111111:param1, value=value1
=&gt; (column=1111111:param2, value=value2
=&gt; (column=1111111:param3, value=value3
</code></pre>

<p>With this structure the query you thought it's quite easy, and then you can always slice on the column name to select only those columns inside the interval you want.</p>
",['partitioner']
19663884,19666901,2013-10-29 16:25:11,Error trying to connect using Astyanax to Cassandra hosted on a EC2 instance,"<p>I am getting the following error ""astyanax.connectionpool.exceptions.PoolTimeoutException:"" when trying to use client Astyanax  to connect to Cassandra on a EC2 instance. Need help</p>

<pre><code>Following is my code snippet.
   import org.mortbay.jetty.servlet.Context;

  import com.netflix.astyanax.AstyanaxContext;
  import com.netflix.astyanax.Keyspace;
  import com.netflix.astyanax.MutationBatch;
  import com.netflix.astyanax.connectionpool.NodeDiscoveryType;
  import com.netflix.astyanax.connectionpool.OperationResult;
  import com.netflix.astyanax.connectionpool.exceptions.ConnectionException;
  import com.netflix.astyanax.connectionpool.impl.ConnectionPoolConfigurationImpl;
  import com.netflix.astyanax.connectionpool.impl.ConnectionPoolType;
  import com.netflix.astyanax.connectionpool.impl.CountingConnectionPoolMonitor;
  import com.netflix.astyanax.impl.AstyanaxConfigurationImpl;
  import com.netflix.astyanax.model.Column;
  import com.netflix.astyanax.model.ColumnFamily;
  import com.netflix.astyanax.model.ColumnList;
  import com.netflix.astyanax.model.CqlResult;
  import com.netflix.astyanax.serializers.StringSerializer;
  import com.netflix.astyanax.thrift.ThriftFamilyFactory;


  public class MetadataRS {


    public static void main(String args[]){
    AstyanaxContext&lt;Keyspace&gt; context = new AstyanaxContext.Builder()
    .forCluster(""ClusterName"")
    .forKeyspace(""KeyspaceName"")
    .withAstyanaxConfiguration(new AstyanaxConfigurationImpl()   
        .setDiscoveryType(NodeDiscoveryType.RING_DESCRIBE)
        .setConnectionPoolType(ConnectionPoolType.ROUND_ROBIN)
    )
    .withConnectionPoolConfiguration(new     ConnectionPoolConfigurationImpl(""MyConnectionPool"")
        .setPort(9042)
        .setMaxConnsPerHost(40)
        .setSeeds(""&lt;EC2-IP&gt;:9042"")
        .setConnectTimeout(5000)
    )
    .withConnectionPoolMonitor(new CountingConnectionPoolMonitor())
    .buildKeyspace(ThriftFamilyFactory.getInstance());

    context.start();
    Keyspace keyspace = context.getEntity();
    System.out.println(keyspace);

    ColumnFamily&lt;String, String&gt; CF_USER_INFO =
              new ColumnFamily&lt;String, String&gt;(
                ""Standard1"",              // Column Family Name
                StringSerializer.get(),   // Key Serializer
                StringSerializer.get());  // Column 

    OperationResult&lt;ColumnList&lt;String&gt;&gt; result = null;
    try {
        result = keyspace.prepareQuery(CF_USER_INFO)
            .getKey(""user_id_hash"")
            .execute();
    } catch (ConnectionException e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
    }
            ColumnList&lt;String&gt; columns = result.getResult();

            // Lookup columns in response by name 

            String uid   = columns.getColumnByName(""user_id_hash"").getStringValue();

            System.out.println(uid);
            // Or, iterate through the columns
            for (Column&lt;String&gt; c : result.getResult()) {
              System.out.println(c.getName());
            }
 }
 }
</code></pre>

<p>Error
    com.netflix.astyanax.thrift.ThriftKeyspaceImpl@1961f4
    com.netflix.astyanax.connectionpool.exceptions.PoolTimeoutException: PoolTimeoutException: [host=():9042, latency=5001(5001), attempts=1] Timed out waiting for connection
        at com.netflix.astyanax.connectionpool.impl.SimpleHostConnectionPool.waitForConnection(SimpleHostConnectionPool.java:201)
        at com.netflix.astyanax.connectionpool.impl.SimpleHostConnectionPool.borrowConnection(SimpleHostConnectionPool.java:158)
        at com.netflix.astyanax.connectionpool.impl.RoundRobinExecuteWithFailover.borrowConnection(RoundRobinExecuteWithFailover.java:60)
        at com.netflix.astyanax.connectionpool.impl.AbstractExecuteWithFailoverImpl.tryOperation(AbstractExecuteWithFailoverImpl.java:50)
        at com.netflix.astyanax.connectionpool.impl.AbstractHostPartitionConnectionPool.executeWithFailover(AbstractHostPartitionConnectionPool.java:229)
        at com.netflix.astyanax.thrift.ThriftColumnFamilyQueryImpl$1.execute(ThriftColumnFamilyQueryImpl.java:180)
        at com.rjil.jiodrive.rs.MetadataRS.main(MetadataRS.java:57)
    Exception in thread ""main"" java.lang.NullPointerException
        at com.rjil.jiodrive.rs.MetadataRS.main(MetadataRS.java:62)</p>
",<amazon-ec2><cassandra><astyanax>,"<p>Since you are running cassandra on EC2 instance, check that the cassandra's port no. (which you have choosen as 9042) is in the allowed list of ec2 security group and that you have access to it. If not add the port no. in the inbound list of the ec2 security group and set the ip ranges as 0.0.0.0.
Alos check the firewall on the ec2 is turned off. By default its false, but its good to check it anyway.</p>

<p>If you have done this, then your client might be behind a firewall that prevents outbound traffic to your choosen port (9042).</p>

<p>Lastly if you have not used any elastic ip, its better to use the ec2 instance dns name, both in your setSeeds section and in the rpc_address of cassandra.yaml</p>
",['rpc_address']
19722075,19722566,2013-11-01 06:47:43,How to generate tokens for my two node Cassandra cluster?,"<p>I am trying to setup two node Cassandra Cluster on windows machine. I have basically two windows machine and I was following this datastax <a href=""http://www.datastax.com/2012/01/how-to-setup-and-monitor-a-multi-node-cassandra-cluster-on-windows"" rel=""nofollow"">tutorial</a></p>

<p>Whenever I use the below command to get the token number from the above tutorial -</p>

<pre><code>python -c ""num=2; print """"\n"""".join([(""""token %d: %d"""" %(i,(i*(2**127)/num))) for i in range(0,num)])""
</code></pre>

<p>I always get this error - </p>

<pre><code>C:\Users\username&gt;python -c ""num=2; print """"\n"""".join([(""""token %d: %d"""" %(i,(i*(2**127)/num))) for i
in range(0,num)])""
  File ""&lt;string&gt;"", line 1
    num=2; print ""\n"".join([(""token %d: %d"" %(i,(i*(2**127)/num))) for i in range(0,num)])
                    ^
SyntaxError: invalid syntax
</code></pre>
",<python><cassandra><datastax-enterprise><opscenter>,"<p>You might have better luck putting that command into an actual Python script.
Here is a similar Python script that I use (saved as newCluster.py):</p>

<pre><code>import sys

if (len(sys.argv) &gt; 1):
        num=int(sys.argv[1])
else:
        num=int(raw_input(""How many nodes are in your cluster? ""))
for i in range(0, num):
        print 'node %d: %d' % (i, (i*(2**127)/num))
</code></pre>

<p>When I run that for two nodes, I get:</p>

<pre><code>How many nodes are in your cluster? 2
node 0: 0
node 1: 85070591730234615865843651857942052864
</code></pre>

<p>Here is exactly how I edit and run it:</p>

<p><img src=""https://i.stack.imgur.com/v421c.jpg"" alt=""enter image description here""></p>

<p>Which version of Python are you using?  I have tested this script in 2.6.7 and 2.7.3.</p>

<p>Also to be balanced, your initial_token values for a two node cluster simply need to have a difference of 85,070,591,730,234,615,865,843,651,857,942,052,864.  They don't necessarily have to be 0 and 85070591730234615865843651857942052864; although those two values should work just fine.</p>
",['initial_token']
19940513,20001792,2013-11-12 21:43:45,Hash value from keys on Cassandra,"<p>I'm developing a mechanism for Cassandra using Hector. 
What I need at this moment is to know which are the hash values of the keys to look at which node is stored (looking at the tokens of each one), and ask directly this node for the value. What I understood is that depending on the partitioner Cassandra uses, the values are stored independently from one partitioner to other. So, are the hash values of all keys stored in any table? In case not, how could I implement a generic class that once I read from System Keyspace the partitioner that is using Cassandra this class could be an instance of it without the necessity of modifying the code depending on the partitioner? I would need it to call the getToken method to calculate the hash value for a given key.</p>
",<hash><cassandra><key><hector><partitioner>,"<p>Finally after testing different implementations I found the way to get the partitioner using the next code:</p>

<pre><code>            CqlQuery&lt;String, String, String&gt; cqlQuery = new CqlQuery&lt;String, String, String&gt;(
            ksp, StringSerializer.get(), StringSerializer.get(),   StringSerializer.get());
            cqlQuery.setQuery(""select partitioner from local"");
            QueryResult&lt;CqlRows&lt;String, String, String&gt;&gt; result = cqlQuery.execute();
            CqlRows rows = result.get();
            for (int i = 0; i &lt; rows.getCount(); i++) {
                RowImpl&lt;String, String, String&gt; row = (RowImpl&lt;String, String, String&gt;) rows
                .getList().get(i);
                List&lt;HColumn&lt;String, String&gt;&gt; column = row.getColumnSlice().getColumns();
                for (HColumn&lt;String , String&gt; c: column) {
                    System.out.println(c.getValue());
            }

    } 
</code></pre>
",['partitioner']
19992430,20012429,2013-11-15 02:28:45,Bring back a dead datacenter: repair or rebuild,"<p>I had Cassandra cluster running across two data centers, for some reason, one data center was taken down for a while, and now I'm planning to bring it back. I'm thinking about two approaches: 
One is to start up all Cassandra nodes of this data center and run ""nodetool repair "" on each node one by one. But It looks like 'repair' takes long time. I had an experience to repair 6GB data on a node before, it took me 5 hours on one node (3 nodes cluster). I have much more data on the cluster now, can't image how long it will take. 
So I'm thinking if I can run re-build instead of repair. I can delete all old data on this data center and re-build it as adding a new data center. But not sure if it works and how performance would be. </p>

<p>Any idea on it? Any suggestion would be appreciated. Thanks in advance. </p>
",<cassandra>,"<p>If the data center was down for more than 10 days then rebuild is the only option. This has to do with the <a href=""http://wiki.apache.org/cassandra/DistributedDeletes"" rel=""nofollow"">tombstones</a>. I am not 100% sure how that works across different data centers, but if you have a server that was down for more than 10 days, any data that has been deleted in the live server has been tombstoned and kept there for 10 days, then removed completely. If all suddenly your downed server wakes up from the sleep, with all deleted data not tombstoned, then it will be repopulated back to the ring via read repair or regular repair operation.</p>

<p>Another thing to consider, is how much data has changed/deleted since the datacenter went down. If a lot, then it obviously it is less work to rebuild. If not then maybe repair will be faster.</p>

<p>You can create another datacenter, add nodes to it with <code>auto_bootstrap: false</code> and then run <code>nodetool rebuild &lt;live dc name&gt;</code></p>

<p>Good luck!</p>
",['dc']
20219934,20220872,2013-11-26 14:34:08,I can't start Cassandra Server in Eclipse( Unknown Commitlog version 4),"<p>I'm trying to run Cassandra in eclipse, but I'm getting this exception</p>

<pre><code>java.lang.IllegalStateException: Unknown commitlog version 4Exception encountered during startup: Unknown commitlog version 4

at org.apache.cassandra.db.commitlog.CommitLogDescriptor.getMessagingVersion(CommitLogDescriptor.java:81)
at org.apache.cassandra.db.commitlog.CommitLogReplayer.recover(CommitLogReplayer.java:118)
at org.apache.cassandra.db.commitlog.CommitLogReplayer.recover(CommitLogReplayer.java:93)
at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:146)
at org.apache.cassandra.db.commitlog.CommitLog.recover(CommitLog.java:126)
at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:305)
at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:461)
at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:504)
</code></pre>

<p>What am I doing wrong?</p>
",<eclipse><cassandra>,"<p>Sounds like a version mismatch - possibly from downgrading Cassandra[?]</p>

<p>What version of Cassandra are you using in eclipse? Also, did you have another version running <em>and sharing the same commitlogs</em>? It is likely you have commitlogs from one version of cassandra being read from another. (That was my experience.)</p>

<p>Adding the solution, as provided by @LyubenTodorov in the comments:</p>

<blockquote>
  <p>To solve this either change your commitlog_directory or empty your current commitlog dir (default is /var/lib/cassandra/commitlog) </p>
</blockquote>
",['commitlog_directory']
20502001,20552508,2013-12-10 18:05:40,How much load can cassandra handle on m1.xlarge instance?,"<p>I setup 3 nodes of Cassandra (1.2.10) cluster on 3 instances of EC2 m1.xlarge. </p>

<p>Based on default configuration with several guidelines included, like:</p>

<ul>
<li>datastax_clustering_ami_2.4</li>
<li>not using EBS, raided 0 xfs on ephemerals instead,</li>
<li>commit logs on separate disk,</li>
<li>RF=3,</li>
<li>6GB heap, 200MB new size (also tested with greater new size/heap values),</li>
<li>enhanced limits.conf.</li>
</ul>

<p>With <strong>500 writes per second</strong>, the cluster works only for couple of hours. After that time it seems like not being able to respond because of CPU overload (mainly GC + compactions).</p>

<p>Nodes remain Up, but their load is huge and logs are full of GC infos and messages like:</p>

<pre><code>ERROR [Native-Transport-Requests:186] 2013-12-10 18:38:12,412 ErrorMessage.java (line 210) Unexpected exception during request java.io.IOException: Broken pipe
</code></pre>

<p>nodetool shows many dropped mutations on each node:</p>

<pre><code>Message type           Dropped
RANGE_SLICE                  0
READ_REPAIR                  7
BINARY                       0
READ                         2
MUTATION               4072827
_TRACE                       0
REQUEST_RESPONSE          1769
</code></pre>

<p>Is 500 wps too much for 3-node cluster of m1.xlarge and I should add nodes? Or is it possible to further tune GC somehow? <strong>What load are you able to serve with 3 nodes of m1.xlarge? What are your GC configs?</strong></p>
",<amazon-ec2><garbage-collection><cassandra>,"<p>Cassandra is perfectly able to handle <em>tens of thousands</em> small writes per second on a single node. I just checked on my <em>laptop</em> and got about 29000 writes/second from cassandra-stress on Cassandra 1.2. So 500 writes per second is not really an impressive number even for a single node. </p>

<p>However beware that there is also a limit on how fast data can be flushed to disk and you definitely don't want your incoming data rate to be close to the physical capabilities of your HDDs. Therefore 500 writes per second can be too much, if those writes are big enough.</p>

<p>So first - what is the average size of the write? What is your replication factor? Multiply number of writes by replication factor and by average write size - then you'll approximately know what is required write throughput of a cluster. But you should take some safety margin for other I/O related tasks like compaction. There are various benchmarks on the Internet telling a single m1.xlarge instance should be able to write anywhere between 20 MB/s to 100 MB/s...</p>

<p>If your cluster has sufficient I/O throughput (e.g. 3x more than needed), yet you observe OOM problems, you should try to:</p>

<ol>
<li>reduce memtable_total_space_mb (this will cause C* to flush smaller memtables, more often, freeing heap earlier)</li>
<li>lower write_request_timeout to e.g. 2 seconds instead of 10 (if you have big writes, you don't want to keep too many of them in the incoming queues, which reside on the heap)</li>
<li>turn off row_cache (if you ever enabled it)</li>
<li>lower size of the key_cache</li>
<li>consider upgrading to Cassandra 2.0, which moved quite a lot of things off-heap (e.g. bloom filters and index-summaries); this is especially important if you just store lots of data per node</li>
<li>add more HDDs and set multiple data directories, to improve flush performance</li>
<li>set larger new generation size; I usually set it to about 800M for a 6 GB heap, to avoid pressure on the tenured gen. </li>
<li>if you're sure memtable flushing lags behind, make sure sstable compression is enabled - this will reduce amount of data physically saved to disk, at the cost of additional CPU cycles</li>
</ol>
",['write_request_timeout']
20643515,20645781,2013-12-17 19:59:36,Cassandra not balancing data over existing nodes in cluster,"<p>Greeings,
I have configured 3 node Cassandra 1.2.12 cluster and I am able to connect to master and create keyspaces and tables over all nodes. However, I want to run YCSB over my cluster so when I run YCSB and load data it is all loaded on Master. Since I am loading 1000000 records I calculated initial tokens by dividing that number by number of nodes I have.
When I run nodetool I get something like:</p>

<pre><code>Address    Rack    Status    State    Load    Owns    Token
10.3.2.8   2       Up        Normal   1.08GB  100%    0
10.3.1.231 2       Up        Normal   67.58KB  0%     330000
10.3.1.128 2       Up        Normal   52.79KB  0%     660000
</code></pre>

<p>Did someone had same problem? I have tried using tokengentool to assign tokes and diffrenet partitions (Murmur3 and Random) and it was all same, just loading all data on Master node.</p>

<p>Regards, Veronika.</p>
",<cassandra><data-partitioning><ycsb>,"<p>A ""row"" does not equal a token in Cassandra.  Regardless of the number of rows you intend to store, Cassandra's RandomPartitioner supports 2^127 tokens.  For a 3-node cluster, those initial tokens should be increments of 56,713,727,820,156,410,577,229,101,238,628,035,242 apart from each other.</p>

<p>Using DataStax's Python script for computing initial tokens, these RandomPartitioner values should work for you:</p>

<pre><code>node 0: 0
node 1: 56713727820156410577229101238628035242
node 2: 113427455640312821154458202477256070485
</code></pre>

<p>If you are using the Murmur3 Partitioner (-2^63 to +2^63 tokens), use these values:</p>

<pre><code>node 0: -9223372036854775808
node 1: -3074457345618258603
node 2: 3074457345618258602
</code></pre>

<p>So at this point, you have two choices:</p>

<p>1 - Decommission 10.3.1.231 and 10.3.1.128, stop the nodes, alter their initial_token values to match what I have above, and restart them.  But given the fact that you have mentioned trying both the Murmur3 and RandomPartitioner, I'm thinking that it might be best for your to go with option #2 below.</p>

<p>2 - Stop all nodes, delete your data, <a href=""http://www.datastax.com/documentation/cassandra/1.2/webhelp/index.html#cassandra/initialize/initializeSingleDS.html"" rel=""nofollow"">follow these instructions</a>, and reload your data.</p>

<p>Also, you may want to adjust the replication factor you defined for your keyspace(s).  For a 3-node cluster, you will want a replication factor of at least 2.  This will ensure that if one server goes down, you will still have one copy of the data out there.  And that should still allow your application to resolve (as long as your read/write consistency is set to ONE).</p>
",['initial_token']
20646598,24172932,2013-12-17 23:12:37,Token Aware Astyanax Connection pool connecting on nodes without distributing connections over nodes,"<p>I was using astyanax connection pool defined as this:</p>

<pre><code>ipSeeds = ""LOAD_BALANCER_HOST:9160"";
conPool.setSeeds(ipSeeds)
.setDiscoveryType(NodeDiscoveryType.TOKEN_AWARE)
.setConnectionPoolType(ConnectionPoolType.TOKEN_AWARE);
</code></pre>

<p>However, my cluster have 4 nodes and I have 8 client machines connecting on it. <code>LOAD_BALANCER_HOST</code> forwards requests to one of my four nodes.</p>

<p>On a client node, I have:</p>

<pre><code>$netstat -an | grep 9160 | awk '{print $5}' | sort |uniq -c
    235 node1:9160
    680 node2:9160
      4 node3:9160
      4 node4:9160
</code></pre>

<p>So although the ConnectionPoolType is <code>TOKEN_AWARE</code>, my client seems to be connecting mainly to node2, sometimes to node1, but almost never to nodes 3 and 4.<br>
Question is: 
Why is this happening? Shouldn't a token aware connection pool query the ring for the node list and connect to all the active nodes using round robin algorithm?</p>
",<cassandra><astyanax><amazon-elb><cassandra-2.0>,"<p><code>William Price</code> is totally right: the fact you're using a <code>TokenAwarePolicy</code> and possibly a default <code>Partitioner</code> means that
- first your data will be stored biased across your nodes and
- then on querying the <code>LoadbalancingPolicy</code> makes your driver remember the correct nodes to ask for</p>

<p>You can improve your cluster's performance by using some deviating or may be a custom partitioner to equally distribute your data. To randomly query nodes use either </p>

<ul>
<li><code>RoundRobinPolicy</code> (<a href=""http://www.datastax.com/doc-source/developer/java-apidocs/com/datastax/driver/core/policies/RoundRobinPolicy.html"" rel=""nofollow"">http://www.datastax.com/doc-source/developer/java-apidocs/com/datastax/driver/core/policies/RoundRobinPolicy.html</a>) or </li>
<li><code>DatacenterAwareRoundRobinPolicy</code> (<a href=""http://www.datastax.com/doc-source/developer/java-apidocs/com/datastax/driver/core/policies/DCAwareRoundRobinPolicy.html"" rel=""nofollow"">http://www.datastax.com/doc-source/developer/java-apidocs/com/datastax/driver/core/policies/DCAwareRoundRobinPolicy.html</a>).</li>
</ul>

<p>The latter, of course, needs the definition of data centers in your keyspace.</p>

<p>Without any further information I would suggest to just change the partitioner as a TokenAware load balancing policy is usually a good idea. The main load will end up on these nodes in the end -- the TokenAware policy get's you to the right coordinator just quicker.</p>
",['partitioner']
21384856,21390188,2014-01-27 15:32:21,Cassandra Partial Replication,"<p>This is my configuration for 4 Data Centers of Cassandra: </p>

<pre><code>create KEYSPACE mySpace WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1' : 1, 'DC2' : 1, 'DC3' : 1, 'DC4' : 1};
</code></pre>

<p>In this configuration (Murmur3Partitioner + 256 tokens) , each DC is storing roughly 25% of the key space. And this 25% are replicated 3 times on each other DC. Meaning that every single row has 4 copies over all. </p>

<p>For instance if my data base is to big to keep 4 complete copies of it, how can I configure cassandra so that each DC is replicated only once or twice (instead of total number of DCs (x3)).</p>

<p>For example: 25% of the key space that is stored on DC1 I want to replicate once on DC2 only. I am not looking for selecting any particular DC for replication neither I care if 25% of DC1 will be split over multiple DC1,2,3 I just want to use NetworkTopologyStrategy but reduce storage costs.</p>

<p>Is it possible ?</p>

<p>Thank you
Best Regards</p>
",<cassandra><replication>,"<p>Your keyspace command shows that each of the DCs hold 1 copy of the data. This means that if you have 1 node in each DC, then each node will have 100% of your data. So, I am not sure how you concluded that each of your DCs store only 25% of keys as it is obvious they are storing 100%. Chances are when you run nodetool command you are not specifying the keyspace so the command shows you load which is based on the token range assigned to each node which would be misleading for NetworkTopology setup. Try running it with your keyspace name and see if you notice the difference.</p>

<p>I don't think there is a way to shift data around DCs using any of existing Snitches the way you want it. If you really wanted to have even distribution and you had equal number of nodes in each DC with initial tokens spaced evenly, you could have used SimpleSnitch to achieve what you want. You can change the Snitch to SimpleSnitch and run nodetool cleanup/repair on each node. Bare in mind that during this process you will have some outage because after the SnitchChange, previously written keys may not be available on some nodes until the repair job is done.</p>

<p>The way NetworkTopology works is that if you say you have DC1:1 and you have for example 2 nodes in DC1, it will evenly distribute keys across 2 nodes leading to 50% effective load on each node. With that in mind, I think what you really want to have done is to keep 3 copies of your data, 1 in each DC. So, you can really discard one DC and save money. I am saying this because I think these DCs you have are virtual in the notion of your NetworkTopology and not real physical DC because no one would want to have only 25% of data in one DC as it will not be an available setup. So, I recommend if your nodes are grouped into virtual DCs, you group them into 4 racks instead and maintain 1 DC:</p>

<pre>
DC1:
nd1-ra_1 rack-a
nd1-rb_1 rack-b
nd1-rc_1 rack-c

nd2-ra_2 rack-a
nd2-rb_2 rack-b
nd2-rc_2 rack-c

nd3-ra_3 rack-a
nd3-rb_3 rack-b
nd3-rc_3 rack-c

nd3-ra_4 rack-a
nd3-rb_4 rack-b
nd3-rc_4 rack-c
</pre>

<p>In this case, if you set your replication option to DC1:3, each of the racks a,b,and c will have 100% of your data (each node in each rack 25%).</p>
",['rack']
22006887,22007669,2014-02-25 06:59:28,cassandra - Saved cluster name Test Cluster != configured name,"<p>How am I supposed to bot a new Cassandra node when I get this error?</p>

<pre><code>INFO [SSTableBatchOpen:1] 2014-02-25 01:51:17,132 SSTableReader.java (line 223) Opening /var/lib/cassandra/data/system/local/system-local-jb-5 (5725 bytes)
ERROR [main] 2014-02-25 01:51:17,377 CassandraDaemon.java (line 237) Fatal exception during initialization
org.apache.cassandra.exceptions.ConfigurationException: Saved cluster name Test Cluster != configured name thisisstupid
        at org.apache.cassandra.db.SystemKeyspace.checkHealth(SystemKeyspace.java:542)
        at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:233)
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:462)
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:552)
</code></pre>

<p>Name of cluster in the cassandra.yaml file is:</p>

<pre><code>cluster_name: 'thisisstupid'
</code></pre>

<p>How do I resolve?</p>
",<cassandra>,"<p>You can rename the cluster without deleting data by updating it's name in the system.local table (but you have to do this <strong>for each node</strong>...)</p>

<pre><code>cqlsh&gt; UPDATE system.local SET cluster_name = 'test' where key='local';
# flush the sstables to persist the update.
bash $ ./nodetool flush
</code></pre>

<p>Finally you need to rename the cluster to the new name in cassandra.yaml (again <strong>on each node</strong>)</p>
",['cluster_name']
22294555,22302497,2014-03-10 07:40:33,Cassandra rack concept and database structure,"<p>I am new to Cassandra and I would like to learn more about Cassandra's racks and structure.</p>

<p>Suppose I have around 70 column families in Cassandra and two AWS2 instances.</p>

<ol>
<li>How many Data Centres will be used?</li>
<li>How many nodes will each rack have?</li>
<li>Is it possible to divide a column family in multiple keyspaces?</li>
</ol>
",<cassandra><nosql><cassandra-cli>,"<p>The intent of making Cassandra aware of logical racks and data centers is to provide additional levels of fault tolerance.  The idea (<a href=""http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureDataDistributeReplication_c.html"" rel=""noreferrer"">as described in this document</a>, under the ""Network Topology Strategy"") is that the application should still be able to function if one rack or data center goes dark.  Essentially, Cassandra...</p>

<blockquote>
  <p>places replicas in the same data center by walking the ring clockwise
  until reaching the first node in another rack. NetworkTopologyStrategy
  attempts to place replicas on distinct racks because nodes in the same
  rack (or similar physical grouping) often fail at the same time due to
  power, cooling, or network issues.</p>
</blockquote>

<p>In this way, you can also query your data by LOCAL_QUORUM, in which QUORUM ((replication_factor / 2) + 1) is only computed from the nodes present in the same data center as the coordinator node.  This reduces the effects of inter-data center latency.</p>

<p>As for your questions:</p>

<ol>
<li><p>How many data centers are used are entirely up to you.  If you only have two AWS instances, putting them in different logical data centers is possible, but only makes sense if you are planning to use consistency level ONE.  As-in, if one instance goes down, your application only needs to worry about finding one other replica.  But even then, the <a href=""http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureSnitchesAbout_c.html"" rel=""noreferrer"">snitch</a> can only find data on one instance, or the other.</p></li>
<li><p>Again, you can define the number of nodes that you wish to have for each rack.  But as I indicated with #1, if you only have two instances, there isn't much to be gained by splitting them into different data centers or racks.</p></li>
<li><p>I do not believe it is possible to divide a column family over multiple keyspaces.  But I think I know what you're getting at.  Each keyspace will be created on each instance.  As you have 2 instances, you will be able to specify a replication factor of 1 or 2.  If you had 3 instances, you could set a replication factor of 2, and then if you lost 1 instance you would still have access to all the data.  As you only have 2 instances, you need to be able to handle one going dark, so you will want to make sure both instances have a copy of every row (replication factor of 2).</p></li>
</ol>

<p>Really, the logical datacenter/rack structure becomes more-useful as the number of nodes in your cluster increases.  With only two, there is little to be gained by splitting them with additional logical barriers.  For more information, read through the two docs I linked above:</p>

<p><a href=""http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureDataDistributeReplication_c.html"" rel=""noreferrer"">Apache Cassandra 2.0: Data Replication</a></p>

<p><a href=""http://www.datastax.com/documentation/cassandra/2.0/cassandra/architecture/architectureSnitchesAbout_c.html"" rel=""noreferrer"">Apache Cassandra 2.0: Snitches</a></p>
",['rack']
22871775,22873075,2014-04-04 19:44:46,How to check vnode disabled on a hadoop node,"<p>Linking back to this question:
<a href=""https://stackoverflow.com/questions/19969329/why-not-enable-virtual-node-in-an-hadoop-node/19974621#19974621"">Why not enable virtual node in an Hadoop node?</a></p>

<p>I'm running a mixed 3 node cluster with 2 cassandra and 1 analytics nodes and disabled the virtual nodes by generating 3 tokens with the utility given by DataStax enterprise.
But when I run 'nodetool status' command, I still see 256 tokens with each node and when a mapreduce job is created, it creates 257 mappers and takes a very long time to execute a query with small data.
So my specific questions are:</p>

<ol>
<li><p>Is virtual node setting still not disabled? How can I verify if its disabled?</p></li>
<li><p>If its disabled then why 257 mappers are still created for each job? Is there a different configuration for that?</p></li>
</ol>

<p>Thanks much for any help!!</p>
",<hadoop><cassandra><datastax-enterprise>,"<p>1) It's not disabled. You can tell because it still says 256 tokens in nodetool status. </p>

<p>To disable vnodes you need to make sure that you change the num_tokens variable in the cassandra.yamnl</p>

<pre><code># If you already have a cluster with 1 token per node, and wish to migrate to 
# multiple tokens per node, see http://wiki.apache.org/cassandra/Operations
# num_tokens: 256  &lt;&lt; Make sure this line is commented out

# initial_token allows you to specify tokens manually.  While you can use it with
# vnodes (num_tokens &gt; 1, above) -- in which case you should provide a 
# comma-separated list -- it's primarily used when adding nodes to legacy clusters 
# that do not have vnodes enabled.
initial_token:  &lt;&lt; Your generated token goes here
</code></pre>
","['num_tokens', 'initial_token']"
23145435,23358506,2014-04-18 00:03:32,Cassandra multiple disk per node setup,"<p><strong>Intro</strong></p>

<p>I have a cassandra 1.2 cluster, all the nodes have SSDs. Now I want to add more disks to the existing nodes, but I want to be able to choose which tables are stored on different disks.</p>

<p><strong>Problem</strong></p>

<p>For example, node 1 will have 3 SSDs and 1 regular disk drive and I want all the column families except 1 (let's call it ""discord"" table) to be stored on the SSDs only, the final table ""discord"" needs to be stored on the regular disk.</p>

<p>According to the documentation this should be possible; however, the only way of doing it that I can see is:</p>

<ol>
<li>Setting up Cassandra to use multiple <code>data_files_directories</code> in <code>cassandra.yaml</code>.</li>
<li>Creating the tables.</li>
<li>Creating a link from the data directory on each SSD to the directory on the hard disk where I want to store the column family.</li>
</ol>

<p><strong>Question</strong></p>

<p>Is this the only way of doing it? Or there is a simpler way of configuring a node to work in this way?</p>
",<cassandra><storage><database><nosql>,"<p>You can set multiples files using the data_file_directories property, but the data is distributed over the folders internally by Cassandra. You can not take decisions on which keyspace or column family goes to each directory.</p>

<p>So the symbolic links is the way to go in my opinion.</p>
",['data_file_directories']
23294298,23296128,2014-04-25 13:16:39,Replication in cassandra,"<p>How does replication work in Cassandra? If I have 3 racks and 3 RF with <code>NetworkTopologyStratagy</code> then will the data be replicated to all the 3 racks? </p>

<p>How exactly will data be replicated across the cluster? I ask because we are designing our cluster to cater for the worst case scenario that 2 of 3 racks go down, and we don't want to lose data.</p>

<p>We have only one datacenter with 3 racks.</p>

<p>If I use:</p>

<pre><code>CREATE KEYSPACE ""myKeyspaceName""
WITH REPLICATION = {'class' : 'NetworkTopologyStrategy', 'DC1' : 3  }
</code></pre>

<p>Will this replicate to all three racks?</p>
",<cassandra><cassandra-2.0>,"<p>In the Cassandra 1.0 docs, they have an article that explains this pretty well: <a href=""http://www.datastax.com/docs/1.0/cluster_architecture/replication"" rel=""noreferrer"">About Replication in Cassandra</a>.</p>

<p>I'll assume that you have two (logical?) datacenters.  Let's say that you have two racks in one DC and the last rack in another, and on each RACK you have 2 nodes.  You'll have these defined in your topology file to look something like this:</p>

<pre><code>server1IP=DC1:RACK1
server2IP=DC1:RACK1
server3IP=DC2:RACK1
server4IP=DC2:RACK1
server5IP=DC2:RACK2
server6IP=DC2:RACK2
</code></pre>

<p>If you want to have 3 copies of the data out there (one for each logical rack) then you'll define your keyspace to use the NetworkTopologyStrategy, with replications settings for each DC, like this:</p>

<pre><code>CREATE KEYSPACE ""myKeyspaceName""
WITH REPLICATION = {'class' : 'NetworkTopologyStrategy', 'DC1' : 1, 'DC2' : 2};
</code></pre>

<p>The PropertyFile snitch is also ""rack aware,"" so when a write occurs it will make sure that one copy of the data is on a node in <code>RACK1</code> in <code>DC1</code>, and one copy is on each <code>RACK</code> in <code>DC2</code>.  Based on what you are saying, it might make sense to have three logical datacenters, each with one rack.</p>

<p>You should also have a look at <a href=""http://www.datastax.com/docs/1.0/cluster_architecture/cluster_planning"" rel=""noreferrer"">this doc in the ""Choosing Keyspace Replication Options"" section</a> that further explains how to configure replication.</p>

<p>EDIT:</p>

<blockquote>
  <p>If I use the CREATE KEYSPACE ""myKeyspaceName"" WITH REPLICATION =
  {'class' : 'NetworkTopologyStrategy', replicationfactor: 3 }. Will
  this replicate to all the three racks?</p>
</blockquote>

<p>I'm not sure.  But every example I'm finding about defining a keyspace's replication strategy using NetworkTopologyStrategy with only one DC, specifically names the DC instead of stating ""replicationfactor.""  Even the doc I linked states:</p>

<blockquote>
  <p>NetworkTopologyStrategy takes as options the number of replicas you
  want per data center. Even for single data center (or single node)
  clusters, you can use this replica placement strategy and just define
  the number of replicas for one data center.</p>
</blockquote>

<p>So assuming that you name your DC <code>DC1</code>, it would look like this:</p>

<pre><code>CREATE KEYSPACE ""myKeyspaceName""
WITH REPLICATION = {'class' : 'NetworkTopologyStrategy', 'DC1' : 3}
</code></pre>

<p>If you did that, and had your three racks defined underneath that DC, this will replicate one copy to all three racks.</p>
",['rack']
23685240,23704345,2014-05-15 17:45:01,Hadoop timing out trying to write to Cassandra in AWS multi-region configuration,"<p>I am running a multi-DC Cassandra (open-source, not DSE) cluster in AWS, where one DC (us-west-2) is set up for analytics and the other (us-east) is the transactional store.  I'm using NetworkTopologyStrategy with the EC2 snitch, and a consistency level of LOCAL_ONE in my Hadoop config.  Hadoop <strong>can read from Cassandra without issue</strong>, but <strong>attempting to write produces a timeout exception</strong>.</p>

<p>Running <code>nodetool status</code> shows the DCs are properly configured:</p>

<pre><code>Datacenter: us-west-2
=====================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address         Load       Owns   Host ID                               Token                                    Rack
UN  x.x.x.x       1.01 GB     9.9%   9e7f4393-7ac9-4559-b3ff-de48be50016f  -9127921345534057723                     2a
UN  x.x.x.x       1001.16 MB  11.4%  d0760383-c3dd-474c-9261-239b71dba3f1  -9221279003374097975                     2b
UN  x.x.x.x       1.05 GB     11.7%  3f09fbf5-0d85-4283-9009-0ec0e29223c0  -9140104347498952504                     2c
Datacenter: us-east
===================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address         Load       Owns   Host ID                               Token                                    Rack
UN  x.x.x.x       1.1 GB     11.3%  5bbd2de4-e1d2-4a17-9f40-034f60b35954  -9061054426204373981                     1b
UN  x.x.x.x       1.15 GB    11.5%  e34c590e-6176-45b2-a8f9-18b4a9a80032  -9216519687724118609                     1c
UN  x.x.x.x       1.18 GB    10.9%  fa0b0a1a-f156-40fc-a267-970d1eb9cddb  -9207673937991303291                     1a
UN  x.x.x.x       1.46 GB    10.7%  b18ae406-c9ec-42b7-a365-b0c6e2fe582f  -9206671929961171506                     1a
UN  x.x.x.x       1.13 GB    11.4%  1ac9c1c5-55ad-4048-b1ba-3b9768933ecc  -9146100851344467112                     1c
UN  x.x.x.x       1.53 GB    11.2%  dad665bb-68d9-4811-b421-f33333261867  -9178920986366339267                     1b
</code></pre>

<p>Stack trace using ColumnFamilyOutputFormat:</p>

<pre><code>java.io.IOException: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection timed out
    at org.apache.cassandra.hadoop.ColumnFamilyRecordWriter$RangeClient.run(ColumnFamilyRecordWriter.java:224)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection timed out
    at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
    at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
    at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
    at org.apache.cassandra.hadoop.AbstractColumnFamilyOutputFormat.createAuthenticatedClient(AbstractColumnFamilyOutputFormat.java:123)
    at org.apache.cassandra.hadoop.ColumnFamilyRecordWriter$RangeClient.run(ColumnFamilyRecordWriter.java:215)
Caused by: java.net.ConnectException: Connection timed out
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
    at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
    at java.net.Socket.connect(Socket.java:579)
    at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
    ... 4 more
</code></pre>

<p>... and using CqlOutputFormat:</p>

<pre><code>java.io.IOException: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection timed out
    at org.apache.cassandra.hadoop.cql3.CqlRecordWriter$RangeClient.run(CqlRecordWriter.java:271)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection timed out
    at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
    at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
    at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
    at org.apache.cassandra.hadoop.AbstractColumnFamilyOutputFormat.createAuthenticatedClient(AbstractColumnFamilyOutputFormat.java:123)
    at org.apache.cassandra.hadoop.cql3.CqlRecordWriter$RangeClient.run(CqlRecordWriter.java:262)
Caused by: java.net.ConnectException: Connection timed out
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
    at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
    at java.net.Socket.connect(Socket.java:579)
    at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
    ... 4 more
</code></pre>

<p>Both traces ultimately point to <code>AbstractColumnFamilyOutputFormat.createAuthenticatedClient(host, port, conf)</code>.</p>

<p>I then opened that source and added some detail to the exception so it would output the host name it's connecting to, which resulted in this trace:</p>

<pre><code>java.io.IOException: java.lang.Exception: Unable to connect to host [hostname]
    at org.apache.cassandra.hadoop.cql3.CqlRecordWriter$RangeClient.run(CqlRecordWriter.java:271)
Caused by: java.lang.Exception: Unable to connect to host [hostname]
    at org.apache.cassandra.hadoop.AbstractColumnFamilyOutputFormat.createAuthenticatedClient(AbstractColumnFamilyOutputFormat.java:139)
    at org.apache.cassandra.hadoop.cql3.CqlRecordWriter$RangeClient.run(CqlRecordWriter.java:262)
Caused by: org.apache.thrift.transport.TTransportException: java.net.ConnectException: Connection timed out
    at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
    at org.apache.thrift.transport.TFramedTransport.open(TFramedTransport.java:81)
    at org.apache.cassandra.thrift.TFramedTransportFactory.openTransport(TFramedTransportFactory.java:41)
    at org.apache.cassandra.hadoop.AbstractColumnFamilyOutputFormat.createAuthenticatedClient(AbstractColumnFamilyOutputFormat.java:124)
    ... 1 more
Caused by: java.net.ConnectException: Connection timed out
    at java.net.PlainSocketImpl.socketConnect(Native Method)
    at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)
    at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)
    at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)
    at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
    at java.net.Socket.connect(Socket.java:579)
    at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
    ... 4 more
</code></pre>

<p><strong>The problem is [hostname] is a machine that's not in the analytics cluster (it's in us-east)</strong>.  Why doesn't it know this automagically, especially when reads work properly?  It seems like it's trying all the nodes in the ring regardless of DC.</p>

<p>For the record, writes fail using <code>CqlOutputFormat</code>, <code>ColumnFamilyOutputFormat</code>, and through Pig using <code>CqlStorage</code> and <code>CassandraStorage</code>.</p>
",<hadoop><amazon-web-services><amazon-ec2><cassandra>,"<p>This issue came down to two things:</p>

<ol>
<li><p>For multi-region EC2 setups, Cassandra requires setting broadcast_address to the public IP and the listen_address to the internal IP.  In most cases you'll want rpc_address to be the internal IP, but this potentially breaks Cassandra's Hadoop client, which is determining endpoints to talk to based on broadcast_address.</p></li>
<li><p>Cassandra's Hadoop client (RingCache specifically) doesn't respect data center on node discovery, and tries to discover all nodes in the ring--including non-local ones.  It respects the consistency level on the actual write, but in our case it never got there due to #1.</p></li>
</ol>

<p>I filed a ticket and submitted a patch to address these issues:</p>

<p><a href=""https://issues.apache.org/jira/browse/CASSANDRA-7252"" rel=""nofollow"">https://issues.apache.org/jira/browse/CASSANDRA-7252</a></p>
","['listen_address', 'broadcast_address', 'rpc_address']"
23798563,24134844,2014-05-22 05:35:53,Unable to connect to remote cassandra from titan,"<p>I am using cassandra 2.0.7 sitting on a remote server listening on non-default port </p>

<pre><code>&lt;code&gt;
---cassandra.yaml
rpc_address: 0.0.0.0
rpc_port: 6543
&lt;/code&gt;
</code></pre>

<p>I am trying to connect to the server using titan-0.4.4 (java API, also tried with rexster) using the following config:</p>

<pre><code>&lt;code&gt;
storage.hostname=172.182.183.215
storage.backend=cassandra
storage.port=6543
storage.keyspace=abccorp
&lt;/code&gt;
</code></pre>

<p>It does not connect and I see the the following exceptions below. However, if I use cqlsh on the same host from where I am trying to execute my code/rexster, I am able to connect without any issues. Anybody seen this?</p>

<pre><code>&lt;code&gt;
0    [main] INFO  com.netflix.astyanax.connectionpool.impl.ConnectionPoolMBeanManager  - Registering mbean: com.netflix.MonitoredResources:type=ASTYANAX,name=ClusterTitanConnectionPool,ServiceType=connectionpool
49   [main] INFO  com.netflix.astyanax.connectionpool.impl.CountingConnectionPoolMonitor  - AddHost: 172.182.183.215
554  [main] INFO  com.netflix.astyanax.connectionpool.impl.ConnectionPoolMBeanManager  - Registering mbean: com.netflix.MonitoredResources:type=ASTYANAX,name=KeyspaceTitanConnectionPool,ServiceType=connectionpool
555  [main] INFO  com.netflix.astyanax.connectionpool.impl.CountingConnectionPoolMonitor  - AddHost: 172.182.183.215
999  [main] INFO  com.netflix.astyanax.connectionpool.impl.CountingConnectionPoolMonitor  - AddHost: 127.0.0.1
1000 [main] INFO  com.netflix.astyanax.connectionpool.impl.CountingConnectionPoolMonitor  - RemoveHost: 172.182.183.215
2366 [main] INFO  com.thinkaurelius.titan.diskstorage.Backend  - Initiated backend operations thread pool of size 16
41523 [RingDescribeAutoDiscovery] WARN  com.netflix.astyanax.impl.RingDescribeHostSupplier  - Failed to get hosts from abccorp via ring describe.  Will use previously known ring instead
61522 [RingDescribeAutoDiscovery] WARN  com.netflix.astyanax.impl.RingDescribeHostSupplier  - Failed to get hosts from abccorp via ring describe.  Will use previously known ring instead
63080 [main] INFO  com.thinkaurelius.titan.diskstorage.util.BackendOperation  - Temporary storage exception during backend operation. Attempting backoff retry
com.thinkaurelius.titan.diskstorage.TemporaryStorageException: Temporary failure in storage backend
    at com.thinkaurelius.titan.diskstorage.cassandra.astyanax.AstyanaxOrderedKeyColumnValueStore.getNamesSlice(AstyanaxOrderedKeyColumnValueStore.java:138)
    at com.thinkaurelius.titan.diskstorage.cassandra.astyanax.AstyanaxOrderedKeyColumnValueStore.getSlice(AstyanaxOrderedKeyColumnValueStore.java:88)
    at com.thinkaurelius.titan.graphdb.configuration.KCVSConfiguration$1.call(KCVSConfiguration.java:70)
    at com.thinkaurelius.titan.graphdb.configuration.KCVSConfiguration$1.call(KCVSConfiguration.java:64)
    at com.thinkaurelius.titan.diskstorage.util.BackendOperation.execute(BackendOperation.java:30)
    at com.thinkaurelius.titan.graphdb.configuration.KCVSConfiguration.getConfigurationProperty(KCVSConfiguration.java:64)
    at com.thinkaurelius.titan.diskstorage.Backend.initialize(Backend.java:277)
    at com.thinkaurelius.titan.graphdb.configuration.GraphDatabaseConfiguration.getBackend(GraphDatabaseConfiguration.java:1174)
    at com.thinkaurelius.titan.graphdb.database.StandardTitanGraph.&lt;init&gt;(StandardTitanGraph.java:75)
    at com.thinkaurelius.titan.core.TitanFactory.open(TitanFactory.java:40)
    at com.thinkaurelius.titan.core.TitanFactory.open(TitanFactory.java:29)
    at com.abccorp.grp.graphorm.GraphORM.&lt;init&gt;(GraphORM.java:23)
    at com.abccorp.grp.graphorm.GraphORM.getInstance(GraphORM.java:47)
    at com.abccorp.grp.utils.dataloader.MainLoader.main(MainLoader.java:150)
Caused by: com.netflix.astyanax.connectionpool.exceptions.NoAvailableHostsException: NoAvailableHostsException: [host=None(0.0.0.0):0, latency=0(0), attempts=0]No hosts to borrow from
    at com.netflix.astyanax.connectionpool.impl.RoundRobinExecuteWithFailover.&lt;init&gt;(RoundRobinExecuteWithFailover.java:30)
    at com.netflix.astyanax.connectionpool.impl.TokenAwareConnectionPoolImpl.newExecuteWithFailover(TokenAwareConnectionPoolImpl.java:83)
    at com.netflix.astyanax.connectionpool.impl.AbstractHostPartitionConnectionPool.executeWithFailover(AbstractHostPartitionConnectionPool.java:256)
    at com.netflix.astyanax.thrift.ThriftColumnFamilyQueryImpl$4.execute(ThriftColumnFamilyQueryImpl.java:519)
    at com.thinkaurelius.titan.diskstorage.cassandra.astyanax.AstyanaxOrderedKeyColumnValueStore.getNamesSlice(AstyanaxOrderedKeyColumnValueStore.java:136)
    ... 13 more
91522 [RingDescribeAutoDiscovery] WARN  com.netflix.astyanax.impl.RingDescribeHostSupplier  - Failed to get hosts from abccorp via ring describe.  Will use previously known ring instead
121522 [RingDescribeAutoDiscovery] WARN  com.netflix.astyanax.impl.RingDescribeHostSupplier  - Failed to get hosts from abccorp via ring describe.  Will use previously known ring instead
&lt;/code&gt;
</code></pre>

<p>Any help greatly appreciated. I am evaluating titan on cassandra and am a bit stuck on this as previously I was using cassandra (same version) on localhost and everything was fine.</p>

<p>thanks</p>
",<java><cassandra><titan>,"<p>Changing the listen_address to 172.182.183.215 in the configuration had done the trick. Initially it was not clear if just setting the rpc_address was enough.</p>
","['listen_address', 'rpc_address']"
24012641,24046196,2014-06-03 10:20:18,Cassandra CLUSTERING ORDER BY not doing what I'd expect,"<p>I'm pretty new to Cassandra, I have created a table like so:</p>

<pre><code>CREATE TABLE IF NOT EXISTS notifications (
  id uuid,
  raised timeuuid,
  recorded timeuuid,
  customer varchar,
  region varchar,
  location varchar,
  operator varchar,
  till varchar,
  receipt_id varchar,
  value decimal,
  details text,
  is_refund boolean,
  has_promos boolean,
  utc_offset int,
  frame_count int,
  expecting_video boolean,
  PRIMARY KEY (id, raised)
) WITH CLUSTERING ORDER BY (raised desc);
</code></pre>

<p>And then inserted 1,000 rows from the DataStax .NET Cassandra adapter like so:</p>

<pre><code>for (var i = 0; i &lt; 1000; i++)
{
                    var id = Guid.NewGuid();
                    var now = DateTime.Now;

                    var insertNotif = session.Prepare(@""
                    INSERT INTO notifications 
                    (id,customer,region,location,operator,till,receipt_id,value,details,is_refund,has_promos,raised,recorded,utc_offset,frame_count,expecting_video)
                    VALUES (?,?,?,?,?,?,?,?,?,?,?,now(),now(),?,?,?)"");
                    var insertNotifStatement = insertNotif.Bind(id, ""cust1"", ""reg1"", ""loc1"", ""tomm"", ""london"", i.ToString(), i % 10.99D, ""DATA_HERE"", false, true, (int)TimeZone.CurrentTimeZone.GetUtcOffset(now).TotalMinutes, 0, false);

                    session.Execute(insertNotifStatement);
                    Thread.Sleep(10);
}
</code></pre>

<p>What I'd expect to happen is that all the records will be stored in time descending order based on the <code>raised</code> column. When I use CQLSH to inspect the data, it appears to be in a random order:</p>

<pre><code>cqlsh:my_keyspace&gt; select dateOf(raised) from notifications limit 5;

 dateOf(raised)
--------------------------------------
 2014-06-03 11:12:45GMT Daylight Time
 2014-06-03 11:12:48GMT Daylight Time
 2014-06-03 11:12:56GMT Daylight Time
 2014-06-03 11:12:32GMT Daylight Time
 2014-06-03 11:12:34GMT Daylight Time

(5 rows)
</code></pre>

<p>Have I done something wrong?
BTW, I have also tried to set <code>raised</code> to a timestamp column and expected the same behaviour (but I passed in DateTimes from .NET instead of now()), but it behaves in the exact same way.</p>

<p>How can I get my records <strong>store and retrieved</strong> in time descending order?</p>
",<database><cassandra><cql><cql3><cqlsh>,"<p>The clustering order refers to the ordering within the partition i.e. for the same ID. So if you inserted multiple rows with different <code>raised</code> values and queried, you would see them returned in descending order.</p>

<p>The order you are seeing is the order of IDs. As you observed, these are essentially random. This order is the partitioner order i.e. ordered by the hash of the ID.</p>

<p>You can't change this order, so you can't read all your partitions back in time order. You can only order within each partition. </p>
",['partitioner']
24219953,24223191,2014-06-14 12:33:58,cassandra - only superuser is allowed to perform CREATE USER queries,"<p>I'm logging in with on Ubuntu 14.10 on Cassandra 2.0.8 with Java 1.7.0_60-b19</p>

<pre><code>cqlsh -u cassandra -p cassandra
</code></pre>

<p>I'm running:</p>

<pre><code>CREATE USER a WITH PASSWORD 'a' NOSUPERUSER;
</code></pre>

<p>I'm getting the error:</p>

<pre><code>Bad Request: Only superusers are allowed to perform CREATE USER queries
</code></pre>

<p>The problem with reasoning - I am logged in as the superuser. </p>

<p>My question is: <strong>If I'm logged into cqlsh as the Cassandra user, why am I told that I'm not the superuser?</strong></p>
",<cassandra><cql><cqlsh>,"<p>You need to enable PasswordAuthenticator in cassandra.yaml file.
To enable PasswordAuthenticator you need to change authenticator property in cassandra.yaml</p>

<p>Change</p>

<pre><code>authenticator: AllowAllAuthenticator
</code></pre>

<p>to </p>

<pre><code>authenticator: PasswordAuthenticator
</code></pre>

<p>After that login with following command and then you will be able to add new user</p>

<pre><code>cqlsh -u cassandra -p cassandra
</code></pre>
",['authenticator']
24684457,24774099,2014-07-10 19:09:24,data auditing in Cassandra,"<p>How to implement auditing for cassandra data?
I am looking for a open source option.</p>

<p>Are there any features of cassandra that help with auditing?
Can I use triggers to log the records into a table? I followed <a href=""https://github.com/apache/cassandra/tree/trunk/examples/triggers"" rel=""nofollow noreferrer"">Triggers</a> example and was able to get a record inserted into <code>triggers_log</code> table when the updates occur on another table.
But not sure how do I capture the <code>user/session</code> details that triggered the update. I have From <code>CQLSH</code> terminal, create <code>users</code> and <code>trigger_log table</code></p>

<pre>
create table AUDIT_LOG ( 
       transaction_id int,
       entries map&lt;text, text&gt;,  --> to capture the modifications done to the tables
       user varchar,  //authenticated user
       time timestamp, 
       primary key(transaction_id));
</pre>

<pre>
CREATE TABLE users (
  user_id int PRIMARY KEY,
  fname text,
  lname text
);
</pre>

<p>Define the trigger on users table using <code>CREATE TRIGGER</code> syntax from <code>cqlsh</code></p>

<p>Below code so far. </p>

<pre class=""lang-java prettyprint-override""><code>public class AuditTrigger implements ITrigger {

    @Override
    public Collection&lt;RowMutation&gt; augment(ByteBuffer key, ColumnFamily update) {

        List&lt;RowMutation&gt; mutations = new ArrayList&lt;RowMutation&gt;();
        for (Column column : update) {
            if (column.value().remaining() &gt; 0) {
                RowMutation mutation = new RowMutation(""mykeyspace"", key);
           //What do I need here to capture the updates to users 
           //table and log the updates into various columns of audit_log
                mutations.add(mutation);
            }
        }
        return mutations;
    }
}
</code></pre>

<p>If triggers is not the correct approach (any spring AOP approach?), please suggest alternatives. I also tried <a href=""https://stackoverflow.com/questions/9604554/cassandra-vs-logging-activity"">Cassandra vs logging activity</a> solution but it does not print the sql executed, authenticated user information.</p>
",<cassandra><cassandra-2.0>,"<p>Unfortunately at this time, Triggers cannot be used as what you need is the ClientState which contains the user information and is not passed to Triggers.</p>

<p>There are 2 approaches I can think of.(You will need to look at the Cassandra code base for better understanding these approaches)</p>

<p>One approach is AOP i.e to add an agent which would AOP and start Cassandra with the Agent. The class that will need to be pointcut is the QueryProcessor#processStatement method. The call to this method will have the prepared statement and the QueryState as parameters. From the PreparedStatement you can identify the intention of the user. QueryState.getClientState will return the ClientState which is where the user information resides.</p>

<p>The other approach involves custom authenticators and authorizers. Configuring this in Cassandra is described here.</p>

<p><a href=""http://www.datastax.com/documentation/cassandra/2.0/cassandra/security/secure_about_native_authenticate_c.html"" rel=""noreferrer"">http://www.datastax.com/documentation/cassandra/2.0/cassandra/security/secure_about_native_authenticate_c.html</a></p>

<p>You can have a custom authorizer extending the AllowAllAuthorizer(this will disable permission caching). Whenever you get an authorize request on the Authorizer you can log it. The downside of this approach is that you do not know what the user intends to do with the table, only that he is request some authorization on it. Permission is the one which contains what he wants to do with the table, but it is not passed on to the authorizer.</p>

<p>If you decide on either of these approaches, you are free to post followups if you need more detail.</p>
",['authorizer']
25098083,25112097,2014-08-02 18:21:02,nodetool repair across replicas of data center,"<p>Just want to understand the performance of 'nodetool repair' in a multi data center setup with Cassandra 2.</p>

<p>We are planning to have keyspaces with 2-4 replicas in each data center. We may have several tens of data centers. Writes are done with LOCAL_QUORUM/EACH_QUORUM consistency depending on the situation and reads are usually done with LOCAL_QUORUM consistency. Questions:</p>

<ol>
<li><p>Does nodetool repair complexity grow linearly with number of replicas across all data centers?</p></li>
<li><p>Or does nodetool repair complexity grow linearly with a combination of number of replicas in the current data center, and number of data centers? Vaguely, this model could possibly sync data with each of the individual nodes in current data center, but at EACH_QUORUM-like operation against replicas in other data centers.</p></li>
<li><p>To scale the cluster, is it better to add more nodes in an existing data center or add a new data center assuming constant number of replicas as a whole? I ask this question in the context of nodetool repair performance.</p></li>
</ol>
",<cassandra><cassandra-2.0><repair><nodetool>,"<p>To understand how nodetool repair affects the cluster or how the cluster size affects repair, we need to understand what happens during repair. There are two phases to repair, the first of which is building a Merkle tree of the data. The second is having the replicas actually compare the differences between their trees and then streaming them to each other as needed. </p>

<p>This first phase can be intensive on disk io since it will touch almost all data on the disk on the node on which you run the repair. One simple way to avoid repair touching the full disk is to use the -pr flag. When using -pr, it will disksize/RF instead of disksize data that repair has to touch. Running repair on a node also sends a message to all nodes that store replicas of any of these ranges to build merkle trees as well. This can be a problem, since all the replicas will be doing it at the same time, possibly making them all slow to respond for that portion of your data. </p>

<p>The factor which determines how the repair operation affects other data centers is the use of the replica placement strategy. Since you are going to need consistency across data centers (EACH_QOURUM cases) it is imperative that you use a cross-dc replication strategy like the Network Topology strategy in your case. For repair this will mean that you cannot limit yourself to local dc while running the repair since you have some EACH_QUORUM consistency cases. To avoid a repair affecting all replicas in all data centers, you should a) Wrap your replication strategy using Dynamic snitch and configure the badness threshold properly b) Use -snapshot option while running the repair.
What this will do is take a snapshot of your data (snapshots are just hardlinks to existing sstables, exploiting the fact that sstables are immutable, thus making snapshots extremely cheap) and sequentially repair from the snapshot. This means that for any given replica set, only one replica at a time will be performing the validation compaction, allowing the dynamic snitch to maintain performance for your application via the other replicas.</p>

<p>Now we can answer the questions you have.</p>

<ol>
<li><p>Does nodetool repair complexity grow linearly with number of replicas across all data centers?
You can limit this by wrapping your replication strategy with Dynamic snitch  and pass -snapshot option during repair.</p></li>
<li><p>Or does nodetool repair complexity grow linearly with a combination of number of replicas in the current data center, and number of data centers? Vaguely, this model could possibly sync data with each of the individual nodes in current data center, but at EACH_QUORUM-like operation against replicas in other data centers.
The complexity will grow in terms of running time with the number of replicas if you use the approach above. This is because the above approach will do a sequential repair on one replica at a time.</p></li>
<li><p>To scale the cluster, is it better to add more nodes in an existing data center or add a new data center assuming constant number of replicas as a whole? I ask this question in the context of nodetool repair performance.
From nodetool repair perspective IMO, this does not make any difference if you take the above approach. Since it depends on the overall number of replicas.</p></li>
</ol>

<p>Also, the goal of repair using nodetool is so that deletes do not come back. The hard requirement for routine repair frequency is the value of gc_grace_seconds. In systems that seldom delete or overwrite data, you can raise the value of gc_grace with minimal impact to disk space. This allows wider intervals for scheduling repair operations with the nodetool utility. One of the recommended ways to avoid frequent repairs is to have immutability of records by design. This may be important to you since you need to run on a tens of data centers and ops will otherwise already be painful.</p>
",['dc']
25306785,25309968,2014-08-14 11:19:06,"How to reset Cassandra superuser, when Cassandra does not know 'cassandra' default user?","<p>How to reset default Cassandra credentials without changing source code?</p>

<p>I have check similar problems like <a href=""https://stackoverflow.com/questions/18398987/how-to-reset-a-lost-cassandra-admin-users-password"">How to reset a lost Cassandra admin user&#39;s password?</a>.
 I have three node cluster of Datastax Cassandra 2.0.8 and I am trying to implement authentication. I have set cassandra.yaml in all nodes and restarted them. Problem is that I still cannot login in to cqlsh.</p>

<p>I have also tried to reset password for cassandra user in cqlsh(I have disabled authentication for that):</p>

<pre><code>update system_auth.credentials set salted_hash='$2a$10$vbfmLdkQdUz3Rmw.fF7Ygu6GuphqHndpJKTvElqAciUJ4SZ3pwquu' where username='cassandra';
</code></pre>

<p>In logs there is Info about creating cassandra superuser. I have checked keyspace system_auth and it includes credentials,permissions and users. And credentials column family does contain user cassandra:</p>

<pre><code>cqlsh&gt; use system_auth;
cqlsh:system_auth&gt; select * from credentials;

 username  | options | salted_hash
-----------+---------+----------------------------------------------------------                                ----
 cassandra |    null | $2a$10$vbfmLdkQdUz3Rmw.fF7Ygu6GuphqHndpJKTvElqAciUJ4SZ3pw                                quu

(1 rows)
</code></pre>

<p>But still, when I try:</p>

<pre><code>./cqlsh -u cassandra -p cassandra
</code></pre>

<p>I get exception, that user does not exists, but I dont have permissions to create one.</p>

<pre><code>cql.cassandra.ttypes.AuthenticationException: AuthenticationException(why=""User cassandra doesn't exist - create it with CREATE USER query first"")
</code></pre>
",<authentication><cassandra>,"<p>I don't know for sure, but there's a good chance that the hash you used above changes with each version, and may be particular to a specific version of Cassandra.  With that in-mind, you could (in-theory) install the same version in a VM, and then query that machine's <code>system_auth.credentials</code> for the cassandra user's <code>salted_hash</code>.  Had it not been for the question you linked above, I never would have thought to try that.</p>

<p>Otherwise, this next option <strong>WILL</strong> work.</p>

<ol>
<li>Stop your Cassandra cluster.</li>
<li><p>On each node, <code>cd</code> down to your <code>data</code> directory, and execute: </p>

<p><code>$ mv system_auth system_auth_20140814</code></p></li>
<li><p>Restart each node.</p></li>
</ol>

<p>As long as the authenticator is still set (in your cassandra.yaml) to use the <code>PasswordAuthenticator</code>, Cassandra will rebuild the <code>system_auth</code> keyspace, with the default Cassandra super user, which you can use with <code>cqlsh</code> to get back in.</p>

<pre><code>$ ./cqlsh -u cassandra -p cassandra
Connected to MyCluster at 127.0.0.1:9042.
[cqlsh 5.0.1 | Cassandra 2.1.0-rc5-SNAPSHOT | CQL spec 3.2.0 | Native protocol v3]
Use HELP for help.
cqlsh&gt;
</code></pre>

<p>Notes:</p>

<ul>
<li>You will have to re-add all of your users, and re-apply all off their permissions.</li>
<li>Instead of renaming (<code>mv</code>) the <code>system_auth</code> directory, you could also just delete it (<code>rm</code>).</li>
<li>You will have to re-apply the appropriate replication settings to your <code>system_auth</code> keyspace.  By default, <code>system_auth</code> only has a replication factor of 1.</li>
</ul>
",['authenticator']
25346597,25353520,2014-08-17 05:42:01,Which Cassandra partitioner is better: Random or Murmur3 (in terms of throughput) and what is the difference between them?,"<p>What difference the choice of partitioners could bring in my Cassandra throughput and latency? I have gone through all three partitioners and one thing I noticed is that <code>ByteOrdered</code> partitioner has overhead so I do not use it. Now I am a bit split between <code>Random</code> and <code>Murmur3</code> partitioners.</p>
",<cassandra>,"<p>The main difference between the two, is in how each generates the token hash values.  The Random partitioner used the JDK native MD5 hash (because it was both convenient for the developers and standard across all JDKs).  But since Cassandra really doesn't need a cryptographic hash, that function took much longer than it needed to.</p>

<p>With the Murmur3 partitioner, the token hashing does only what Cassandra needs it to do.  Which, is to generate a token ensuring even distribution across the nodes.  This results in an improvement of 3 to 5 times in token hashing performance, which untimately translates into the overall 10% gain that Carlo mentioned above.</p>

<p>It should also be noted that DataStax warns that the partitioners are not compatible.  Which means, that once you start with one partitioner, you cannot (easily) convert to the other.  Therefore, I would pick the newer, slightly faster Murmur3 partitioner.</p>
",['partitioner']
26708594,26717954,2014-11-03 05:56:43,Problems In Cassandra ByteOrderedPartitioner in Cluster Environment,"<p>I am using cassandra 1.2.15 with ByteOrderedPartitioner in a cluster environment of 4 nodes with 2 replicas. I want to know what are the drawbacks of using the above partitioner in cluster environment? After a long search I found one drawback. I need to know what are the consequences of such drawback?</p>

<pre><code>1) Data will not distribute evenly. 
   What type of problem will occur if data are not distributed evenly?
</code></pre>

<p>Is there is any other drawback with the above partitioner in cluster environment if so, what are the consequences of such drawbacks? Please explain me clearly.</p>

<p>One more question is, Suppose If I go with Murmur3Partitioner the data will distribute evenly. But the order will not be preserved, however this drawback can be overcome with cluster ordering (Second key in the primary keys). Whether my understanding is correct?</p>
",<cassandra><nosql>,"<p>As you are using Cassandra 1.2.15, I have found a doc pertaining to Cassandra 1.2 which illustrates the points behind why using the ByteOrderedPartitioner (BOP) is a bad idea:</p>

<p><a href=""http://www.datastax.com/documentation/cassandra/1.2/cassandra/architecture/architecturePartitionerBOP_c.html"" rel=""nofollow noreferrer"">http://www.datastax.com/documentation/cassandra/1.2/cassandra/architecture/architecturePartitionerBOP_c.html</a></p>

<blockquote>
  <ul>
  <li><p><strong>Difficult load balancing</strong> More administrative overhead is required to    load balance the cluster. An ordered partitioner
  requires    administrators to manually calculate partition ranges
  (formerly token    ranges) based on their estimates of the row key
  distribution. In    practice, this requires actively moving node
  tokens around to    accommodate the actual distribution of data once
  it is loaded.</p></li>
  <li><p><strong>Sequential writes can cause hot spots</strong> If your application tends to    write or update a sequential block of rows at a time, then the
  writes    are not be distributed across the cluster; they all go to
  one node.    This is frequently a problem for applications dealing
  with    timestamped data. </p></li>
  <li><p><strong>Uneven load balancing for multiple tables</strong> If your    application has multiple tables, chances are that those tables have different row keys and different distributions of data. An ordered<br>
  partitioner that is balanced for one table may cause hot spots and uneven distribution for another table in the same cluster.</p></li>
  </ul>
</blockquote>

<p>For these reasons, the BOP has been identified as a <a href=""http://www.datastax.com/documentation/cassandra/1.2/cassandra/architecture/architecturePlanningAntiPatterns_c.html"" rel=""nofollow noreferrer"">Cassandra anti-pattern</a>.  Matt Dennis has a <a href=""http://www.slideshare.net/mattdennis"" rel=""nofollow noreferrer"">slideshare presentation on Cassandra Anti-Patterns</a>, and his slide about the BOP looks like this:</p>

<p><img src=""https://i.stack.imgur.com/49jZR.jpg"" alt=""OPP/BOP""></p>

<p>So seriously, do not use the BOP.</p>

<p>""however this drawback can be overcome with cluster ordering (Second key in the primary keys). Whether my understanding is correct?""</p>

<p>Somewhat, yes.  In Cassandra you can dictate the order of your rows (within a partition key) by using a clustering key.  If you wanted to keep track of (for example) station-based weather data, your table definition might look something like this:</p>

<pre><code>CREATE TABLE stationreads (
  stationid uuid,
  readingdatetime timestamp,
  temperature double,
  windspeed double,
PRIMARY KEY ((stationid),readingdatetime));
</code></pre>

<p>With this structure, you could query all of the readings for a particular weather station, and order them by <code>readingdatetime</code>.  However, if you queried all of the data (ex: <code>SELECT * FROM stationreads;</code>) the results probably will not be in any discernible order.  That's because the total result set will be ordered by the (random) hashed values of the partition key (stationid in this case).  So while ""yes"" you can order your results in Cassandra, you can only do so within the context of a particular partition key. </p>

<p>Also, there have been many improvements in Cassandra since 1.2.15.  You should definitely consider using a more recent (2.x) version.</p>
",['partitioner']
27088251,27090428,2014-11-23 11:05:35,"After setting authenticator: PasswordAuthenticator in Cassandra.yaml, Cassandra CQL Shell does not run","<p>I'm new in Cassandra. I'm using Datastax Community edition and using only a single node in Windows 7. Trying to change my authentication, set authenticator value from <code>AllowAllAuthenticator</code> to <code>PasswordAuthenticator</code> in Cassandra.yaml. After that setting, it does not let me to run my Cassandra CQL Shell.</p>

<p>Q1. Why this is happening?</p>

<p>Q2. How to overcome it?</p>
",<windows><cassandra><cqlsh>,"<p>How are you accessing cqlsh?  If you have the password authenticator activated, then you will need to specify the default Cassandra super user with the username and password flags.</p>

<p>Linux:</p>

<pre><code>./cqlsh -u cassandra -p cassandra
</code></pre>

<p>In Windows, I'm going to guess that it's something like this:</p>

<pre><code>cqlsh -u cassandra -p cassandra
</code></pre>

<p>Note that once you get in, you'll want to create your own superuser and <a href=""http://www.datastax.com/documentation/cassandra/2.1/cassandra/security/security_config_native_authenticate_t.html"" rel=""nofollow noreferrer"">disable the default cassandra account, as described here</a>.</p>

<p>""I'm accessing cqlsh from START-> Datastax Community Edition-> Cassandra CQL Shell""</p>

<p>I wasn't aware that the Windows version now had a shortcut to cqlsh.  Try modifying that shortcut's target (<a href=""https://superuser.com/questions/358565/adding-command-line-switches-to-windows-shortcuts"">as shown here</a>), and add <code>-u cassandra -p cassandra</code> to the end.  I was able to get this to work by installing and modifying my shortcut's ""target"" property to this:</p>

<pre><code>""E:\Program Files\DataStax Community\python\python.exe"" ""e:\Program Files\DataStax Community\apache-cassandra\bin\cqlsh"" -u cassandra -p cassandra
</code></pre>

<p>Basically, put the <code>-u</code> and <code>-p</code> flags <em>outside</em> of the double quotes, and it should work.</p>
",['authenticator']
27939234,27944273,2015-01-14 09:11:15,Cassandra ByteOrderedPartitioner,"<p>I want to execute some range queries on a table that is structured like:</p>

<pre><code>CREATE TABLE table(

num int,
val1 int,
val2 float,
val3 text,
...
PRIMARY KEY(num)
)
</code></pre>

<p>A range query should look like:</p>

<pre><code>SELECT num, val1, val2 FROM table WHERE num&gt;100 AND num&lt;1000;
</code></pre>

<p>I read ths post: <a href=""https://stackoverflow.com/questions/24919732/performing-range-queries-for-cassandra-table"">Performing range queries for cassandra table</a> and now I have problems with using the ByteOrderedPartitoner. </p>

<p>I use the OPSCenter Web Interface and try to create a new cluster. I change the Partitioner and the following error appears:</p>

<p>Error provisioning cluster: A token_map argument of the form {ip: token} is required when not using RandomPartitioner or Murmur3Partitioner</p>

<p>I can not find a token_map argument. What am I doing wrong? What else do I have to do to enable the query?</p>

<p>I hope somebody can help me. Thank you!</p>
",<cassandra><cql>,"<blockquote>
  <p>What am I doing wrong?</p>
</blockquote>

<p>You are using the Byte Ordered Partitioner.  Its use has been identified as a Cassandra anti-pattern...for a while now. Matt Dennis has a <a href=""http://www.slideshare.net/mattdennis"" rel=""noreferrer"">slideshare presentation on Cassandra Anti-Patterns</a>, and it contains a slide concerning the BOP:
<img src=""https://i.stack.imgur.com/wOJyk.jpg"" alt=""Don&#39;t use the Byte Ordered Partitioner""></p>

<p>So while the above slide is meant to be humorous, seriously, do not use the Byte Ordered Partitioner.  It is still included with Cassanra, so that those who used it back in 2011 have an upgrade path.  <strong>No new clusters should be built with the BOP.</strong>  The (default) Murmur3 partitioner is what you should use.</p>

<p>As for how to solve your problem with the Murmur3 partitioner, the question/answer you linked above refers to Patrick McFadin's article on <a href=""http://planetcassandra.org/blog/post/getting-started-with-time-series-data-modeling/"" rel=""noreferrer"">Getting Started With Time Series Data Modeling</a>.  In that article, there are three modeling patterns demonstrated.  They should be able to help you come up with an appropriate data model.  Basically, you can order your data with a clustering key and then read it with a range query...just not by your <em>current</em> partitioning key.</p>

<pre><code>CREATE TABLE tableorderedbynum(
 num int,
 val1 int,
 val2 float,
 val3 text,
 someotherkey text,
...
PRIMARY KEY((someotherkey),num)
);
</code></pre>

<p>Examine your data model, and see if you can find another key to help partition your data.  Then, if you create a query table (like I have above) using the other key as your partitioning key, and num as your clustering key; then this range query will work:</p>

<pre><code>SELECT num, val1, val2 
FROM tableorderedbynum WHERE someotherkey='yourvalue' AND num&gt;100 AND num&lt;1000;
</code></pre>
",['partitioner']
29087090,29087407,2015-03-16 21:17:41,Connecting to Cassandra with Spark,"<p>First, I have bought the new O'Reilly Spark book and tried those Cassandra setup instructions. I've also found other stackoverflow posts and various posts and guides over the web. None of them work as-is. Below is as far as I could get.</p>

<p>This is a test with only a handful of records of dummy test data. I am running the most recent Cassandra 2.0.7 Virtual Box VM provided by plasetcassandra.org linked from the main Cassandra project page.</p>

<p>I downloaded Spark 1.2.1 source and got the latest Cassandra Connector code from github and built both against Scala 2.11. I have JDK 1.8.0_40 and Scala 2.11.6 setup on Mac OS 10.10.2.</p>

<p>I run the spark shell with the cassandra connector loaded:</p>

<pre><code>bin/spark-shell --driver-class-path ../spark-cassandra-connector/spark-cassandra-connector/target/scala-2.11/spark-cassandra-connector-assembly-1.2.0-SNAPSHOT.jar
</code></pre>

<p>Then I do what should be a simple row count type test on a test table of four records:</p>

<pre><code>import com.datastax.spark.connector._
sc.stop
val conf = new org.apache.spark.SparkConf(true).set(""spark.cassandra.connection.host"", ""192.168.56.101"")
val sc = new org.apache.spark.SparkContext(conf)
val table = sc.cassandraTable(""mykeyspace"", ""playlists"")
table.count
</code></pre>

<p>I get the following error. What is confusing is that it is getting errors trying to find Cassandra at 127.0.0.1, but it also recognizes the host name that I configured which is 192.168.56.101.</p>

<pre><code>15/03/16 15:56:54 INFO Cluster: New Cassandra host /192.168.56.101:9042 added
15/03/16 15:56:54 INFO CassandraConnector: Connected to Cassandra cluster: Cluster on a Stick
15/03/16 15:56:54 ERROR ServerSideTokenRangeSplitter: Failure while fetching splits from Cassandra
java.io.IOException: Failed to open thrift connection to Cassandra at 127.0.0.1:9160
&lt;snip&gt;
java.io.IOException: Failed to fetch splits of TokenRange(0,0,Set(CassandraNode(/127.0.0.1,/127.0.0.1)),None) from all endpoints: CassandraNode(/127.0.0.1,/127.0.0.1)
</code></pre>

<p>BTW, I can also use a configuration file at conf/spark-defaults.conf to do the above without having to close/recreate a spark context or pass in the --driver-clas-path argument. I ultimately hit the same error though, and the above steps seem easier to communicate in this post.</p>

<p>Any ideas?</p>
",<cassandra><apache-spark><cassandra-2.0>,"<p>Check the rpc_address config in your cassandra.yaml file on your cassandra node.  It's likely that the spark connector is using that value from the system.local/system.peers tables and it may be set to 127.0.0.1 in your cassandra.yaml.</p>

<p>The spark connector uses thrift to get token range splits from cassandra.  Eventually I'm betting this will be replaced as C* 2.1.4 has a new table called system.size_estimates (<a href=""https://issues.apache.org/jira/browse/CASSANDRA-7688"" rel=""nofollow"">CASSANDRA-7688</a>).  It looks like it's getting the host metadata to find the nearest host and then making the query using thrift on port 9160.</p>
",['rpc_address']
29133678,29134982,2015-03-18 22:11:50,"add cassandra node fails with ConfigurationException: For input string: ""None""","<p>I have a dse cluster with 4 nodes already. I am adding the fifth node using opscenter. </p>

<p>I installed datastax-agent on this last node which seems to run properly, then using the opscenter, I proceeded to add the node. It first reports that it is loading new software onto the node, then errors out.</p>

<p>in /var/log/cassandra/system.out I see this error</p>

<p>ERROR [main] 2015-03-18 15:04:27,080 DatabaseDescriptor.java (line 117) Fatal configuration error
org.apache.cassandra.exceptions.ConfigurationException: For input string: ""None""
        at org.apache.cassandra.dht.Murmur3Partitioner$1.validate(Murmur3Partitioner.java:178)
        at org.apache.cassandra.config.DatabaseDescriptor.applyConfig(DatabaseDescriptor.java:447)</p>

<p>I can't find out where this configuration comes from and how to fix it. </p>

<p>Can someone help?</p>
",<cassandra><opscenter>,"<p>Sounds like the Murmur partitioner did not like the token value from your configuration. Exception is thrown out of <a href=""http://grepcode.com/file/repo1.maven.org/maven2/org.apache.cassandra/cassandra-all/2.0.12/org/apache/cassandra/dht/Murmur3Partitioner.java?av=f"" rel=""nofollow"">Murmur3Partitioner.java</a></p>

<pre><code>170       public void validate(String token) throws ConfigurationException
171        {
172            try
173            {
174                Long i = Long.valueOf(token);
175            }
176            catch (NumberFormatException e)
177            {
178                throw new ConfigurationException(e.getMessage());
179            }
180        }
</code></pre>

<p>Check what that value is in your cassandra.yaml. I suspect you should see ""None"" in place for the token value.</p>
",['partitioner']
29502979,29546956,2015-04-07 23:08:53,Backups folder in Opscenter keyspace growing really huge,"<p>We have a 10 node Cassandra cluster. We configured a repair in Opscenter. We find there is a backups folder created for every table in Opscenter keyspace. It keeps growing huge. Is there a solution to this, or do we manually delete the data in each backups folder?</p>
",<cassandra><cql><datastax><datastax-enterprise><opscenter>,"<p>First off, Backups are different from snapshots - you can take a look at the backup <a href=""http://www.datastax.com/2015/03/datastax-opscenter-5-1-real-world-test-simulation-of-visual-backup-and-restore-services"" rel=""nofollow noreferrer"">documentation</a> for OpsCenter to learn more.</p>
<h2>Incremental backups:</h2>
<p>From the datastax <a href=""http://docs.datastax.com/en/cassandra/2.0/cassandra/operations/ops_backup_incremental_t.html"" rel=""nofollow noreferrer"">docs</a> -</p>
<blockquote>
<p>When incremental backups are enabled (disabled by default), Cassandra
hard-links each flushed SSTable to a backups directory under the
keyspace data directory. This allows storing backups offsite without
transferring entire snapshots. Also, incremental backups combine with
snapshots to provide a dependable, up-to-date backup mechanism.
...
As with snapshots, Cassandra does not automatically clear
incremental backup files. DataStax recommends setting up a process to
clear incremental backup hard-links each time a new snapshot is
created.</p>
</blockquote>
<p>You must have turned on incremental backups by setting incremental_backups to true in cassandra yaml.</p>
<p>If you are interested in a backup strategy, I recommend you use <a href=""http://docs.datastax.com/en/opscenter/5.1/opsc/online_help/services/opscBackupCluster.html"" rel=""nofollow noreferrer"">the OpsCenter Backup Service</a> instead. That way, you're able to control granularly which keyspace you want to back up and push your files to S3.</p>
<h2>Snapshots</h2>
<p>Snapshots are hardlinks to old (no longer used) SSTables. Snapshots protect you from yourself. For example you accidentally truncate the wrong keyspace, you'll still have a snapshot for that table that you can bring back. There are some cases when you have too many snapshots, there's a couple of things you can do:</p>
<h3>Don't run Sync repairs</h3>
<p>This is related to repairs because synchronous repairs generate a Snapshot each time they run. In order to avoid this, you should run parallel repairs instead (-par flag or by setting the number of repairs in the opscenter config file note below)</p>
<h3>Clear your snapshots</h3>
<p>If you have too many snapshots and need to free up space (maybe once you have backed them up to S3 or glacier or something) go ahead and use nodetool clearsnapshots to delete them. This will free up space. You can also go in and remove them manually from your file system but nodetool clearsnapshots removes the risk of rm -rf ing the wrong thing.</p>
<p><strong>Note:</strong> You may also be running repairs too fast if you don't have a ton of data (check my response to this <a href=""https://stackoverflow.com/questions/28021344/high-load-on-cassandra-nodes"">other SO question</a> for an explanation and the repair service config levers).</p>
",['incremental_backups']
29583586,29583904,2015-04-11 22:02:38,Is it possible to shut down cassandra cluster and restart it back without loosing data?,"<p>Im running 2 node cassandra cluster on virtual box (one as a seed). I need to shut down the cluster and turn it on again. But when i tried to restart, it is throwing an error ""cannot change the number of tokens from 1 to 256"", even though i dint change any configuration. But i am able to restart it after deleting the data. Is there any way to restart the cluster without removing the data ?</p>
",<cassandra><cluster-computing><datastax>,"<p>You must have changed your cassandra.yaml to include num_tokens to 256 on a cluster that was using single tokens.</p>

<p>Comment out num_tokens and try again.</p>
",['num_tokens']
29589311,29592830,2015-04-12 12:11:15,Prevent UnAuhtorize Node to Join Cassandra Cluster,"<p>I'm using Apache Cassandra 2.1.2 and create 5 nodes cluster.
in <code>cassandra.yaml</code> config file, authorizer &amp; authenticator properties are set to <code>CassandraAuthorizer</code> and <code>PasswordAuthenticator</code>.</p>

<p>It's works prefect but when some of these nodes config file changed to connect without authorization, this node can query all keyspaces and read all secure data easily!</p>

<p>What can do to secure Cassandra keyspaces and data from being accessed from authorized client (node)?</p>
",<cassandra><authorization><cql><cassandra-2.0>,"<p>If you are concerned about config files being reset, you should really consider using configuration management software like <a href=""https://puppetlabs.com/"" rel=""nofollow"">Puppet</a> or <a href=""https://www.chef.io/"" rel=""nofollow"">Chef</a> to keep your configuration in sync between the nodes in your cluster.</p>

<p>I'd also strongly recommend setting up <a href=""http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSSLNodeToNode_t.html"" rel=""nofollow"">node-to-node encryption</a> and set up a trust store on your cassandra nodes that only allows other nodes to join the ring if they provide a certificate that is trusted.</p>

<p>This way you can't have unauthorized nodes joining your ring that you don't know about.   Also, chances are if your config files are changed, the server_encryption_options will be invalidated as well and your node won't be able to connect.</p>

<p>If you are concerned about securing your cluster.  I'd also recommend using <a href=""http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSSLClientToNode_t.html"" rel=""nofollow"">client-to-node encryption</a> when using authorization as without SSL the credentials are passed in the clear when a client connects.</p>
",['server_encryption_options']
29635372,29636188,2015-04-14 18:59:56,How does Cassandra partitioning work when replication factor == cluster size?,"<h2>Background:</h2>

<p>I'm new to Cassandra and still trying to wrap my mind around the internal workings.</p>

<p>I'm thinking of using Cassandra in an application that will only ever have a limited number of nodes (less than 10, most commonly 3).  Ideally each node in my cluster would have a complete copy of all of the application data.  So, I'm considering setting replication factor to cluster size.  When additional nodes are added, I would alter the keyspace to increment the replication factor setting (nodetool repair to ensure that it gets the necessary data).</p>

<p>I would be using the NetworkTopologyStrategy for replication to take advantage of knowledge about datacenters.</p>

<p>In this situation, how does partitioning actually work?  I've read about a combination of nodes and partition keys forming a ring in Cassandra.  If all of my nodes are ""responsible"" for each piece of data regardless of the hash value calculated by the partitioner, do I just have a ring of one partition key?</p>

<p>Are there tremendous downfalls to this type of Cassandra deployment?  I'm guessing there would be lots of asynchronous replication going on in the background as data was propagated to every node, but this is one of the design goals so I'm okay with it.</p>

<p>The consistency level on reads would probably generally be ""one"" or ""local_one"".</p>

<p>The consistency level on writes would generally be ""two"".</p>

<h2>Actual questions to answer:</h2>

<ol>
<li>Is replication factor == cluster size a common (or even a reasonable) deployment strategy aside from the obvious case of a cluster of one?</li>
<li>Do I actually have a ring of one partition where all possible values generated by the partitioner go to the one partition?</li>
<li>Is each node considered ""responsible"" for every row of data?</li>
<li>If I were to use a write consistency of ""one"" does Cassandra always write the data to the node contacted by the client?</li>
<li>Are there other downfalls to this strategy that I don't know about?</li>
</ol>
",<cassandra><replication><partitioning><distributed-system>,"<blockquote>
<p>Do I actually have a ring of one partition where all possible values
generated by the partitioner go to the one partition?</p>
<p>Is each node considered &quot;responsible&quot; for every row of data?</p>
<p>If all of my nodes are &quot;responsible&quot; for each piece of data regardless
of the hash value calculated by the partitioner, do I just have a ring
of one partition key?</p>
</blockquote>
<p>Not exactly, C* nodes still have token ranges and c* still assigns a primary replica to the &quot;responsible&quot; node. But all nodes will also have a replica with RF = N (where N is number of nodes). So in essence the implication is the same as what you described.</p>
<blockquote>
<p>Are there tremendous downfalls to this type of Cassandra deployment?
Are there other downfalls to this strategy that I don't know about?</p>
</blockquote>
<p>Not that I can think of, I guess you might be more susceptible than average to inconsistent data so use C*'s anti-entropy mechanisms to counter this (repair, read repair, hinted handoff).</p>
<p>Consistency level quorum or all would start to get expensive but I see you don't intend to use them.</p>
<blockquote>
<p>Is replication factor == cluster size a common (or even a reasonable)
deployment strategy aside from the obvious case of a cluster of one?</p>
</blockquote>
<p>It's not common, I guess you are looking for super high availability and all your data fits on one box. I don't think I've ever seen a c* deployment with RF &gt; 5. Far and wide RF = 3.</p>
<blockquote>
<p>If I were to use a write consistency of &quot;one&quot; does Cassandra always
write the data to the node contacted by the client?</p>
</blockquote>
<p>This depends on your load balancing policies at the driver. Often we select token aware policies (assuming you're using one of the Datastax drivers), in which case requests are routed to the primary replica automatically. You could use round robin in your case and have the same effect.</p>
",['partitioner']
29976998,29993081,2015-04-30 20:14:48,How to Connect to Cassandra Remotely Using DevCenter,"<p>I setup the DataStax Cassandra Sandbox on Azure using their image. I was able to run OpsCenter locally on the server without any issues. The install is Ubuntu which I am very new to. </p>

<p>Per this post <a href=""https://stackoverflow.com/questions/12236898/apache-cassandra-remote-access"">Apache Cassandra remote access</a>, <strong>I should be able to set my rpc_address to 0.0.0.0 to allow remote access to my database</strong>. However it says unable to connect when attempting a connection from DevCenter on my local Windows 8 PC.</p>

<p>Here are my settings:
<img src=""https://i.stack.imgur.com/9MlTP.png"" alt=""enter image description here""></p>

<p>The contact host address is the virtual ip address shown in Azure for my VM. The port is the same one shown in the cassandra.yaml config file. <strong>I haven't configured any authorization and from what I have read I should just be able to connect using .NET or the management tools but neither works.</strong></p>

<p><img src=""https://i.stack.imgur.com/f8krr.png"" alt=""enter image description here""></p>

<p>I also checked to see if the ports are open which they are as far as I can tell:
<img src=""https://i.stack.imgur.com/wGKJW.png"" alt=""enter image description here""></p>

<p>Far I know it would be either 9160 or 9042.</p>
",<.net><azure><cassandra><datastax>,"<p>Thanks to everyone who helped me figured this out. Ultimately the issue was that when setting up an Azure VM, the Virtual IP that is assigned is for the cloud service itself and not the virtual machine. Therefore even though it appears that the proper ports are exposed you are not able to access them from an external computer.</p>

<p>More <a href=""http://blogs.technet.com/b/canitpro/archive/2014/10/28/step-by-step-assign-a-public-ip-to-a-vm-in-azure.aspx"" rel=""nofollow"" title=""more info here"">info about it here</a> <strong>(but read my instructions below first since this is much easier to do in the Azure Management Console)</strong>.</p>

<p><strong>You will notice when setting up your virtual machine that Azure automatically creates an endpoint for your SSH connection such as 55xxx. You won't be able to connect to the configured port of 22 as shown on the box itself, but instead will have to use the endpoint port of 55xxx, etc.</strong> </p>

<p><strong>This is important to note because the same goes for the Cassandra ports 8888 (OpsCenter), and 9042 (native transport).</strong> </p>

<p>So you can either:</p>

<ol>
<li>Create endpoints for these ports and use them when connecting
remotely.</li>
<li>Create a public IP address that points to the VM itself
rather than the cloud service.</li>
</ol>

<p>I couldn't get the endpoints to work at first, <em>but later got them working</em>. This lead me to setup a public ip address. I did it the hard way using the Azure Powershell. This was painful and a lot of research. <strong>But, after spending the time to do this, I realized it can now be done in the preview console. Simply go to the IP Addresses settings on your VM and enable the ""Instance IP Address"" option.</strong> </p>

<p>Then you should be able to connect remotely to OpsCenter using the ip address that is returned after the setup is complete via your browser: (The New IP Address):8888 </p>

<p>...then in DevCenter using the new ip address and port 9042. </p>

<p>If you used endpoints instead of setting up a public static ip <strong>(which you will want to do for security reasons and enable user access control via ip filters)</strong>, then you will want to use those newly created port numbers instead along with your virtual ip address.</p>

<p>Secondly... you will need to set rpc_address to 0.0.0.0 in the cassandra.yaml file.</p>
",['rpc_address']
30073253,30079778,2015-05-06 09:52:34,Cassandra datastax driver ResultSet sharing in multiple threads for fast reading,"<p>I've huge tables in cassandra, more than 2 billions rows and increasing. The rows have a date field and it is following date bucket pattern so as to limit each row.</p>

<p>Even then, I've more than a million entries for a particular date. </p>

<p>I want to read and process rows for each day as fast as possible. What I am doing is that getting instance of <code>com.datastax.driver.core.ResultSet</code> and obtain iterator from it and share that iterator across multiple threads.</p>

<p>So, essentially I want to increase the read throughput. Is this the correct way? If not, please suggest a better way.</p>
",<cassandra><cassandra-2.0><datastax-java-driver>,"<p>Unfortunately you cannot do this as is.  The reason why is that a ResultSet provides an <a href=""https://github.com/datastax/java-driver/blob/2.0/driver-core/src/main/java/com/datastax/driver/core/PagingState.java"">internal paging state</a> that is used to retrieve rows 1 page at a time.</p>

<p>You do have options however.  Since I imagine you are doing range queries (queries across multiple partitions), you can use a strategy where you submit multiple queries across token ranges at a time using the token directive.  A good example of this is documented in <a href=""http://docs.datastax.com/en/cql/3.0/cql/cql_using/paging_c.html"">Paging through unordered partitioner results</a>.</p>

<p>java-driver 2.0.10 and 2.1.5 each provide a mechanism for retrieving token ranges from Hosts and <a href=""https://github.com/datastax/java-driver/blob/2.1.5/driver-core/src/main/java/com/datastax/driver/core/TokenRange.java#L65-L90"">splitting them</a>.  There is an example of how to do this in the java-driver's integration tests in <a href=""https://github.com/datastax/java-driver/blob/2.1/driver-core/src/test/java/com/datastax/driver/core/TokenIntegrationTest.java#L96-L127"">TokenRangeIntegrationTest.java#should_expose_token_ranges()</a>:</p>

<pre class=""lang-java prettyprint-override""><code>    PreparedStatement rangeStmt = session.prepare(""SELECT i FROM foo WHERE token(i) &gt; ? and token(i) &lt;= ?"");

    TokenRange foundRange = null;
    for (TokenRange range : metadata.getTokenRanges()) {
        List&lt;Row&gt; rows = rangeQuery(rangeStmt, range);
        for (Row row : rows) {
            if (row.getInt(""i"") == testKey) {
                // We should find our test key exactly once
                assertThat(foundRange)
                    .describedAs(""found the same key in two ranges: "" + foundRange + "" and "" + range)
                    .isNull();
                foundRange = range;
                // That range should be managed by the replica
                assertThat(metadata.getReplicas(""test"", range)).contains(replica);
            }
        }
    }
    assertThat(foundRange).isNotNull();
}
...
private List&lt;Row&gt; rangeQuery(PreparedStatement rangeStmt, TokenRange range) {
    List&lt;Row&gt; rows = Lists.newArrayList();
    for (TokenRange subRange : range.unwrap()) {
        Statement statement = rangeStmt.bind(subRange.getStart(), subRange.getEnd());
        rows.addAll(session.execute(statement).all());
    }
    return rows;
}
</code></pre>

<p>You could basically generate your statements and submit them in async fashion, the example above just iterates through the statements one at a time.</p>

<p>Another option is to use the <a href=""https://github.com/datastax/spark-cassandra-connector"">spark-cassandra-connector</a>, which essentially does this under the covers and in a very efficient way.  I find it very easy to use and you don't even need to set up a spark cluster to use it.  See <a href=""https://github.com/datastax/spark-cassandra-connector/blob/master/doc/7_java_api.md"">this document</a> for how to use the Java API.</p>
",['partitioner']
30205795,30209147,2015-05-13 04:37:56,"I am getting an InvalidTypeException whenever I am using the row.getToken(""fieldname"")?","<p>for the following piece of code I am getting an InvalidTypeException whenever I am using the <code>row.getToken(""fieldname"")</code>.</p>

<pre><code>Record RowToRecord(Row rw) {

    ColumnDefinitions cd = rw.getColumnDefinitions();
    Record rec = new Record();
    int i;
    for(i = 0; i &lt; cd.size(); i++) {
        rec.fields.add(cd.getName(i));
        System.out.println(cd.getName(i));
        //System.out.println((rw.getToken(cd.getName(i))).getValue());
        Token tk = rw.getToken(cd.getName(i));    //// InvalidTypeException on this line.
        //System.out.println(tk.getValue()+"" ""+tk.getType().toString());
        rec.values.add(tk.getValue());
        rec.types.add(tk.getType().toString());
        //Token tk = new Token();

    }
    return rec;
}
</code></pre>
",<cassandra><datastax-java-driver>,"<p><code>getToken</code> is meant to be called on a column that contains a Cassandra token. In 99% of cases, that will be the result of a call to the <code>token()</code> CQL function, for example the first column in this query:</p>

<pre><code>select token(id), col1 from my_table where id = ...
</code></pre>

<p>Your code is calling it for all columns, which will fail as soon as you have a column that doesn't match the CQL type for tokens.</p>

<p>That CQL type depends on the partitioner used in your cluster:</p>

<ul>
<li>murmur3 partitioner (the default): <code>token(...)</code> will return a BIGINT</li>
<li>random partitioner: VARINT</li>
<li>ordered partitioner: BLOB</li>
</ul>

<p>In theory you can call <code>getToken</code> on any column with this type (although in practice it probably only makes sense for columns that are the result of a <code>token()</code> call, as explained above).</p>
",['partitioner']
30449194,30453712,2015-05-26 03:55:45,Failover not working with Cassandra when using DataStax C# Driver,"<p>I have a two node setup in Azure and I am trying to get failover working when connecting with the C# driver. My nodes seem to be communicating fine when working with cqlsh and within OpsCenter.</p>

<pre><code>var contact = ""publicipforfirstnode"";
_cluster = Cassandra.Cluster.Builder().AddContactPoint(contact).Build();
_session = _cluster.Connect(""demo"");
</code></pre>

<p>I initially connect with the public IP of the first node. This works fine. However in the configuration I use the internal network IPs assigned by my virtual network such as 10.1.0.4, 10.1.0.5, etc. I set them as the listen_address and broadcast_rpc_address for each node. Even though I use the internal IP in the configuration I can connect with the public IP just fine. I have a special firewall rule that allows me to connect from a certain machine on the public IP. However to avoid firewall rules for inner-node communication, I put the nodes on the same virtual network and no extra work is required.</p>

<p>This seems great until my first node goes down. <strong>It then tries the second node using the internal IP.</strong> </p>

<blockquote>
  <p>I get an error: All Hosts tried for query (Public IP of First
  Node), (Internal IP of Second Node)</p>
</blockquote>

<p>But since I am connecting from a machine not in the virtual network it can't reach this internal ip. My application won't be in the internal network so this seems like an issue. </p>

<p>Not using internal ips forces me to setup authentication and/or special firewall rules I'd rather not have to do. Is there any way to force the c# driver to use public ips and allow the nodes to communicate on internal ips? Using internal ips seems to be the recommended best practice unless you have multiple regions.</p>
",<c#><azure><cassandra><datastax-enterprise>,"<p>The IP configured as <code>broadcast_rpc_address</code> in the cassandra.yaml file is used by the drivers to connect to them.</p>

<p>In your case, if you want to connect with the driver using the public ip addresses, you should set the <code>broadcast_rpc_address</code> as the public IP address.</p>

<p>You can enable tracing in the driver to see what is happening under the hood:</p>

<pre><code>// Specify the minimum trace level you want to see
Cassandra.Diagnostics.CassandraTraceSwitch.Level = TraceLevel.Info;
// Add a standard .NET trace listener
Trace.Listeners.Add(new ConsoleTraceListener());
</code></pre>

<p><a href=""http://docs.datastax.com/en/cassandra/2.1/cassandra/configuration/configCassandra_yaml_r.html"" rel=""nofollow"">From the docs</a>:</p>

<ul>
<li>listen_address: The IP address or hostname that Cassandra binds to for connecting to other Cassandra nodes.</li>
<li>broadcast_rpc_address: RPC address to <strong>broadcast</strong> to drivers and other Cassandra nodes. This cannot be set to 0.0.0.0. If blank, it is set to the value of the rpc_address or rpc_interface. If rpc_address or rpc_interfaceis set to 0.0.0.0, this property must be set.</li>
</ul>
",['rpc_address']
30627835,30628055,2015-06-03 18:24:45,What is the difference between broadcast_address and broadcast_rpc_address in cassandra.yaml?,"<p><strong>GOAL:</strong> I am trying to understand the best way to configure my Cassandra cluster so that several different drivers across several different networking scenarios can communicate with it properly. </p>

<p><strong>PROBLEM/QUESTION:</strong> It is not entirely clear to me, after reading the documentation what the difference is between these two settings: broadcast_address and broadcast_rpc_address as it pertains to the way that a driver connects and interacts with the cluster. Which one or which combination of these settings should I use with my node's accessible network endpoint (DNS record attainable by the client's/drivers)?</p>

<p>Here is the documentation for broadcast_address from <a href=""http://docs.datastax.com/en/cassandra/2.1/cassandra/configuration/configCassandra_yaml_r.html?scroll=reference_ds_qfg_n1r_1k__broadcast_address"" rel=""noreferrer"" title=""cassandra.yaml documentation"">datastax</a>:
(Default: listen_address)note The IP address a node tells other nodes in the cluster to contact it by. It allows public and private address to be different. For example, use the broadcast_address parameter in topologies where not all nodes have access to other nodes by their private IP addresses.
If your Cassandra cluster is deployed across multiple Amazon EC2 regions and you use the EC2MultiRegionSnitch, set the broadcast_address to public IP address of the node and the listen_address to the private IP.</p>

<p>Here is the documentation for broadcast_rpc_address from <a href=""http://docs.datastax.com/en/cassandra/2.1/cassandra/configuration/configCassandra_yaml_r.html?scroll=reference_ds_qfg_n1r_1k__broadcast_rpc_address"" rel=""noreferrer"" title=""cassandra.yaml documentation"">datastax</a>:
(Default: unset)note RPC address to broadcast to drivers and other Cassandra nodes. This cannot be set to 0.0.0.0. If blank, it is set to the value of the rpc_address or rpc_interface. If rpc_address or rpc_interfaceis set to 0.0.0.0, this property must be set.</p>

<p>EDIT: This question pertains to Cassandra version 2.1, and may not be relevant in the future.</p>
",<cassandra><bigdata>,"<p>One of the users of #cassandra on freenode was kind enough to provide an answer to this question:</p>

<p>The rpc family of settings pertain to drivers that use the Thrift protocol to communicate with cassandra. For those drivers that use the native transport, the broadcast_address will be reported and used.</p>

<p>My test case confirms this.</p>
",['broadcast_address']
30779774,30781880,2015-06-11 11:41:04,How to delete a record in Cassandra?,"<p>I have a table like this:</p>

<pre><code>CREATE TABLE mytable (
    user_id int,
    device_id ascii,
    record_time timestamp,
    timestamp timeuuid,
    info_1 text,
    info_2 int, 
    PRIMARY KEY (user_id, device_id, record_time, timestamp)
);
</code></pre>

<p>When I ask Cassandra to delete a record (an entry in the columnfamily) like this:</p>

<pre><code>DELETE from my_table where user_id = X and device_id = Y and record_time = Z and timestamp = XX;
</code></pre>

<p>it returns without an error, but when I query again the record is still there. Now if I try to delete a whole row like this:</p>

<pre><code>DELETE from my_table where user_id = X
</code></pre>

<p>It works and removes the whole row, and querying again immediately doesn't return any more data from that row.</p>

<p>What I am doing wrong? How you can remove a record in Cassandra?</p>

<p>Thanks</p>
",<cassandra><cassandra-2.0><cql3>,"<p>Ok, here is my theory as to what is going on.  You have to be careful with timestamps, because they will <em>store</em> data down to the millisecond.  But, they will only <em>display</em> data to the second.  Take this sample table for example:</p>

<pre><code>aploetz@cqlsh:stackoverflow&gt; SELECT id, datetime  FROM data;

 id     | datetime
--------+--------------------------
 B25881 | 2015-02-16 12:00:03-0600
 B26354 | 2015-02-16 12:00:03-0600

(2 rows)
</code></pre>

<p>The <code>datetime</code>s (of type timestamp) are equal, right?  Nope:</p>

<pre><code>aploetz@cqlsh:stackoverflow&gt; SELECT id, blobAsBigint(timestampAsBlob(datetime)),
                                  datetime FROM data;

 id     | blobAsBigint(timestampAsBlob(datetime)) | datetime
--------+-----------------------------------------+--------------------------
 B25881 |                           1424109603000 | 2015-02-16 12:00:03-0600
 B26354 |                           1424109603234 | 2015-02-16 12:00:03-0600

(2 rows)
</code></pre>

<p>As you are finding out, this becomes problematic when you use timestamps as part of your PRIMARY KEY.  It is possible that your timestamp is storing more precision than it is showing you.  And thus, you will need to provide that hidden precision if you will be successful in deleting that single row.</p>

<p>Anyway, you have a couple of options here.  One, find a way to ensure that you are not entering more precision than necessary into your <code>record_time</code>.  Or, you could define <code>record_time</code> as a timeuuid.</p>

<p>Again, it's a theory.  I could be totally wrong, but I have seen people do this a few times.  Usually it happens when they insert timestamp data using <code>dateof(now())</code> like this:</p>

<pre><code>INSERT INTO table (key, time, data) VALUES (1,dateof(now()),'blah blah');
</code></pre>
",['precision']
30782581,35349566,2015-06-11 13:44:00,Reading rows using AllRowsReader but starting from a specific row,"<p>I have a batch job that reads through approximately 33 million rows in Cassandra, using the <code>AllRowsReader</code> as described <a href=""https://github.com/Netflix/astyanax/wiki/AllRowsReader-All-rows-query"" rel=""nofollow"">in the Astyanax wiki</a>:</p>

<pre><code>new AllRowsReader.Builder&lt;&gt;(getKeyspace(), columnFamily)
            .withPageSize(100)
            .withIncludeEmptyRows(false)
            .withConcurrencyLevel(1)
            .forEachRow(
                row -&gt; {
                    try {
                        return processRow(row);
                    } catch (Exception e) {
                        LOG.error(""Error while processing row!"", e);
                        return false;
                    }
                }
            )
            .build()
            .call();
</code></pre>

<p>If some sort of error stops the batch job, I would like to be able to pick up and continue reading from the row where it stopped, so that I don't have to start reading from the first row again. Is there any fast and simple way to do this? </p>

<p>Or isn't the <code>AllRowsReader</code> the right fit for this kind of task?</p>
",<java><cassandra><astyanax>,"<p>Since nobody has answered let me try this one. Cassandra uses partitioners to determine in which node it should place the row. 
There are mainly two type of partitioners:
1) Ordered
2) Unordered</p>

<p><a href=""https://docs.datastax.com/en/cassandra/2.2/cassandra/architecture/archPartitionerAbout.html"" rel=""nofollow"">https://docs.datastax.com/en/cassandra/2.2/cassandra/architecture/archPartitionerAbout.html</a></p>

<p>In case of Ordered Partitioner, rows are placed according to the lexicographic order.But in case of Unordered Partitioner you dont have any way to know about the order.</p>

<p>Ordered Partitioner are regarded as anti-pattern in cassandra because it makes cluster distribution pretty difficult.
<a href=""https://docs.datastax.com/en/cassandra/2.2/cassandra/planning/planPlanningAntiPatterns.html"" rel=""nofollow"">https://docs.datastax.com/en/cassandra/2.2/cassandra/planning/planPlanningAntiPatterns.html</a></p>

<p>I am assuming you should be using unordered partitioner in your code. So currently there is no way to tell cassandra which is using unordered partitioner that start from this particular row.</p>

<p>I hope this answers your question</p>
",['partitioner']
31300682,31301133,2015-07-08 18:23:23,CQLSH: Converting unix timestamp to datetime,"<p>I am performing a cql query on a column that stores the values as unix timestmap, but want the results to output as datetime. Is there a way to do this?</p>

<p>i.e. something like the following:</p>

<pre><code>select convertToDateTime(column) from table;
</code></pre>
",<cassandra><cql><cqlsh>,"<p>I'm trying to remember if there's an easier, more direct route.  But if you have a table with a UNIX timestamp and want to show it in a datetime format, you can combine the <code>dateOf</code> and <code>min</code>/<code>maxTimeuuid</code> functions together, like this:</p>

<pre><code>aploetz@cqlsh:stackoverflow2&gt; SELECT datetime,unixtime,dateof(mintimeuuid(unixtime)) FROM unixtime;

 datetimetext   | unixtime      | dateof(mintimeuuid(unixtime))
----------------+---------------+-------------------------------
     2015-07-08 | 1436380283051 |      2015-07-08 13:31:23-0500

(1 rows)
aploetz@cqlsh:stackoverflow2&gt; SELECT datetime,unixtime,dateof(maxtimeuuid(unixtime)) FROM unixtime;

 datetimetext   | unixtime      | dateof(maxtimeuuid(unixtime))
----------------+---------------+-------------------------------
     2015-07-08 | 1436380283051 |      2015-07-08 13:31:23-0500

(1 rows)
</code></pre>

<p>Note that timeuuid stores greater precision than either a UNIX timestamp or a datetime, so you'll need to first convert it to a TimeUUID using either the <code>min</code> or <code>maxtimeuuid</code> function.  Then you'll be able to use <code>dateof</code> to convert it to a datetime timestamp.</p>
",['precision']
31612199,31701968,2015-07-24 13:45:22,"Cassandra - Write doesn't fail, but values aren't inserted","<p>I have a cluster of 3 Cassandra 2.0 nodes. My application I wrote a test which tries to write and read some data into/from Cassandra. In general this works fine.</p>

<p>The curiosity is that after I restarted my computer, this test will fail, because after writting I read the same value I´ve write before and there I get null instead of the value, but the was no exception while writing. 
If I manually truncate the used column family, the test will pass. After that I can execute this test how often I want, it passes again and again. Furthermore it doesn´t matter if there are values in the Cassandra or not. The result is alwalys the same.</p>

<p>If I look at the CLI and the CQL-shell there are two different views:</p>

<p><a href=""https://i.stack.imgur.com/A8wsO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/A8wsO.png"" alt=""cassandra-cli""></a></p>

<p><a href=""https://i.stack.imgur.com/fMe7O.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fMe7O.png"" alt=""enter image description here""></a></p>

<p>Does anyone have an ideas what is going wrong? The timestamp in the CLI is updated after re-execution, so it seems to be a read-problem?</p>

<p>A part of my code:
For inserts I tried </p>

<pre><code>Insert.Options insert =   QueryBuilder.insertInto(KEYSPACE_NAME,TABLENAME)
                .value(ID, id)
                .value(JAHR, zonedDateTime.getYear())
                .value(MONAT, zonedDateTime.getMonthValue())
                .value(ZEITPUNKT, date)
                .value(WERT, entry.getValue())
                .using(timestamp(System.nanoTime() / 1000));
</code></pre>

<p>and</p>

<pre><code>Insert insert = QueryBuilder.insertInto(KEYSPACE_NAME,TABLENAME)
                .value(ID, id)
                .value(JAHR, zonedDateTime.getYear())
                .value(MONAT, zonedDateTime.getMonthValue())
                .value(ZEITPUNKT, date)
                .value(WERT, entry.getValue());
</code></pre>

<p>My select looks like</p>

<pre><code>Select.Where select = QueryBuilder.select(WERT)
            .from(KEYSPACE_NAME,TABLENAME)
            .where(eq(ID, id))
            .and(eq(JAHR, zonedDateTime.getYear()))
            .and(eq(MONAT, zonedDateTime.getMonthValue()))
            .and(eq(ZEITPUNKT, Date.from(instant)));
</code></pre>

<p>Consistencylevel is QUORUM (for both) and replicationfactor 3</p>
",<cassandra><cql><cassandra-2.0><datastax-java-driver><cassandra-cli>,"<p>I'd say this seems to be a problem with timestamps since a truncate solves the problem. In Cassandra last write wins and this could be a problem caused by the use of System.nanoTime() since</p>
<blockquote>
<p>This method can only be used to measure elapsed time and is not related to any other notion of system or wall-clock time.</p>
<p>...</p>
<p>The values returned by this method become meaningful only when the difference between two such values, obtained within the same instance of a Java virtual machine, is computed.</p>
</blockquote>
<p><a href=""http://docs.oracle.com/javase/7/docs/api/java/lang/System.html#nanoTime()"" rel=""nofollow noreferrer"">http://docs.oracle.com/javase/7/docs/api/java/lang/System.html#nanoTime()</a></p>
<p>This means that the write that occured before the restart could have been performed &quot;in the future&quot; compared to the write after the restart. This would not fail the query, but the written value would simply not be visible due to the fact that there is a &quot;newer&quot; value available.</p>
<p>Do you have a requirement to use sub-millisecond precision for the insert timestamps? If possible I would recommend using System.currentTimeMillis() instead of nanoTime().</p>
<p><a href=""http://docs.oracle.com/javase/7/docs/api/java/lang/System.html#currentTimeMillis()"" rel=""nofollow noreferrer"">http://docs.oracle.com/javase/7/docs/api/java/lang/System.html#currentTimeMillis()</a></p>
<p>If you have a requirement to use sub-millisecond precision it would be possible to use System.currentTimeMillis() with some kind of atomic counter that ranged between 0-999 and then use that as a timestamp. This would however break if multiple clients insert the same row at the same time.</p>
",['precision']
31723110,31723919,2015-07-30 11:54:26,keyspace and tables not replicating across data centre in cassandra,"<p>I am trying to create cassandra cluster. For that I have a single node data centres
One data center is named DC1 and the other is DC2. Hence there are 2 single node data center. I followed the steps given here
<a href=""http://docs.datastax.com/en/cassandra/2.0/cassandra/initialize/initializeMultipleDS.html"" rel=""nofollow"">http://docs.datastax.com/en/cassandra/2.0/cassandra/initialize/initializeMultipleDS.html</a></p>

<p>Since I have single node data center, so my seed will be a single machine. I can do ndoetool -h  status to both the machines. I created a keyspace like this</p>

<pre><code>CREATE KEYSPACE sams WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '1', 'DC2': '1'}  AND durable_writes = true;
</code></pre>

<p>and a table like </p>

<pre><code>CREATE TABLE apikey (   appname text,   appkey text,   PRIMARY KEY ((appname), appkey) );
</code></pre>

<p>I create keyspace and table in one data centre. This should get replicated on the other machine but it does not replicate. There are no keyspaces shown on the other data center neither any tables.</p>

<p>What am I missing here?</p>

<p>Adding nodetool output</p>

<pre><code>nodetool -h cassandra1 status
Datacenter: DC1
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address          Load       Tokens  Owns (effective)  Host ID                               Rack
UN  100.117.100.107  178.28 KB  256     100.0%            0c5da294-2a86-472d-98ec-857ed5140417  RAC1


 nodetool -h cassandra2 status
Datacenter: DC2
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address         Load       Tokens  Owns    Host ID                               Rack
UN  100.117.150.55  162.94 KB  256     ?       9f3e49f6-debc-4a9c-ba93-bc65b3851a48  RAC1
</code></pre>
",<cassandra>,"<p>It looks like you have accidentally set up two independent clusters rather than a single cluster that spans two data centers.</p>

<p>Make sure in cassandra.yaml that both nodes have the same cluster_name and that both have the same list of ip's for ""- seeds:"".  Since you only have two nodes, I'd list both ip's as the seeds rather than just one.</p>

<p>If the nodes have joined the same cluster, then it should show both of them when you run nodetool status.</p>
",['cluster_name']
31733395,31734440,2015-07-30 20:26:00,How to prevent Cassandra commit logs filling up disk space,"<p>I'm running a two node Datastax AMI cluster on AWS. Yesterday, Cassandra started refusing connections from everything. The system logs showed nothing. After a <em>lot</em> of tinkering, I discovered that the commit logs had filled up all the disk space on the allotted mount and this seemed to be causing the connection refusal (deleted some of the commit logs, restarted and was able to connect).</p>

<p>I'm on DataStax AMI 2.5.1 and Cassandra 2.1.7</p>

<p>If I decide to wipe and restart everything from scratch, how do I ensure that this does not happen again?</p>
",<cassandra><datastax><datastax-java-driver><cassandra-2.1>,"<p>You could try lowering the <code>commitlog_total_space_in_mb</code> setting in your <code>cassandra.yaml</code>.  The default is 8192MB for 64-bit systems (it should be commented-out in your <code>.yaml</code> file... you'll have to un-comment it when setting it).  It's usually a good idea to plan for that when sizing your disk(s).</p>

<p>You can verify this by running a <code>du</code> on your commitlog directory:</p>

<pre><code>$ du -d 1 -h ./commitlog
8.1G    ./commitlog
</code></pre>

<p>Although, a smaller commit log space will cause more frequent flushes (increased disk I/O), so you'll want to keep any eye on that.</p>

<p><strong>Edit 20190318</strong></p>

<p>Just had a related thought (on my 4-year-old answer).  I saw that it received some attention recently, and wanted to make sure that the right information is out there.</p>

<p>It's important to note that sometimes the commit log can grow in an ""out of control"" fashion.  Essentially, this can happen because the write load on the node exceeds Cassandra's ability to keep up with flushing the memtables (and thus, removing old commitlog files).  If you find a node with dozens of commitlog files, and the number seems to keep growing, this might be your issue.</p>

<p>Essentially, your <code>memtable_cleanup_threshold</code> may be too low.  Although this property is deprecated, you can still control how it is calculated by lowering the number of <code>memtable_flush_writers</code>.</p>

<pre><code>memtable_cleanup_threshold = 1 / (memtable_flush_writers + 1)
</code></pre>

<p>The documentation has been updated as of 3.x, but used to say this:</p>

<pre><code># memtable_flush_writers defaults to the smaller of (number of disks,
# number of cores), with a minimum of 2 and a maximum of 8.
# 
# If your data directories are backed by SSD, you should increase this
# to the number of cores.
#memtable_flush_writers: 8
</code></pre>

<p>...which (I feel) led to many folks setting this value <em>WAY</em> too high.</p>

<p>Assuming a value of 8, the <code>memtable_cleanup_threshold</code> is <code>.111</code>.  When the footprint of all memtables exceeds this ratio of total memory available, flushing occurs.  Too many flush (blocking) writers can prevent this from happening expediently.  With a single <code>/data</code> dir, I recommend setting this value to <strong>2</strong>.</p>
",['memtable_flush_writers']
31785110,31793736,2015-08-03 10:32:09,How to understand bloom_filter_fp_chance and read_repair_chance in Cassandra,"<p><strong>Bloom Filters</strong> </p>

<pre><code>When data is requested, the Bloom filter checks if the row exists before doing disk I/O. 
</code></pre>

<p><strong>Read Repair</strong></p>

<pre><code>Read Repair perform a digest query on all replicas for that key
</code></pre>

<p>My confusion is how to set this value between 0 to 1,. What happens when the value varies?</p>

<p>Thanks in advance,.</p>
",<cassandra>,"<p>The bloom_filter_fp_chance and read_repair_chance control two different things.  Usually you would leave them set to their default values, which should work well for most typical use cases.</p>

<p>bloom_filter_fp_chance controls the precision of the bloom filter data for SSTables stored on disk.  The bloom filter is kept in memory and when you do a read, Cassandra will check the bloom filters to see which SSTables <em>might</em> have data for the key you are reading.  A bloom filter will often give false positives and when you actually read the SSTable, it turns out that the key does not exist in the SSTable and reading it was a waste of time.  The better the precision used for the bloom filter, the fewer false positives it will give (but the more memory it will need).</p>

<p>From the documentation:</p>

<pre><code>0 Enables the unmodified, effectively the largest possible, Bloom filter
1.0 Disables the Bloom Filter
The recommended setting is 0.1. A higher value yields diminishing returns.
</code></pre>

<p>So a higher number gives a higher chance of a false positive (fp) when reading the bloom filter.</p>

<p>read_repair_chance controls the probability that a read of a key will be checked against the other replicas for that key.  This is useful if your system has frequent downtime of the nodes resulting in data getting out of sync.  If you do a lot of reads, then the read repair will slowly bring the data back into sync as you do reads without having to run a full repair on the nodes.  Higher settings will cause more background read repairs and consume more resources, but would sync the data more quickly as you do reads.</p>

<p>See documentation on these settings <a href=""http://docs.datastax.com/en/cql/3.1/cql/cql_reference/tabProp.html"">here</a>.</p>
",['precision']
31790072,31791790,2015-08-03 14:34:36,Failover and Replication in 2-node Cassandra cluster,"<p>I run KairosDB on a 2-node Cassandra cluster, RF = 2, Write CL = 1, Read CL = 1. If 2 nodes are alive, client sends half of data to node 1 (e.g. metric from METRIC_1 to METRIC_5000) and the other half of data to node 2 (e.g. metric from METRIC_5001 to METRIC_10000). Ideally, each node always has a copy of all data. But if one node is dead, client sends all data to the alive node.</p>

<p>Client started sending data to the cluster. After 30 minutes, I turned node 2 off for 10 minutes. During this 10-minute period, client sent all data to node 1 properly. After that, I restarted node 2 and client continued sending data to 2 nodes properly. One hour later I stopped the client.</p>

<p>I wanted to check if the data which was sent to node 1 when node 2 was dead had been automatically replicated to node 2 or not. To do this, I turned node 1 off and queried the data within time when node 2 was dead from node 2 but it returned nothing. This made me think that the data had not been replicated from node 1 to node 2. I posted a question <a href=""https://stackoverflow.com/questions/31737836/doesnt-cassandra-perform-late-replication-when-a-node-down-and-up-again"">Doesn't Cassandra perform “late” replication when a node down and up again?</a>. It seems that the data was replicated automatically but it was so slow.</p>

<p>What I expect is data in both 2 servers are the same (for redundancy purpose). That means the data sent to the system when node 2 is dead must be replicated from node 1 to node 2 automatically after node 2 becomes available (because RF = 2).</p>

<p>I have several questions here:</p>

<p>1) Is the replication truly slow? Or did I configure something wrong?</p>

<p>2) If client sends half of data to each node as in this question I think it's possible to lose data (e.g. node 1 receives data from client, while node 1 is replicating data to node 2 it suddenly goes down). Am I right?</p>

<p>3) If I am right in 2), I am going to do like this: client sends all data to both 2 nodes. This can solve 2) and also takes advantages of replication if one node is dead and is available later. But I am wondering that, this would cause duplication of data because both 2 nodes receive the same data. Is there any problem here?</p>

<p>Thank you!</p>
",<cassandra><cassandra-2.0><kairosdb>,"<p>Can you check the value of hinted_handoff_enabled in cassandra.yaml config file?</p>

<p>For your question: Yes you may lose data in some cases, until the replication is fully achieved, Cassandra is not exactly doing late replication - there are three mechanisms.</p>

<ul>
<li>Hinted handoffs  <a href=""http://docs.datastax.com/en/cassandra/2.2/cassandra/operations/opsRepairNodesHintedHandoff.html"" rel=""nofollow"">http://docs.datastax.com/en/cassandra/2.2/cassandra/operations/opsRepairNodesHintedHandoff.html</a></li>
<li>Repairs - <a href=""http://docs.datastax.com/en/cassandra/2.0/cassandra/tools/toolsRepair.html"" rel=""nofollow"">http://docs.datastax.com/en/cassandra/2.0/cassandra/tools/toolsRepair.html</a></li>
<li>Read Repairs - those may not help much on your use case - <a href=""http://wiki.apache.org/cassandra/ReadRepair"" rel=""nofollow"">http://wiki.apache.org/cassandra/ReadRepair</a></li>
</ul>

<p>AFAIK, if you are running a version greater than 0.8, the hinted handoffs should duplicate the data after node restarts without the need for a repair, unless data is too old (this should not be the case for 10 minutes). I don't know why those handoffs where not sent to your replica node when it was restarted, it deserves some investigation.</p>

<p>Otherwise, when you restart the node, you can force Cassandra to make sure that data is consistent by running a repair (e.g. by running nodetool repair).</p>

<p>By your description I have the feeling you are getting confused between the coordinator node and the node that is getting the data (even if the two nodes hold the data, the distinction is important).</p>

<p>BTW, what is the client behaviour with metrics sharding between node 1 and node 2 you are describing? Neither KairosDB nor Cassandra work like that, is it your own client that is sending metrics to different KairosDB instances? </p>

<p>The Cassandra partition is not made on metric name but on row key (partition key exactly, but it's the same with kairosDB). So every 3-weeks data for each unique series will be associated a token based on hash code, this token will be use for sharding/replication on the cluster.
KairosDB is able to communicate with several nodes and would round robin between those as coordinator nodes.</p>

<p>I hope this helps.</p>
",['hinted_handoff_enabled']
31815665,31817416,2015-08-04 17:29:48,Cassandra 2.1.8 remote access,"<p>I'm configuring Cassandra to accept remote accesses (cqlsh ).
Here's the following that I changed in the cassandra.yaml:</p>

<ul>
<li><p>start_native_transport: true</p></li>
<li><p>start_rpc: true</p></li>
<li><p>rpc_address: my-server-ip</p></li>
</ul>

<p>But when I'm launching Cassandra I get the following error: </p>

<blockquote>
  <p>""Failed to bind port 9042 on my-server-ip""</p>
</blockquote>

<p>If I set start_native_transport: false, I get no error, but I can't get a remote access Cassandra.</p>

<p>Does anyone knows the problem?</p>

<p>Thanks</p>
",<cassandra>,"<p>Check your listen_address in cassandra.yaml. It defaults to localhost, which will not allow for external access. Change it to the private IP, and you will be able to talk to it from the outside. The rpc_address is for Thrift requests.</p>
","['listen_address', 'rpc_address']"
32012777,32013024,2015-08-14 14:43:25,ERROR Session: Error creating pool to /127.0.0.1:9042,"<p>I am trying to insert values in cassandra when I come across this error:</p>

<pre><code>15/08/14 10:21:54 INFO Cluster: New Cassandra host /a.b.c.d:9042 added
15/08/14 10:21:54 INFO Cluster: New Cassandra host /127.0.0.1:9042 added
INFO CassandraConnector: Connected to Cassandra cluster: Test Cluster
15/08/14 10:21:54 ERROR Session: Error creating pool to /127.0.0.1:9042
com.datastax.driver.core.TransportException: [/127.0.0.1:9042] Cannot connect
        at com.datastax.driver.core.Connection.&lt;init&gt;(Connection.java:109)
        at com.datastax.driver.core.PooledConnection.&lt;init&gt;(PooledConnection.java:32)
        at com.datastax.driver.core.Connection$Factory.open(Connection.java:586)
        at com.datastax.driver.core.SingleConnectionPool.&lt;init&gt;(SingleConnectionPool.java:76)
        at com.datastax.driver.core.HostConnectionPool.newInstance(HostConnectionPool.java:35)
        at com.datastax.driver.core.SessionManager.replacePool(SessionManager.java:271)
        at com.datastax.driver.core.SessionManager.access$400(SessionManager.java:40)
        at com.datastax.driver.core.SessionManager$3.call(SessionManager.java:308)
        at com.datastax.driver.core.SessionManager$3.call(SessionManager.java:300)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
        at java.util.concurrent.FutureTask.run(FutureTask.java:166)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:722)
Caused by: java.net.ConnectException: Connection refused: /127.0.0.1:9042
</code></pre>

<p>My replication factor is 1. There are 5 nodes in the Cass cluster (they're all up). rpc_address: 0.0.0.0, broadcast_rpc_address: 127.0.0.1</p>

<p>I would think that I should see 5 of those ""INFO Cluster: New Cassandra host.."" line from above for each of the 5 nodes. <strong>But instead I see 127.0.0.1, I am not sure why.</strong></p>

<p>I also noticed that in the cassandra.yaml file, all the 5 nodes are listed under seed. (which I know is not advised but I did not set up this  cluster)</p>

<pre><code>seed_provider:
class_name: org.apache.cassandra.locator.SimpleSeedProvider
parameters:
seeds: ""ip1, ip2, ip3, ip4, ip5""
</code></pre>

<p>Where ipx is the ipaddr for node x.</p>

<p>And under cassandra-topology.properties it just says the following and does not mention any of the 5 nodes.</p>

<pre><code># default for unknown nodes                                                                                                                     

default=DC1:r1
</code></pre>

<p>Can someone explain why I am seeing the ERROR Session: Error creating pool to /127.0.0.1:9042 error.</p>

<p>Kind of new to Cassandra.. thanks in advance!</p>
",<configuration><cassandra>,"<p>I think the problem is your rpc_broadcast_address is set to 127.0.0.1.  Is there a reason in particular you are doing this?</p>

<p>The java driver uses the system.peers table to look up the ip address to use to connect to hosts.  If rpc_broadcast_address is set this is what will be present in system.peers and the driver will try to use it.  If rpc_broadcast_address is not set, rpc_address will be used.  In either case, you'll want to set one of these addresses to an address that will be accessible by your client.  If you set rpc_address, you will want to remove broadcast_rpc_address.</p>
",['rpc_address']
32062552,32081643,2015-08-18 02:20:55,Querying in KairosDB/OpenTSDB,"<p>I have 3 million records with entries like:</p>

<pre><code>~/Abharthan/kairosdb$ head -10 export.txt
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""1"",""building_type"":""ElementarySchool"",""meter_type"":""temperature"",""unit"":""F""},""value"":""34.85""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""2"",""building_type"":""Park"",""meter_type"":""temperature"",""unit"":""F""},""value"":""0""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""3"",""building_type"":""Industrial"",""meter_type"":""temperature"",""unit"":""F""},""value"":""0.07""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""4"",""building_type"":""RecreationCenter"",""meter_type"":""temperature"",""unit"":""F""},""value"":""0""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""5"",""building_type"":""Park"",""meter_type"":""temperature"",""unit"":""F""},""value"":""2.2""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""6"",""building_type"":""CommunityCenter"",""meter_type"":""temperature"",""unit"":""F""},""value"":""31.41""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""7"",""building_type"":""Office"",""meter_type"":""temperature"",""unit"":""F""},""value"":""0""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""8"",""building_type"":""ElementarySchool"",""meter_type"":""temperature"",""unit"":""F""},""value"":""10.88""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""9"",""building_type"":""ElementarySchool"",""meter_type"":""temperature"",""unit"":""F""},""value"":""42.27""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700"",""tags"": {""Building_id"":""10"",""building_type"":""ElementarySchool"",""meter_type"":""temperature"",""unit"":""F""},""value"":""10.14""}
</code></pre>

<p>These are 1 year readings for meterreadings for each building with building_id collected every hour.</p>

<p>My starting data timestamp is: 1359695700 and ending timestamp is: 1422853200.
I want to query this DB to get the following:</p>

<pre><code>Query hourly average for one building(say building_id:100) for one year (output expected of 8760 points)
Query monthly sum for one building for one year (output expected of 12 points)
</code></pre>

<p>I have written following two queries to get results for above two queries:</p>

<p>Query1:</p>

<blockquote>
  <p>{ ""start_absolute"":1359695700, ""end_absolute"":1422853200,
  ""metrics"":[{""tags"":{""Building_id"":[""100""]},""name"":""meterreadings"",""aggregators"":[{""name"":""avg"",""align_sampling"":true,""sampling"":{""value"":""1"",""unit"":""hours""}}]}]}</p>
  
  <p>Response: 200
  {""queries"":[{""sample_size"":70168,""results"":[{""name"":""meterreadings"",""group_by"":[{""name"":""type"",""type"":""number""}],""tags"":{""Building_id"":[""100""],""building_type"":[""MiddleSchool""],""meter_type"":[""temperature""],""unit"":[""F""]},""values"":[[1359695700,42.45377343113282],[1360800000,36.42662912912908],[1364400000,41.12510250000007],[1368000000,54.915547499999946],[1371600000,65.07990000000015],[1375200000,55.8904375],[1378800000,47.33335249999986],[1382400000,38.952450000000034],[1386000000,41.99267000000001],[1389600000,41.28209500000009],[1393200000,40.31645895895911],[1396800000,40.758327499999915],[1400400000,54.05608750000002],[1404000000,63.410385],[1407600000,65.38089749999993],[1411200000,45.99822500000001],[1414800000,39.669450137465724],[1418400000,39.039874999999945],[1422000000,41.795917721519]]}]}]}</p>
</blockquote>

<p>Query 2:</p>

<blockquote>
  <p>{ ""start_absolute"":1359695700, ""end_absolute"":1422853200,
  ""metrics"":[{""tags"":{""Building_id"":[""100""]},""name"":""meterreadings"",""aggregators"":[{""name"":""sum"",""align_sampling"":true,""sampling"":{""value"":""1"",""unit"":""months""}}]}]}</p>
  
  <p>Response: 200
  {""queries"":[{""sample_size"":70168,""results"":[{""name"":""meterreadings"",""group_by"":[{""name"":""type"",""type"":""number""}],""tags"":{""Building_id"":[""100""],""building_type"":[""MiddleSchool""],""meter_type"":[""temperature""],""unit"":[""F""]},""values"":[[1359695700,3337957.570000005]]}]}]}</p>
</blockquote>

<p>I am not getting what I expected, am I missing something.</p>
",<cassandra><opentsdb><kairosdb>,"<p>The answer is simple,as I pointed out previously as a possible problem :-)  cf. <a href=""https://stackoverflow.com/questions/31926735/kairosdb-error-metric0name-abcd-tagxyz-value-may-not-be-empty"">Kairosdb error metric[0](name=abcd).tag[xyz].value may not be empty</a></p>

<p>KairosDB has millisecond precision - All the timestamps in KairosDB are Unix milliseconds.</p>

<p>But your timestamps are in Unix seconds, and that's your problem.</p>

<p>Therefore you need to multiply by 1000 all your timestamps in the data acquisition and in the queries.  </p>

<p>For instance query2 asks for all samples during less than 24h between January 16 1970 to January 17 1970, as you aggregate on one month you get only one result. </p>

<p>E.g. for data acquisition:</p>

<pre><code>{""name"": ""meterreadings"", ""timestamp"":""1359695700000"",""tags"": {""Building_id"":""1"",""building_type"":""ElementarySchool"",""meter_type"":""temperature"",""unit"":""F""},""value"":""34.85""}
    {""name"": ""meterreadings"", ""timestamp"":""1359695700000"",""tags"": {""Building_id"":""2"",""building_type"":""Park"",""meter_type"":""temperature"",""unit"":""F""},""value"":""0""}
</code></pre>

<p>...And query:</p>

<pre><code>{ ""start_absolute"":1359695700000, ""end_absolute"":1422853200000, ""metrics"":[{""tags"":{""Building_id"":[""100""]},""name"":""meterreadings"",""aggregators"":[{""name"":""sum"",""align_sampling"":true,""sampling"":{""value"":""1"",""unit"":""months""}}]}]}
</code></pre>
",['precision']
32307615,32307980,2015-08-31 09:07:23,Can I use num_tokens as load factor in Cassandra?,"<p>If you run cassandra on machines with different sizes of hard disk (e.g. one with one TB, another with 2TB), can I use num_tokens as load factor?
I want to reduce the risk of one node running out of disk space and balance the usage of disk on different machines. </p>

<p>I know, the more data one node collects, the more probable it might become a hotspot. Apart from that, which other considerations do I need to take care of? Which limits or practical restrictions exist for the number of nodes?
Can I change the number of nodes later if disk space changes without trouble?</p>

<p>I would appreciate some advice on that topic because I have not found much information about that in google or at the website of cassandra.</p>

<p>EDIT: numnodes replaced by num_tokens</p>
",<cassandra><cassandra-2.0>,"<p>Are you referring to <a href=""http://docs.datastax.com/en/cassandra/2.1/cassandra/configuration/configCassandra_yaml_r.html?scroll=reference_ds_qfg_n1r_1k__num_tokens"" rel=""nofollow"">num_tokens</a> settings? Yes, you can use a different number of tokens based on the hardware resources. Nodes with a larger number of tokens will see higher load and disk usage. Once set, the num_tokens setting cannot be changed at a later point without decommissioning the node.</p>
",['num_tokens']
32729181,32732661,2015-09-23 00:30:27,Installing Cassandra on Vagrant Centos using Puppet missing dsc22,"<p>I'm new to puppet. I know that cassandra is missing from yum so I figured a puppet recipe would download and install it, but it seems like <code>locp/cassandra</code> is just trying to install it from yum. The recipe is supposed to work, but I don't see anything on <a href=""https://github.com/locp/cassandra"" rel=""nofollow"">https://github.com/locp/cassandra</a> as to why it's not working for me or any thing I need to set up before it should work.</p>

<p>I used librarian-puppet to install the modules in puppet/modules.</p>

<p><strong>Error</strong></p>

<pre><code>==&gt; default: Notice: /Stage[main]/Cassandra/File[/var/lib/cassandra/data]: Dependency Package[dsc22] has failures: true
</code></pre>

<p><strong>Vagrantfile</strong></p>

<pre><code># -*- mode: ruby -*-
# vi: set ft=ruby :

Vagrant.configure(2) do |config|
  config.vm.box = ""puphpet/centos65-x64""

  config.vm.provision ""puppet"" do |p|
    p.module_path = ""puppet/modules""
    p.manifests_path = ""puppet/manifests""
    p.manifest_file = ""site.pp""
  end
end
</code></pre>

<p><strong>puppet/manifests/site.pp</strong></p>

<pre><code>class { 'cassandra':
  cluster_name    =&gt; 'foobar',
  listen_address  =&gt; ""${::ipaddress}"",
}
</code></pre>

<p><strong>puppet/Puppetfile</strong></p>

<pre><code>forge 'https://forgeapi.puppetlabs.com'

mod ""locp/cassandra""
</code></pre>
",<cassandra><centos><vagrant><puppet>,"<p>Thats probably because the repo is not configured (see <a href=""http://docs.datastax.com/en/cassandra/2.2/cassandra/install/installRHEL.html"" rel=""nofollow"">here</a>)</p>

<p>Add the following to your <code>site.pp</code> and make sure to add a <code>require</code> on it in your cassandra class</p>

<pre><code>class repo {
  yumrepo { ""datastax"":
    descr          =&gt; ""DataStax Repo for Apache Cassandra"",
    baseurl        =&gt; ""http://rpm.datastax.com/community"",
    gpgcheck       =&gt; ""0"",
    enabled        =&gt; ""1"";
  } 
}

class { 'cassandra':
  cluster_name    =&gt; 'foobar',
  listen_address  =&gt; ""${::ipaddress}"",
  require         =&gt; Yumrepo[""datastax""],
}

include repo
include cassandra
</code></pre>
","['listen_address', 'cluster_name']"
33460506,33639635,2015-11-01 08:42:34,Not able to run multi node cluster on AWS EC2,"<p>Trying to configure 3 nodes in Cassandra on AWS EC2 (have set ICMP, SSH, HTTP and HTTPS in security groups accordingly)</p>

<p>Cluster name is also set as same in all the three cassandra.yaml file i.e. 'Test Cluster'</p>

<p>Mentioned there corresponding ip as example for node1
listen_address: node1 
seeds:  ""node1,node2,node3""
rpc_address: 0.0.0.0
broadcast_rpc_address: 1.2.3.4</p>

<p>Machines are able to ping each other, using the IP obtained by ifconfig.</p>

<p>But when I run cassandra on the three mentioned machine I get</p>

<p>INFO  08:33:52 No gossip backlog; proceeding.
cassandra 2.2.3
Machine Ubuntu</p>

<p>Is something I am missing?</p>
",<amazon-web-services><amazon-ec2><cassandra>,"<p>although you've posted very little, it might be your snitch. Use GossipingPropertyFileSnitch or Ec2Snitch. Also, you shouldn't make every node a seed. In a 3-node cluster you need only 1 or maybe 2 for redundancy. The seeds: list in cassandra.yaml should be the same on each node. You shouldn't set both the rpc_address and the broadcast_rpc_address. Pick one or the other.</p>
",['rpc_address']
34455066,34460870,2015-12-24 15:45:57,How many systems a given rack can hold,"<p>I am getting trained on Apache casssandra, where terms like nodes and racks are quite predominantly used. I understand that a rack is to hold n number of systems or nodes. But was wondering whether there is any upper limit to it, like a rack can hold this many systems.</p>

<p>It was just for the sake of understanding, if any one knows the answer or any points to make on this, please share.</p>
",<cassandra>,"<p>There is no limit to the number of systems in a rack - racks are used to balance replicas within a datacenter, but are not bounded (though certainly, you're limited to a reasonable number of nodes in a datacenter, typically around 1000).</p>

<p>Rack awareness can be tricky, especially if you have fewer racks than your replication_factor, or if your racks are of uneven sizes. Adding a rack after the fact, in particular, can cause significant problems - many operators disable rack awareness to avoid edge cases.</p>
",['rack']
34730779,34731094,2016-01-11 20:48:14,How to store microsecond level timestamps in cassandra?,"<p>I'm trying to store data in cassandra which contains microsecond level timestamps.
Cassandra's docs say that the 'timestamp' data type can store milliseconds since epoch but several messages on the internet seem to imply that cassandra can natively store microsecond timestamps.</p>

<p>What is the best way practice for storing microsecond level times in cassandra? Should I just leave out the date part and store a long?</p>

<p>I'm trying to sore a columsn which look like this:
2015-11-18 07:30:46.700824</p>

<p>I get the following error:</p>

<p>ErrorMessage code=2200 [Invalid query] message=""unable to coerce '2015-11-18 07:30:18.261543' to a  formatted date (long)""</p>

<p>Aborting import at record #1. Previously inserted records are still present, and some records after that may be present as well.</p>

<p>My cassandra version:
[cqlsh 5.0.1 | Cassandra 2.1.11 | CQL spec 3.2.1 | Native protocol v3]</p>

<p>EDIT:
Here is an example of microsecond confusion in Cassandra's own docs:</p>

<p>""CAS and new features in CQL such as DROP COLUMN assume that cell timestamps are microseconds-since-epoch""</p>

<p><a href=""https://docs.datastax.com/en/upgrade/doc/upgrade/cassandra/upgradeChangesC_c.html"" rel=""nofollow"">https://docs.datastax.com/en/upgrade/doc/upgrade/cassandra/upgradeChangesC_c.html</a></p>

<p>Another: <a href=""https://issues.apache.org/jira/browse/CASSANDRA-8297"" rel=""nofollow"">https://issues.apache.org/jira/browse/CASSANDRA-8297</a></p>

<p>EDIT2:
I should mention that I intend to query this using spark. From what I understand, spark parses its own flavor of sql and translates it to cassandra (although I'm using CassandraContext in zeppelin). Anything which might help or hinder my search for microsecond level timestmaps?</p>
",<cassandra>,"<p>You can use bigint or a timeuuid. Type 1 uuid's have 100ns precision so it can cover you. Some utilities, libraries, convenience functions may not give you what you need though so be prepared to write some uuid functions.</p>
",['precision']
34871464,34871831,2016-01-19 08:08:30,How to programmatically determine the number of nodes in a Cassandra Cluster?,"<p>Is there a way to determine the number of nodes in a Cassandra cluster without first having a context?</p>

<p>I am trying to get that number to make sure that the user does not give me a replicating factor that is too large (i.e. says 10 with only 9 nodes.)</p>

<p><strong>Important:</strong> At this point, the only interface I have is thrift in C.</p>

<p><strong>Note:</strong> I looked into using the describe_ring() but unfortunately, the function forces you to have a valid context (so it describes the ring for that context and not the number of existing nodes in a Cassandra cluster.)</p>
",<c><cassandra><thrift><cassandra-2.0>,"<p>You can look at the system table using the Thrift protocol:  <strong>system.peers</strong>. Here are listed <strong>all others nodes</strong> and their information, but not the local node. By counting the number of nodes in <strong>system.peers</strong>, the total node count is entries_count_in_peers + 1</p>

<p>Below is the structure (CQL) of the <strong>system.peers</strong> table</p>

<pre><code>CREATE TABLE system.peers (
    peer inet PRIMARY KEY,
    data_center text,
    host_id uuid,
    preferred_ip inet,
    rack text,
    release_version text,
    rpc_address inet,
    schema_version uuid,
    tokens set&lt;text&gt;
)
</code></pre>

<p>There is one <strong>partition</strong> (row key in Thrift terminology) per node</p>
","['rpc_address', 'rack']"
34944323,34950340,2016-01-22 10:23:06,"Does NetworkTopologyStrategy behave exactly as SimpleStrategy for single rack, single datacenter?","<p>I'm trying to understand <a href=""https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/locator/NetworkTopologyStrategy.java"" rel=""nofollow""><code>NetworkTopologyStrategy</code></a>. Does it behave exactly as <code>SimpleStrategy</code> for a single rack and a single datacenter?</p>
",<cassandra><cassandra-2.0><datastax><datastax-enterprise>,"<p>Yes. SimpleStrategy finds the first replica using the primary key token, then places replicas on subsequent nodes in their order along the token ring. NetworkTopologyStrategy does the same thing, but also skips nodes while looking for unique racks within each datacenter. If it does not find enough, the replicas are placed on nodes in the order they were skipped. With a single rack this results in the same placement as SimpleStrategy.</p>
",['rack']
35005734,35076202,2016-01-26 01:46:00,Constant timeouts in Cassandra after adding second node,"<p>I'm trying to migrate a moderately large swath of data (~41 million rows) from an SQL database to Cassandra.  I've previously done a trial-run using half the dataset, and everything worked exactly as expected.</p>

<p>The problem is, now that I'm trying the complete migration Cassandra is throwing constant timeout errors.  For instance:</p>

<pre><code>[INFO] [talledLocalContainer] com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:10112 (com.datastax.driver.core.exceptions.DriverException: Timed out waiting for server response))
[INFO] [talledLocalContainer]   at com.datastax.driver.core.exceptions.NoHostAvailableException.copy(NoHostAvailableException.java:84)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:289)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:205)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52)
[INFO] [talledLocalContainer]   at com.mycompany.tasks.CassandraMigrationTask.execute(CassandraMigrationTask.java:164)
[INFO] [talledLocalContainer]   at org.quartz.core.JobRunShell.run(JobRunShell.java:202)
[INFO] [talledLocalContainer]   at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
[INFO] [talledLocalContainer] Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:10112 (com.datastax.driver.core.exceptions.DriverException: Timed out waiting for server response))
[INFO] [talledLocalContainer]   at com.datastax.driver.core.RequestHandler.sendRequest(RequestHandler.java:108)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.RequestHandler$1.run(RequestHandler.java:179)
[INFO] [talledLocalContainer]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
[INFO] [talledLocalContainer]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
[INFO] [talledLocalContainer]   at java.lang.Thread.run(Thread.java:745)
</code></pre>

<p>I've tried increasing the timeout values in <code>cassandra.yaml</code>, and that increased the amount of time that the migration was able to run before dying to a timeout (roughly in proportion to the increase in the timeout).  </p>

<p>Prior to changing the timeout settings, my stack-trace looked more like:</p>

<pre><code>[INFO] [talledLocalContainer] com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:54)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:289)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:205)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52)
[INFO] [talledLocalContainer]   at com.mycompany.tasks.CassandraMigrationTask.execute(CassandraMigrationTask.java:164)
[INFO] [talledLocalContainer]   at org.quartz.core.JobRunShell.run(JobRunShell.java:202)
[INFO] [talledLocalContainer]   at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
[INFO] [talledLocalContainer] Caused by: com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency ONE (1 replica were required but only 0 acknowledged the write)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.exceptions.WriteTimeoutException.copy(WriteTimeoutException.java:54)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.Responses$Error.asException(Responses.java:99)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.DefaultResultSetFuture.onSet(DefaultResultSetFuture.java:140)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.RequestHandler.setFinalResult(RequestHandler.java:249)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.RequestHandler.onSet(RequestHandler.java:433)
[INFO] [talledLocalContainer]   at com.datastax.driver.core.Connection$Dispatcher.messageReceived(Connection.java:697)
[INFO] [talledLocalContainer]   at com.datastax.shaded.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
[INFO] [talledLocalContainer]   at com.datastax.shaded.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
[INFO] [talledLocalContainer]   at com.datastax.shaded.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
[INFO] [talledLocalContainer]   at com.datastax.shaded.netty.channel.Channels.fireMessageReceived(Channels.java:296)
[INFO] [talledLocalContainer]   at com.datastax.shaded.netty.handler.codec.oneone.OneToOneDecoder.handleUpstream(OneToOneDecoder.java:70)
</code></pre>

<p>My timeout settings are currently:</p>

<pre><code># How long the coordinator should wait for read operations to complete
read_request_timeout_in_ms: 30000
# How long the coordinator should wait for seq or index scans to complete
range_request_timeout_in_ms: 30000
# How long the coordinator should wait for writes to complete
write_request_timeout_in_ms: 30000
# How long the coordinator should wait for counter writes to complete
counter_write_request_timeout_in_ms: 30000
# How long a coordinator should continue to retry a CAS operation
# that contends with other proposals for the same row
cas_contention_timeout_in_ms: 1000
# How long the coordinator should wait for truncates to complete
# (This can be much longer, because unless auto_snapshot is disabled
# we need to flush first so we can snapshot before removing the data.)
truncate_request_timeout_in_ms: 60000
# The default timeout for other, miscellaneous operations
request_timeout_in_ms: 20000
</code></pre>

<p>...which gets me about 1.5m rows inserted before the timeout happens.  The original timeout settings were:</p>

<pre><code># How long the coordinator should wait for read operations to complete
read_request_timeout_in_ms: 5000
# How long the coordinator should wait for seq or index scans to complete
range_request_timeout_in_ms: 10000
# How long the coordinator should wait for writes to complete
write_request_timeout_in_ms: 2000
# How long the coordinator should wait for counter writes to complete
counter_write_request_timeout_in_ms: 5000
# How long a coordinator should continue to retry a CAS operation
# that contends with other proposals for the same row
cas_contention_timeout_in_ms: 1000
# How long the coordinator should wait for truncates to complete
# (This can be much longer, because unless auto_snapshot is disabled
# we need to flush first so we can snapshot before removing the data.)
truncate_request_timeout_in_ms: 60000
# The default timeout for other, miscellaneous operations
request_timeout_in_ms: 10000
</code></pre>

<p>...which caused the timeouts to happen approximately every 300,000 rows.  </p>

<p>The only significant change that's occurred between when I had my successful run and now is that I added a second node to the Cassandra deployment.  So intuitively I'd think the issue would have something to do with the propagation of data from the first node to the second (as in, there's <code>&lt;some process&gt;</code> that scales linearly with the amount of data inserted and which isn't used when there's only a single node).  But I'm not seeing any obvious options that might be useful for configuring/mitigating this.  </p>

<p>If it's relevant, I'm using batch statements during the migration, typically with between 100 and 200 statements/rows per batch, at most.  </p>

<p>My keyspace was originally set up <code>WITH REPLICATION =
  { 'class' : 'SimpleStrategy', 'replication_factor' : 2 }</code>, but I altered it to be <code>WITH REPLICATION =
  { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }</code> to see if that would make any difference.  It didn't.  </p>

<p>I also tried explicitly setting <code>ConsistencyLevel.ANY</code> on all my insert statements (and also the enclosing batch statements).  That also made no difference.  </p>

<p>There doesn't seem to be anything interesting in Cassandra's log on either node, although the first node is certainly showing more 'ops' than the second:</p>

<p><strong>First node - 454317 ops</strong></p>

<pre><code>INFO  [SlabPoolCleaner] 2016-01-25 19:46:08,806 ColumnFamilyStore.java:905 - Enqueuing flush of assetproperties_flat: 148265302 (14%) on-heap, 0 (0%) off-heap
INFO  [MemtableFlushWriter:15] 2016-01-25 19:46:08,807 Memtable.java:347 - Writing Memtable-assetproperties_flat@350387072(20.557MiB serialized bytes, 454317 ops, 14%/0% of on/off-heap limit)
INFO  [MemtableFlushWriter:15] 2016-01-25 19:46:09,393 Memtable.java:382 - Completed flushing /var/cassandra/data/itb/assetproperties_flat-e83359a0c34411e593abdda945619e28/itb-assetproperties_flat-tmp-ka-32-Data.db (5.249MiB) for commitlog position ReplayPosition(segmentId=1453767930194, position=15188257)
</code></pre>

<p><strong>Second node - 2020 ops</strong></p>

<pre><code>INFO  [BatchlogTasks:1] 2016-01-25 19:46:33,961 ColumnFamilyStore.java:905 - Enqueuing flush of batchlog: 4923957 (0%) on-heap, 0 (0%) off-heap
INFO  [MemtableFlushWriter:22] 2016-01-25 19:46:33,962 Memtable.java:347 - Writing Memtable-batchlog@796821497(4.453MiB serialized bytes, 2020 ops, 0%/0% of on/off-heap limit)
INFO  [MemtableFlushWriter:22] 2016-01-25 19:46:33,963 Memtable.java:393 - Completed flushing /var/cassandra/data/system/batchlog-0290003c977e397cac3efdfdc01d626b/system-batchlog-tmp-ka-11-Data.db; nothing needed to be retained.  Commitlog position was ReplayPosition(segmentId=1453767955411, position=18567563)
</code></pre>

<p>Has anyone encountered a similar issue, and if so, what was the fix?  </p>

<p>Would it be advisable to just take the second node offline, run the migration with just the first node, and then run <code>nodetool repair</code> afterwards to get the second node back in sync? </p>

<p><strong>Edit</strong></p>

<p>Answers to questions from comments:</p>

<ol>
<li><p>I'm using the datastax Java driver, and have a server-side task (<a href=""http://quartz-scheduler.org/api/2.2.0/"" rel=""noreferrer"">Quartz job</a>) that uses the ORM layer (hibernate) to lookup the next chunk of data to migrate, write it into Cassandra, and then purge it from the SQL database.  I'm getting a connection to Cassandra using the following code:</p>

<pre><code>public static Session getCassandraSession(String keyspace) {
    Session session = clusterSessions.get(keyspace);
    if (session != null &amp;&amp; ! session.isClosed()) {
        //can use the cached session
        return session;
    }

    //create a new session for the specified keyspace
    Cluster cassandraCluster = getCluster();
    session = cassandraCluster.connect(keyspace);

    //cache and return the session
    clusterSessions.put(keyspace, session);
    return session;
}

private static Cluster getCluster() {
    if (cluster != null &amp;&amp; ! cluster.isClosed()) {
        //can use the cached cluster
        return cluster;
    }

    //configure socket options
    SocketOptions options = new SocketOptions();
    options.setConnectTimeoutMillis(30000);
    options.setReadTimeoutMillis(300000);
    options.setTcpNoDelay(true);

    //spin up a fresh connection
    cluster = Cluster.builder().addContactPoint(Configuration.getCassandraHost()).withPort(Configuration.getCassandraPort())
                .withCredentials(Configuration.getCassandraUser(), Configuration.getCassandraPass()).withSocketOptions(options).build();

    //log the cluster details for confirmation
    Metadata metadata = cluster.getMetadata();
    LOG.debug(""Connected to Cassandra cluster: "" + metadata.getClusterName());
    for ( Host host : metadata.getAllHosts() ) {
        LOG.debug(""Datacenter:  "" + host.getDatacenter() + ""; Host:  "" + host.getAddress() + ""; Rack: "" + host.getRack());
    }

    return cluster;
}
</code></pre>

<p>The part with the <code>SocketOptions</code> is a recent addition, as the latest timeout error sounded like it was coming from the Java/client side rather than from within Cassandra itself.</p></li>
<li><p>Each batch inserts no more than 200 records.  Typical values are closer to 100.</p></li>
<li><p>Both nodes have the same specs:  </p>

<ul>
<li>Intel(R) Xeon(R) CPU E3-1230 V2 @ 3.30GHz</li>
<li>32GB RAM</li>
<li>256GB SSD (primary), 2TB HDD (backups), both in RAID-1 configurations</li>
</ul></li>
<li><p><strong>First node:</strong></p>

<pre><code>Pool Name                    Active   Pending      Completed   Blocked  All time blocked
CounterMutationStage              0         0              0         0                 0
ReadStage                         0         0          58155         0                 0
RequestResponseStage              0         0         655104         0                 0
MutationStage                     0         0         259151         0                 0
ReadRepairStage                   0         0              0         0                 0
GossipStage                       0         0          58041         0                 0
CacheCleanupExecutor              0         0              0         0                 0
AntiEntropyStage                  0         0              0         0                 0
MigrationStage                    0         0              0         0                 0
Sampler                           0         0              0         0                 0
ValidationExecutor                0         0              0         0                 0
CommitLogArchiver                 0         0              0         0                 0
MiscStage                         0         0              0         0                 0
MemtableFlushWriter               0         0             80         0                 0
MemtableReclaimMemory             0         0             80         0                 0
PendingRangeCalculator            0         0              3         0                 0
MemtablePostFlush                 0         0            418         0                 0
CompactionExecutor                0         0           8979         0                 0
InternalResponseStage             0         0              0         0                 0
HintedHandoff                     0         0              2         0                 0
Native-Transport-Requests         1         0        1175338         0                 0

Message type           Dropped
RANGE_SLICE                  0
READ_REPAIR                  0
PAGED_RANGE                  0
BINARY                       0
READ                         0
MUTATION                     0
_TRACE                       0
REQUEST_RESPONSE             0
COUNTER_MUTATION             0
</code></pre>

<p><strong>Second node:</strong></p>

<pre><code>Pool Name                    Active   Pending      Completed   Blocked  All time blocked
CounterMutationStage              0         0              0         0                 0
ReadStage                         0         0          55803         0                 0
RequestResponseStage              0         0              1         0                 0
MutationStage                     0         0         733828         0                 0
ReadRepairStage                   0         0              0         0                 0
GossipStage                       0         0          56623         0                 0
CacheCleanupExecutor              0         0              0         0                 0
AntiEntropyStage                  0         0              0         0                 0
MigrationStage                    0         0              0         0                 0
Sampler                           0         0              0         0                 0
ValidationExecutor                0         0              0         0                 0
CommitLogArchiver                 0         0              0         0                 0
MiscStage                         0         0              0         0                 0
MemtableFlushWriter               0         0            394         0                 0
MemtableReclaimMemory             0         0            394         0                 0
PendingRangeCalculator            0         0              2         0                 0
MemtablePostFlush                 0         0            428         0                 0
CompactionExecutor                0         0           8883         0                 0
InternalResponseStage             0         0              0         0                 0
HintedHandoff                     0         0              1         0                 0
Native-Transport-Requests         0         0             70         0                 0

Message type           Dropped
RANGE_SLICE                  0
READ_REPAIR                  0
PAGED_RANGE                  0
BINARY                       0
READ                         0
MUTATION                     0
_TRACE                       0
REQUEST_RESPONSE             0
COUNTER_MUTATION             0
</code></pre></li>
<li><p>The output of <code>nodetool ring</code> was very long.  Here's a <code>nodetool status</code> instead:</p>

<pre><code>Datacenter: DC1
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address         Load       Tokens  Owns    Host ID                               Rack
UN  204.11.xxx.1  754.66 MB  1024    ?       8cf373d8-0b3e-4fd3-9e63-fdcdd8ce8cd4  RAC1
UN  208.66.xxx.2  767.78 MB  1024    ?       42e1f336-84cb-4260-84df-92566961a220  RAC2
</code></pre></li>
<li><p>I increased all of Cassandra's timeout values by a factor of 10, and also set the Java driver's read timeout settings to match, and now I'm up to <s>8m</s> 29.4m inserts with no issues.  In theory if the issue scales linearly with the timeout values I should be good up until around 15m inserts (which is at least good enough that I don't need to constantly babysit the migration process waiting for each new error).</p></li>
</ol>
",<java><cassandra><timeout>,"<p>Okay, so I was able to get the timeout errors to stop by doing two things.  First, I increased Cassandra's timeout values on both hosts, as follows:</p>

<pre><code># How long the coordinator should wait for read operations to complete
read_request_timeout_in_ms: 30000
# How long the coordinator should wait for seq or index scans to complete
range_request_timeout_in_ms: 30000
# How long the coordinator should wait for writes to complete
write_request_timeout_in_ms: 30000
# How long the coordinator should wait for counter writes to complete
counter_write_request_timeout_in_ms: 30000
# How long a coordinator should continue to retry a CAS operation
# that contends with other proposals for the same row
cas_contention_timeout_in_ms: 1000
# How long the coordinator should wait for truncates to complete
# (This can be much longer, because unless auto_snapshot is disabled
# we need to flush first so we can snapshot before removing the data.)
truncate_request_timeout_in_ms: 60000
# The default timeout for other, miscellaneous operations
request_timeout_in_ms: 20000
</code></pre>

<p>I suspect those values are unnecessarily large, but those are what I had in place when everything started working.</p>

<p>The second part of the solution was to adjust the client timeout in my Java code, as follows:</p>

<pre><code>//configure socket options
SocketOptions options = new SocketOptions();
options.setConnectTimeoutMillis(30000);
options.setReadTimeoutMillis(300000);
options.setTcpNoDelay(true);

//spin up a fresh connection (using the SocketOptions set up above)
cluster = Cluster.builder().addContactPoint(Configuration.getCassandraHost()).withPort(Configuration.getCassandraPort())
            .withCredentials(Configuration.getCassandraUser(), Configuration.getCassandraPass()).withSocketOptions(options).build();
</code></pre>

<p>With those two changes, the timeout errors stopped and the data migration completed without issue.  </p>

<p>As @MarcintheCloud rightly points out in the comments above, increasing the timeout values may only have the effect of masking the underlying problem.  But that's good enough in my case since 1) the underlying problem only surfaces under very high load, 2) I only need to run the migration process once, and 3) once the data has been migrated, the actual load levels are orders of magnitude lower than what's experienced during the migration.</p>

<p>However, understanding the underlying cause still seems worthwhile.  So what was it?  Well I've got two theories:</p>

<ol>
<li><p>As @MarcintheCloud posits, perhaps 1024 is too many tokens to reasonably use with Cassandra.  And perhaps as a consequence of that the deployment gets a bit flaky under heavy load.</p></li>
<li><p>My alternative theory has to do with network chatter between the two nodes.  In my deployment, the first node runs the app-server instance, the first Cassandra instance, and the primary SQL database.  The second node runs the second Cassandra instance and also a replica SQL database that is kept in sync with the primary database in near-real-time.  </p>

<p>Now, the migration process essentially does two things concurrently; it writes data into Cassandra, and it deletes data from the SQL database.  Both of those actions generate changesets that need to propagate over the network to the second node.  </p>

<p>So my theory is that if changes are happening quickly enough on the first node (since the SSD <em>does</em> allow very high IO throughput), the network transfers of the SQL and Cassandra changelogs (and/or the subsequent IO ops on the second node) may occasionally contend with each other, introducing additional latency into the replication process(es) and potentially leading to timeouts.  It seems plausible that with enough contention, one process or the other might get blocked for several seconds at a time, which is enough to trigger timeout errors at Cassandra's default settings.</p></li>
</ol>

<p>Those are the plausible theories I can think of.  Though no real way of testing to confirm which (if any) is correct.</p>
",['auto_snapshot']
35010995,35014015,2016-01-26 09:52:21,Cassandra nodes appearing in different datacenters,"<p>I am having trouble with three nodes in Cassandra, each of them in an individual computer, as I am trying to set up my first Cassandra structure. I have set up everything as in the Datastax documentation, and I have the same configuration in the different cassandra.yaml of each machine (changing the relative ips). The thing is that after configuring everything, each computer sees each other as DN, and each machine (localhost) appears as UN, with the difference that in the .101 computer I can see two different datacenters, while in the other computers only one datacenter appears. </p>

<p>So in my 192.168.1.101 machine when I type </p>

<pre><code>sudo nodetool status
</code></pre>

<p>I get this output: </p>

<pre><code>Datacenter: DC1
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address        Load       Tokens       Owns    Host ID                               Rack
DN  192.168.1.200  ?          256          ?       968d5d1e-a113-40ce-9521-e392a927ea5e  r1
DN  192.168.1.102  ?          256          ?       fc5c2dbe-8834-4040-9e77-c3d8199b6767  r1
Datacenter: dc1
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address        Load       Tokens       Owns    Host ID                               Rack
UN  127.0.0.1      446.13 KB  256          ?       6d28d540-2b44-4522-8612-b5f70a3d7d52  rack1
</code></pre>

<p>While when I type ""nodetool status"" in one of the other two machines, I get this output: </p>

<pre><code>Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address        Load       Tokens       Owns    Host ID                               Rack
DN  192.168.1.200  ?          256          ?       968d5d1e-a113-40ce-9521-e392a927ea5e  rack1
UN  127.0.0.1      506,04 KB  256          ?       fc5c2dbe-8834-4040-9e77-c3d8199b6767  rack1
DN  192.168.1.101  ?          256          ?       6d28d540-2b44-4522-8612-b5f70a3d7d52  rack1
</code></pre>

<p>In OpsCenter I can only see my 192.168.1.101 machine:</p>

<p><a href=""https://i.stack.imgur.com/DBQod.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DBQod.png"" alt=""OpsCenter displaying only one node""></a></p>

<p>... Which makes me think that something's odd in the yaml file of this machine and the others, but I have checked several times and it seems that the configuration is the same in the other computers. Enpoint_snitch is set to ""GossipingPropertyFileSnitch"". </p>

<p>Any tips on how to solve the reason why all the other nodes appear as Down Normal and why I am getting two datacenters would be highly appreaciated. It's driving me crazy! </p>

<p>Thanks for reading.</p>
",<cassandra><yaml><nosql>,"<p>It looks like some of the installed nodes were dead, so I deleted the nodes that were not the local machine in each of the nodes, ie: </p>

<pre><code>nodetool removenode 968d5d1e-a113-40ce-9521-e392a927ea5e
nodetool removenode fc5c2dbe-8834-4040-9e77-c3d8199b6767
</code></pre>

<p>and after that I got the right output when I executed nodetools status </p>

<pre><code>[machine1]~$ sudo nodetool status
Datacenter: dc1
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address    Load       Tokens       Owns    Host ID                               Rack
UN  127.0.0.1  286.93 KB  256          ?       6d28d540-2b44-4522-8612-b5f70a3d7d52  rack1


[machine2]~$ sudo nodetool status
Datacenter: dc1
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address    Load       Tokens       Owns    Host ID                               Rack
UN  127.0.0.1  268.45 KB  256          ?       fc5c2dbe-8834-4040-9e77-c3d8199b6767  rack1
</code></pre>

<p>And made sure that the parameters cluster_name, seeds, listen_address and rpc_address were right. </p>

<pre><code>cluster_name: 'Test Cluster'
seeds: ""192.168.1.101, 192.168.1.102""
listen_address: 192.168.1.101
rpc_address: 192.168.1.101
</code></pre>

<p>Changing listen_address and rpc_address to the corresponding ip of each machine in their corresponding cassandra.yaml file.</p>

<p>After that I got the right output (I am using only 2 machines for the nodes now):</p>

<pre><code>Datacenter: dc1
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address        Load       Tokens       Owns (effective)  Host ID                               Rack
UN  192.168.1.101  309.13 KB  256          51.6%             6d28d540-2b44-4522-8612-b5f70a3d7d52  rack1
UN  192.168.1.102  257.15 KB  256          48.4%             fc5c2dbe-8834-4040-9e77-c3d8199b6767  rack1
</code></pre>
","['listen_address', 'rpc_address']"
36133127,36139750,2016-03-21 14:03:17,How to configure cassandra for remote connection,"<p>I am trying to configure Cassandra Datastax Community Edition for remote connection on windows, </p>

<p>Cassandra Server is installed on a Windows 7 PC, <strong>With the local CQLSH it connects perfectly to the local server.</strong></p>

<p>But when i try to connect <strong>with CQLSH from another PC in the same Network, i get this error message:</strong> </p>

<blockquote>
  <p>Connection error: ('Unable to connect to any servers', {'MYHOST':
  error(10061, ""Tried connecting to [('HOST_IP', 9042)]. Last error: No
  connection could be made because the target machine actively refused
  it"")})</p>
</blockquote>

<p>So i am wondering how to configure correctly (what changes should i make on cassandra.yaml config file) the Cassandra server to allow  remote connections.</p>

<p>Thank you in advance!</p>
",<cassandra><cqlsh><cassandra-cli><nosql>,"<p>Remote access to Cassandra is via its thrift port for Cassandra 2.0. In Cassandra 2.0.x, the default cqlsh listen port is 9160 which is defined in cassandra.yaml by the rpc_port parameter. By default, Cassandra 2.0.x and earlier enables Thrift by configuring start_rpc to true in the cassandra.yaml file. </p>

<p>In Cassandra 2.1, the cqlsh utility uses the native protocol. In Cassandra 2.1, which uses the Datastax python driver, the default cqlsh listen port is 9042.</p>

<p>The cassandra node should be bound to the IP address of your server's network card - it shouldn't be 127.0.0.1 or localhost which is the loopback interface's IP, binding to this will prevent direct remote access. To configure the bound address, use the rpc_address parameter in cassandra.yaml. Setting this to 0.0.0.0 will listen on all network interfaces.</p>

<p>Have you checked that the remote machine can connect to the Cassandra node? Is there a firewall between the machines? You can try these steps to test this out:</p>

<p><strong>1) Ensure you can connect to that IP from the server you are on:</strong></p>

<p>$ ssh user@xxx.xxx.xx.xx</p>

<p><strong>2) Check the node's status and also confirm it shows the same IP:</strong></p>

<p>$nodetool status</p>

<p><strong>3) Run the command to connect with the IP (only specify the port if you are not using the default):</strong></p>

<p>$ cqlsh xxx.xxx.xx.xx</p>
",['rpc_address']
36217451,36241271,2016-03-25 09:38:39,What is the main difference between partition and column family in Cassandra,"<p>I can't figure out if in the implementation of Apache Cassandra the notion of partition and family column is the same!? It seems that Cassandra is no longer of column family databases but more likely a tabular partitioned database. Can some please explain. I'm following this <a href=""https://pdfs.semanticscholar.org/22c6/740341ef13d3c5ee52044a4fbaad911f7322.pdf"" rel=""nofollow"">paper work</a></p>
",<cassandra><cql><nosql>,"<p>No.</p>

<p>A columnfamily, now called Table (since CQL took over thrift), is a table which is going to be saved on all nodes in your Cassandra cluster.</p>

<p>How the data of a table is broken down on nodes is the work of the partitioner, so the partitioning mechanism has nothing to do with the concept of a table since from the outside you are not supposed to know whether your data is saved on node 1 or node 2 or node 3...</p>

<p>Finally, the partitioner is defined for a cluster as a whole. This, in part, defines things such as whether your rows will be sorted (which is not a good idea because then the number of rows saved on a given node will not be well balanced.)</p>

<p>For additional information, you may want to search for the word ""partition"" on this page:</p>

<p><a href=""http://wiki.apache.org/cassandra/Operations"" rel=""nofollow"">http://wiki.apache.org/cassandra/Operations</a></p>
",['partitioner']
36242493,36246069,2016-03-27 00:27:22,Are sorted columns in Cassandra using just one set of nodes? (one set = repeat factor),"<p>Using older versions of Cassandra, we were expected to create our own sorted rows using a <em>special</em> row of columns, because columns are saved sorted in Cassandra.</p>

<p>Is Cassandra 3.0 with CQL using the same concept when you create a <code>PRIMARY KEY</code>?</p>

<p>Say, for example, that I create a table like so:</p>

<pre><code>CREATE TABLE my_table (
    created_on timestamp,
    ...,
    PRIMARY KEY (created_on)
);
</code></pre>

<p>Then I add various entries like so:</p>

<pre><code>INSERT INTO my_table (created_on, ...) VALUES (1, ...);
...
INSERT INTO my_table (created_on, ...) VALUES (9, ...);
</code></pre>

<p>How does Cassandra manage the sort on the <code>PRIMARY KEY</code>? Will that happens on all nodes, or only one set (what I call a set is the number of replicates, so if you have a cluster of 100 nodes with a replication factor of 4, would the primary key appear on 100 nodes, 25, or just 4? With older versions, it would only be on 4 nodes.)</p>
",<cassandra><primary-key><cql><cql3>,"<p>In your case the primary key is the partition key, which used to be the row key. Which means the data your are inserting will be present on 4 out of 100 nodes if the replication factor is set to 4.</p>

<p>In CQL you can add more columns to the primary key, which are called clustering keys. When querying C* with CQL the result set might contain more than one row for a partition key. Those rows are logical and are stored in the partition of which they share the partition key (but vary in their clustering key values). The data in those logical rows is replicated as the partition is.</p>

<p>Have a look at the example for possible primary keys in the official documentation of the <a href=""https://docs.datastax.com/en/cql/3.1/cql/cql_reference/create_table_r.html"" rel=""nofollow"">CREATE TABLE</a> statement.</p>

<p><strong>EDIT</strong> (row sorting):</p>

<p>C* keeps the partitions of a table in the order of their partition key values' hash code. The ordering is therefor not straight forward and results for range queries by partition key values are not what you would expect them to be. But as partitions are in fact ordered you still can do server side pagination with the help of the <a href=""http://docs.datastax.com/en//cql/3.1/cql/cql_using/paging_c.html"" rel=""nofollow"">token function</a>.
That said, you could employ the <a href=""https://docs.datastax.com/en/cassandra/2.1/cassandra/architecture/architecturePartitionerBOP_c.html"" rel=""nofollow"">ByteOrderedPartitioner</a> to achieve lexical ordering of your partitions. But it is very easy to create hotspots with that partitioner and it is generally discouraged to use it.</p>

<p>The rows of a given partition are ordered by the actual values of their clustering keys. Range queries on those behave as you'd expect them to.</p>
",['partitioner']
36741702,36809977,2016-04-20 10:58:56,Cassandra TTL not working,"<p>I am using datastax with cassandra. I want a row to be automatically deleted after 15 minutes of its insertion. But the row still remains. </p>

<p>My code is below:</p>

<pre><code>Insert insertStatement = QueryBuilder.insertInto(keySpace, ""device_activity"");
        insertStatement.using(QueryBuilder.ttl(15* 60));
        insertStatement.value(""device"", UUID.fromString(persistData.getSourceId()));
        insertStatement.value(""lastupdatedtime"", persistData.getLastUpdatedTime());
        insertStatement.value(""devicename"", persistData.getDeviceName());
        insertStatement.value(""datasourcename"", persistData.getDatasourceName());
</code></pre>

<p>The table consist of 4 columns : device (uuid), datasourcename(text), devicename(text), lastupdatedtime (timestamp).</p>

<p>If I query the TTL of some field it shows me 4126 seconds which is wrong.
//Select TTL(devicename) from device_activity; // Gives me 4126 seconds</p>
",<cassandra><datastax><ttl>,"<p>In the below link, the explanation of TTL is provided.</p>

<p><a href=""https://docs.datastax.com/en/cql/3.1/cql/cql_using/use_expire_c.html"" rel=""nofollow"">https://docs.datastax.com/en/cql/3.1/cql/cql_using/use_expire_c.html</a></p>

<p>""TTL data has a precision of one second, as calculated on the server. Therefore, a very small TTL probably does not make much sense. Moreover, the clocks on the servers should be synchronized; otherwise reduced precision could be observed because the expiration time is computed on the primary host that receives the initial insertion but is then interpreted by other hosts on the cluster.""</p>

<p>After reading this i could resolve by setting proper time on the corresponding node(machine.)</p>
",['precision']
36764437,36766364,2016-04-21 08:49:34,Data Replication In Cassandra,"<p>I am trying to understand data replication in Cassandra. In my case, I have to store a huge number of records into a single table based on yymmddhh primary key partition.</p>

<p>I have two data centers (DC1 and DC2) and I created a keyspace using below CQL.</p>

<pre><code>CREATE KEYSPACE db1 WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'DC1' : 1, 'DC2' : 1 };
</code></pre>

<p>And then created a new table tbl_data using below CQL</p>

<pre><code>CREATE TABLE db1.tbl_data (
        yymmddhh varchar,
        other_details text,
        PRIMARY KEY (yymmddhh)
    ) WITH read_repair_chance = 0.0;
</code></pre>

<p>Now, I can see that the above keyspace ""db1"" and table ""tbl_data"" created successfully. I have few millions of rows to insert, I am assuming that all rows will be stored on both servers i.e. DC1 and DC2 since replication factor is 1 of both data centers.</p>

<p>Suppose, after some time I need to add more nodes since number of records can increase to billions, so in that case one data center can't handle that huge number of records due to disk space limitation. </p>

<p><strong>a)</strong> So, how can I divide data into different nodes and can add new nodes on demand?</p>

<p><strong>b)</strong> Do I need to alter keyspace ""db1"" to put name of new data centers in the list?</p>

<p><strong>c)</strong> How the current system will work horizontally?</p>

<p><strong>d)</strong> I am connecting Cassandra using nodejs driver by using below code. Do I need to put ip address of all nodes here in code? What If I keep increasing the number of nodes on demand, do I need to change the code every time?</p>

<pre><code>var client = new cassandra.Client({ contactPoints: ['ipaddress_of_node1'], keyspace: 'db1' });
</code></pre>

<p>From all above examples you can see that my basic requirement is to store a huge number of records into a single table spreading data to different servers where I should be able to add new servers if data volume increases.</p>
",<cassandra>,"<p>a) If you add new nodes to the data center, the data will be automatically shared between the nodes. With replication factor 1 and default settings, it should be ~50% on each node, though it might take a bit to redistribute data between the nodes after adding a new node. 'nodetool status ' can show you which node owns how much of that keyspace.</p>

<p>b) Yes, I do believe you have to (though not 100% on this).</p>

<p>c) Horizontally with your setup it'll scale linearly (assuming the machines are equal and have the same num_tokens value) by distributing data as according to 1 divided on number of nodes (1 node = 100%, 2 = 50%, 3 = 33%, etc.), both throughput and storage capacity will scale.</p>

<p>d) No, assuming the nodejs driver works like the C++ and Python drivers of Cassandra (it should!), after connecting to Cassandra it'll be aware of the other nodes in the cluster.</p>
",['num_tokens']
37191751,37218301,2016-05-12 15:46:34,Unable to add another node to existing node to form a cluster. Couldn't change num_tokens to vnodes,"<p>i have installed cassandra on two individual nodes both on Amazon.when i am trying to configure nodes to form a cluster the nodes. I am receiving the following error.</p>

<p><strong><em>ERROR [main] 2016-05-12 11:01:26,402  CassandraDaemon.java:381 - Fatal configuration error
org.apache.cassandra.exceptions.ConfigurationException: Cannot change the number of tokens from 1 to 256.</em></strong></p>

<p>I using these setting in  cassandra.yaml file</p>

<p>listen_address and rpc_address to : private Ip address</p>

<p>seeds : Public Ip [Elastic Ip address]</p>

<p>num_tokens: 256</p>
",<amazon-ec2><cassandra><datastax-enterprise>,"<p>This message usually appears when num_tokens is changed after the node has been bootstrapped.</p>

<p>The solution is:</p>

<ol>
<li>Stop Cassandra on all nodes</li>
<li>Delete the data directory (inc. datafiles, commitlog and saved_caches)</li>
<li>Double check that <code>num_tokens</code> is set to <code>256</code>, <code>initial_token</code> is commented out and <code>auto_bootstrap</code> is set to <code>true</code> in cassandra.yaml</li>
<li>Start Cassandra on all nodes</li>
</ol>

<p>This will wipe your existing cluster and cause the nodes to bootstrap from scratch again.</p>

<p>Cassandra doesn't support changing between vnodes and static tokens after a datacenter is bootstrapped. If you need to change from vnodes to static tokens or vice versa in an already running cluster, you'll need to create a second datacenter using the new configuration, stream your data across, and then decomission the original nodes.</p>
",['num_tokens']
37237596,37238543,2016-05-15 11:18:05,Change Cassandra datacenter name,"<p>Is it possible to change the datacenter name in a Cassandra Cluster?
If so how do I accomplish this? I have a Dev cluster which was built with the default DC name 'Cassandra'. I would like to change this because we are going to be setting up and testing replication between DCs.</p>
",<cassandra>,"<p>Its possible you can change the snitch to GossipingFilePropertySnitch and specify the dc name and rack name in <code>cassandra-rackdc.properties</code> file, After doing that you need to restart the node, in that case you will get an error like :</p>

<pre><code>Error: Cannot start node if snitch's data center (&lt;new-datacentername&gt;) differs from previous data center (&lt;old-datacenter-name&gt;). 
Please fix the snitch configuration, decommission and rebootstrap this node or use the flag -Dcassandra.ignore_dc=true.
</code></pre>

<p>In order to avoid this need to add the below line in <code>cassandra-env.sh</code> file and restart the node. </p>

<pre><code>JVM_OPTS=\""$JVM_OPTS -Dcassandra.ignore_rack=true -Dcassandra.ignore_dc=true\""'
</code></pre>

<p>Remember, you will need downtime for your cluster to restart your datacenter in this case if doing this on production environment.</p>
","['rack', 'dc']"
37480186,37515887,2016-05-27 09:45:59,DataStax Community: Inconsistent reads,"<p>We're using datastax-community-64bit_2.2.6 and DevCenter-1.4.1-win-x86 on a Windows Server 2012 (and same setup on an older Win Server 2008, that does NOT seem to experience the problem).</p>

<p>We have a time series table that is behaving VERY oddly with inconsistent reads. We have a full day of data, but data for some hours in the day is NOT loaded, when we perform queries - both through code and through DevCenter, as seen on the following screenshot:::</p>

<p>devcenter lookups::: <a href=""https://drive.google.com/file/d/0B_e9YTMgramiSTFqUGFPYVB3bkk"" rel=""nofollow"">https://drive.google.com/file/d/0B_e9YTMgramiSTFqUGFPYVB3bkk</a></p>

<p>As can be seen - the hour 7-8 cannot be loaded directly - as the hour from 9-10 can.
Loading just the hour 7-8 while using >= and &lt; is possible (the top select), which just confuses matters even more.</p>

<p>In our application it gives a lot of the hours in the day as unknown (the icon with the ?) - as no data is loaded from Cassandra....see next screenshot::</p>

<p>missing hours in application::: <a href=""http://drive.google.com/open?id=0B_e9YTMgramiTUxfNTlJYlVwUEU"" rel=""nofollow"">http://drive.google.com/open?id=0B_e9YTMgramiTUxfNTlJYlVwUEU</a></p>

<p>The hours with a green icon are the same that we are able to query in DevCenter (as the hour 9-10 was on figure 2) - while the rest are not.
Making this even more cryptic is the fact that we load the same data for trend graphs where points for ALL hours are included.</p>

<p>Has anyone ever experienced anything like this??? ....it seems data for some hours are ALWAYS selectable from Cassandra, while others have issues :/
...and of course all data is inserted the same way!!</p>
",<cassandra><datastax><datastax-startup>,"<p>So, when you query it by time range, you get the data back. When you query it by exact time match, you do not get the data for some timestamps. Correct? If it is correct, it is most likely you have got your timestamps recorded with precision higher than a second. Querying by exact timestamp match is almost never a good idea, unless you know exact timestamp value up to the required precision.</p>
",['precision']
37591435,37591944,2016-06-02 12:07:18,How to connect Node.js with Cassandra?,"<p>I've been trying to connect Node.js with Cassandra on localhost for 50 years (feel like it), but haven't figured out how they work together. I would appreciate any suggestion that could lead to solution.</p>

<p><strong>Project Directory:</strong></p>

<pre><code>project  - app - some files
        \- build - index.js, index.html, etc.(I start the server by ""node index.js"")
        \- node_modules - some modules
        \- signup - some files to be minified
        \- signin - some files to be minified
        \- apache-cassandra-3.0.6 - bin, conf, etc.(downloaded from tarball)
        \- package.json
        \- webpack.config.js
</code></pre>

<p>Webpack is working without any problem, so the problem doesn't exist in webpack configuration.<br>
I can insert data using cqlsh, so the problem isn't the model of data structure.</p>

<p>I believe the problem is my lack of knowledge about how to use Node.js and  Cassandra together.</p>

<p><strong>My process to connect Node.js with Cassandra:</strong></p>

<ol>
<li>go to build directory</li>
<li><code>node index.js</code></li>
<li>open localhost:3000 and find the home page, routed by express.js, displayed with no problem.</li>
<li>go to sign-up page and submit a form</li>
<li>error (no data inserted)</li>
</ol>

<hr>

<p>I'm not sure which contact point is correct, '127.0.0.1:9042' or '127.0.0.1'</p>

<pre><code>var client = new cassandra.Client({contactPoints:['127.0.0.1:9042']});
                   OR
var client = new cassandra.Client({contactPoints:['127.0.0.1']});
</code></pre>

<p>I set my router like this.</p>

<pre><code>var router = express.Router();
var insertUser = 'INSERT INTO keyspace.users (username, create_time, email, password) VALUES (?, ?, ?, ?);';

router.get""/"", function(req, res) {
  res.sendFile(__dirname + '/index.html'); // This is working.
});

router.post(""/signup"", function(req, res) {
  var username = req.body.username;
  var email = req.body.email;
  var password = req.body.password;
  client.execute(insertUser, [username, now(), email, password], 
  { prepare: true }, function(err) {
    if (err) {
      console.log(""error""); // I receive error.
    } else {
      console.log(""success"");
    }
  });
});
</code></pre>

<p>Should I keep the cassandra running in the background like this?</p>

<p><code>cd apache-cassandra-3.0.6</code> -> <code>cd bin</code> -> <code>./cassandra</code></p>

<p>What am I missing here?</p>
",<node.js><cassandra>,"<p>Based the error message you provided, it looks like you have <code>PasswordAuthenticator</code> authentication or some other authenticator set up on your Cassandra instance.   Check your 'authenticator' property in your cassandra.yaml file, is it set to <code>PasswordAuthenticator</code>, <code>AllowAllAuthenticator</code>, or something else?</p>

<p>If using <code>PasswordAuthenticator</code>, you can specify credentials by passing a <code>PlainTextAuthenticator</code> instance to your client options as <code>authProvider</code>:</p>



<pre><code>var PlainTextAuthProvider = cassandra.auth.PlainTextAuthProvider;
var client = new cassandra.Client({ contactPoints:['127.0.0.1:9042'], 
                                    authProvider: new PlainTextAuthProvider('cassandra', 'cassandra')};
</code></pre>

<p>The default user made available when using authentication is 'cassandra' with password 'cassandra', but you can change this by following <a href=""https://docs.datastax.com/en/cassandra/2.1/cassandra/security/security_config_native_authenticate_t.html"" rel=""noreferrer"">Configuring Authentication</a>.</p>
",['authenticator']
37940630,37982696,2016-06-21 09:31:56,Cassandra Vnodes and token Ranges,"<p>I know that Vnodes form many token ranges for each node by setting num_tokens in cassandra.yaml file.</p>

<p>say for example (a), i have 6 nodes, each node i have set num_token=256. How many virtual nodes are formed among these 6 nodes that is, how many virtual nodes or sub token ranges contained in each physical node.</p>

<p>According to my understanding, when every node has assigned num_token as 256, then it means that all the 6 nodes contain 256 vnodes each. Is this statement true? if not then, how vnodes form the range of tokens (obviously random) in each node. It would be really convenient if someone can explain me with the example mentioned as (a).</p>

<p>what is the Ring of Vnodes signify in this url:=> <a href=""http://docs.datastax.com/en/cassandra/3.x/cassandra/images/arc_vnodes_compare.png"" rel=""noreferrer"">http://docs.datastax.com/en/cassandra/3.x/cassandra/images/arc_vnodes_compare.png</a> (taken from: <a href=""http://www.datastax.com/dev/blog/virtual-nodes-in-cassandra-1-2"" rel=""noreferrer"">http://www.datastax.com/dev/blog/virtual-nodes-in-cassandra-1-2</a> )</p>
",<cassandra>,"<p>Every partition key in Cassandra is converted to a numerical token value using the MurMur3 hash function. The token range is between -2^63 to +2^63 -1
num_token defines how many token ranges are assigned to a node. this is the same as the signed java long. Each node calculates 256 (num_tokens) random values in the token range and informs other nodes what they are, thus when a node needs to coordinate a request for a specific token it knows which nodes are responsible for it, according to the Replication Factor and DC/rack placement.
A better description for this feature would be ""automatic token range assignment for better streaming capabilities"", calling it ""virtual"" is a bit confusing.
In your case you have 6 nodes, each set with 256 token ranges so you have 6*256 token ranges and each psychical node contains 256 token ranges.</p>

<p>For example consider 2 nodes with num_tokens set to 4 and token range 0 to 100.
Node 1 calculates tokens 17, 35, 77, 92
Node 2 calculates tokens 4, 25, 68, 85
The ring shows the distribution of token ranges in this case
Node 2 is responsible for token ranges 4-17, 25-35, 68-77, 85-92 and node 1 for the rest.</p>
",['num_tokens']
38210719,38215999,2016-07-05 18:58:11,Will Cassandra avoid calculating the row MD5 if the value already is an MD5?,"<p>From various documents about Cassandra, it clearly says that it converts row keys to an MD5 before saving them in the database.</p>

<p>If my row keys already are MD5 sums, is there a way to let Cassandra know and thus avoid having it calculate the MD5 of that MD5?</p>

<p>P.S. The table I am talking about has files in it and the keys are the files MD5 sums.</p>
",<cassandra><cql3><md5sum><cassandra-3.0>,"<p>What Cassandra actually does is hash the partition key based on what the partitioner defines. The original partitioner was MD5, but modern versions of Cassandra default to Murmur3 (not QUITE murmur3, but basically murmur3).</p>

<p>In either case, yes, Cassandra hashes the partition key, because there is no way to let Cassandra know that it's already an MD5. </p>

<p>If you <strong>really</strong> want to avoid the hashing, you can look at other alternative partitioners (such as <a href=""https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/dht/ByteOrderedPartitioner.java"" rel=""nofollow"">byte ordered</a> or <a href=""https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/dht/OrderPreservingPartitioner.java"" rel=""nofollow"">order preserving</a> ), or write your own that implements <a href=""https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/dht/IPartitioner.java"" rel=""nofollow"">IPartitioner</a> . Note, though, that if you do use a different partitioner, it's used for all tables/keyspaces in the cluster. </p>
",['partitioner']
38254971,38255215,2016-07-07 20:46:26,"Datastax Cassandra Driver always attempts to connect to localhost, even though it's not configured to do so","<p>So I have the following Client code: </p>

<pre><code>def getCluster:Session = {
    import collection.JavaConversions._
    val endpoints = config.getStringList(""cassandra.server"")
    val keyspace = config.getString(""cassandra.keyspace"")

    val clusterBuilder = Cluster.builder

    endpoints.toTraversable.map { x =&gt;
      clusterBuilder.addContactPoint(x)
    }
    val cluster = clusterBuilder.build
    cluster
      .getConfiguration
      .getProtocolOptions
      .setCompression(ProtocolOptions.Compression.LZ4)
    cluster.connect(keyspace)}
</code></pre>

<p>which is shamelessly borrowed from the examples in datastax's driver documentation. </p>

<p>When I attempt to execute code with it, it always tries to connect to localhost, even though it's not configured for that... </p>

<p>In some cases, it will connect (basic reads) but for writes I get the following log message: </p>

<pre><code> 2016-07-07 11:34:31 DEBUG Connection:157 - Connection[/127.0.0.1:9042-10, inFlight=0, closed=false] Error connecting to /127.0.0.1:9042 (Connection refused: /127.0.0.1:9042)
2016-07-07 11:34:31 DEBUG STATES:404 - Defuncting Connection[/127.0.0.1:9042-10, inFlight=0, closed=false] because: [/127.0.0.1] Cannot connect
2016-07-07 11:34:31 DEBUG STATES:108 - [/127.0.0.1:9042] Connection[/127.0.0.1:9042-10, inFlight=0, closed=false] failed, remaining = 0
2016-07-07 11:34:31 DEBUG Connection:629 - Connection[/127.0.0.1:9042-10, inFlight=0, closed=true] closing connection
2016-07-07 11:34:31 DEBUG Cluster:1802 - Aborting onDown because a reconnection is running on DOWN host /127.0.0.1:9042
2016-07-07 11:34:31 DEBUG Cluster:1872 - Failed reconnection to /127.0.0.1:9042 ([/127.0.0.1] Cannot connect), scheduling retry in 512000 milliseconds
2016-07-07 11:34:31 DEBUG STATES:196 - [/127.0.0.1:9042] next reconnection attempt in 512000 ms
</code></pre>

<p>I can't figure out where/what I need to configure on the driver side (no local client, it's just the driver) to correct this issue</p>
",<scala><cassandra><datastax-java-driver>,"<p>My guess is that this is caused by configuration of the <code>cassandra.yaml</code> file on your cassandra node(s).  The two main settings that would impact this are <code>broadcast_rpc_address</code> and <code>rpc_address</code>, from <a href=""https://docs.datastax.com/en/cassandra/2.1/cassandra/configuration/configCassandra_yaml_r.html"" rel=""nofollow noreferrer"">The cassandra.yaml configuration</a> reference:</p>
<blockquote>
<p>broadcast_rpc_address</p>
<p>(Default: unset) RPC address to broadcast to drivers and other Cassandra nodes. This cannot be set to 0.0.0.0. If blank, it is set to the value of the rpc_address or rpc_interface. If rpc_address or rpc_interfaceis set to 0.0.0.0, this property must be set.</p>
<p>rpc_address</p>
<p>(Default: localhost) The listen address for client connections (Thrift RPC service and native transport).</p>
</blockquote>
<p>If you leave both of these to the defaults, <code>localhost</code> will be the default address cassandra will communicate to connect on.</p>
<p>After the driver is able to connect to a contact point, it queries the <code>system.local</code> and <code>system.peers</code> table of the contact point to determine which hosts to connect to, the addresses those tables communicate are from <code>rpc_address</code>/<code>broadcast_rpc_address</code></p>
",['rpc_address']
38296328,38315855,2016-07-10 20:46:57,How to add a decommissioned node in cassandra?,"<p>I just did nodetool decommission and it removed the node and I am trying to add it back in so I just started cassandra(decomissioned node) again but it doesnt seem to join the cluster?</p>
",<cassandra>,"<p>The other nodes will remember that the host ID you decommissioned should no longer be part of the cluster and will refuse to talk to it.</p>

<p>So if you want that machine to rejoin the cluster, you have to make it look like a new empty node so that the remaining nodes will let it rejoin. The easiest way to do that is to clear out all the data on the decommissioned node so that it will generate a new host ID for itself. Then it should be able to rejoin.</p>

<p>To clear out the old data, do this:</p>

<p>Stop Cassandra on the node, then:</p>

<pre><code>rm -r &lt;the commitlog_directory specified in cassandra.yaml&gt;
rm -r &lt;the data_file_directories specified in cassandra.yaml&gt;
rm &lt;the contents of the saved_caches_directory specified in cassandra.yaml&gt;
rm &lt;old logfiles in /var/log/cassandra/&gt;
</code></pre>

<p>Then restart the Cassandra service</p>
","['data_file_directories', 'commitlog_directory', 'saved_caches_directory']"
38506734,38509423,2016-07-21 14:17:47,Cassandra commit log clarification,"<p>I have read over several documents regarding the Cassandra commit log and, to me, there is conflicting information regarding this ""structure(s)"". The diagram shows that when a write occurs, Cassandra writes to the memtable and commit log. The confusing part is where this commit log resides.</p>

<p>The diagram that I've seen over-and-over shows the commit log on disk. However, if you do some more reading, they also talk about a commit log buffer in memory - and that piece of memory is flushed to disk every 10 seconds.</p>

<p>DataStax Documentation states: 
""When a write occurs, Cassandra stores the data in a memory structure called memtable, and to provide configurable durability, it also appends writes to the commit log buffer in memory. This buffer is flushed to disk every 10 seconds"". </p>

<p>Nowhere in their diagram do they show a memory structure called a commit log buffer. They only show the commit log residing on disk.</p>

<p>It also states:
""When a write occurs, Cassandra stores the data in a structure in memory, the memtable, and also appends writes to the commit log on disk.""</p>

<p>So I'm confused by the above. Is it written to the commit log memory buffer, which is eventually flushed to disk (which I would assume is also called the ""commit log""), or is it written to the memtable and commit log on disk?</p>

<p>Apache's documentation states this:
""Instead, like other modern systems, Cassandra provides durability by appending writes to a commitlog first. This means that only the commitlog needs to be fsync'd, which, if the commitlog is on its own volume, obviates the need for seeking since the commitlog is append-only. Implementation details are in ArchitectureCommitLog.</p>

<p>Cassandra's default configuration sets the commitlog_sync mode to periodic, causing the commitlog to be synced every commitlog_sync_period_in_ms milliseconds, so you can potentially lose up to that much data if all replicas crash within that window of time.""</p>

<p>What I have inferred from the Apache statement is that ONLY because of the asynchronous nature of writes (acknowledgement of a cache write) could you lose data (it even states you can lose data if all replicas crash before it is flushed/sync'd). </p>

<p>I'm not sure what I can infer from the DataStax documentation and diagram as they've mentioned two different statements regarding the commit log - one in memory, one on disk.</p>

<p>Can anyone clarify, what I consider, a poorly worded and conflicting set of documentation?</p>

<p>I'll assume there is a commit log buffer, as they both reference it (yet DataStax doesn't show it in the diagram). How and when this is managed, I think, is a key to understand.</p>
",<cassandra><datastax>,"<p>Generally when explaining the write path, the commit log is characterized as a file - and it's true the commit log is the on-disk storage mechanism that provides durability.  The confusion is introduced when going deeper and the part about buffer cache and having to issue fsyncs is introduced.  The reference to ""commit log buffer in memory"" is talking about OS buffer cache, not a memory structure in Cassandra. You can see in the <a href=""https://github.com/apache/cassandra/blob/cassandra-2.2/src/java/org/apache/cassandra/db/commitlog/CommitLog.java#L272"" rel=""noreferrer"">code</a> that there's not a separate in-memory structure for the commit log, but rather the mutation is serialized and written to a <a href=""https://github.com/apache/cassandra/blob/cassandra-2.2/src/java/org/apache/cassandra/db/commitlog/CommitLogSegment.java#L145"" rel=""noreferrer"">file-backed buffer</a>.</p>

<p>Cassandra comes with two strategies for managing fsync on the commit log.</p>

<pre><code>commitlog_sync 
    (Default: periodic) The method that Cassandra uses to acknowledge writes in milliseconds:
    periodic: (Default: 10000 milliseconds [10 seconds])
    Used with commitlog_sync_period_in_ms to control how often the commit log is synchronized to disk. Periodic syncs are acknowledged immediately.

    batch: (Default: disabled)note
    Used with commitlog_sync_batch_window_in_ms (Default: 2 ms) to control how long Cassandra waits for other writes before performing a sync. When using this method, writes are not acknowledged until fsynced to disk.
</code></pre>

<p>The <code>periodic</code> offers better performance at the cost of a small increase in the chance that data can be lost.  The <code>batch</code> setting guarantees durability at the cost of latency.</p>
",['commitlog_sync_batch_window_in_ms']
38718623,38721676,2016-08-02 11:01:37,Connecting two desktop PC into multi node cluster Cassandra,"<p>I'm doing this for the very first time and I need help about clearing some stuffs. 
I have Ubuntu 14.04 desktop on one machine, and on the other I have Windows 8.1. also on both machines I have installed the same version of Cassandra. </p>

<p>Can someone tell me, is it possible to connect 2 desktop machines and make a cluster with 2 nodes in Cassandra and how?</p>
",<cassandra><replication><datastax><hierarchical-clustering><cassandra-2.1>,"<p>You need make sure the following settings are set correctly in the cassandra.yaml on each machine:</p>

<ol>
<li>cluster_name - this needs to be the same on both nodes</li>
<li>seed_provider.parameters.seeds - this needs to be set to the external IP address of one of the nodes and needs to be the same on both nodes.</li>
<li>listen_address - this needs to be set to the external IP address on each machine.</li>
</ol>

<p>Note: Make sure you can ping each machine from the other on the IP address you use for the listen_address and make sure that the storage_port 7000 isn't blocked by a firewall on either machine.</p>
","['listen_address', 'storage_port']"
38730024,38733805,2016-08-02 20:37:57,cannot connect to local Cassandra instance?,"<p>I am a Cassandra newbie so this is a very rudimentary question. For my project I need an older version of Cassandra, so I installed it like so: </p>

<pre><code>brew install python
brew install homebrew/versions/cassandra22
pip install cql
</code></pre>

<p>After that, I simply started it via Homebrew too, like so:</p>

<pre><code>brew services start homebrew/versions/cassandra22
</code></pre>

<p>I can see it in the list of services having been started:</p>

<pre><code>tracyxia$ brew services list
Name        Status  User     Plist
cassandra22 started tracyxia  /Users/tracyxia/Library/LaunchAgents/homebrew.mxcl.cassandra22.plist
</code></pre>

<p>Furthermore, I can also see it running as a service on my Mac:</p>

<pre><code>tracyxia$ ps -ef | grep cassandra
1425523232  9962 87919   0  4:33PM ttys000    0:00.00 grep cassandra
</code></pre>

<p>But when I try to connect to my local instance of Cassandra via DevCenter, I kept getting the ""cannot connect to host"" error. :( I am pretty sure this is an installation issue because it works perfectly fine when I installed Cassandra 3.0.7 (current default version for Homebrew cassandra). </p>

<p>Any help would be most appreciated! </p>
",<cassandra>,"<p><a href=""https://docs.datastax.com/en/cassandra/1.2/cassandra/configuration/configCassandra_yaml_r.html"" rel=""nofollow"">configure</a> listen_address and rpc_address as below in cassandra.yaml</p>

<p>listen_address : 192.168.1.15 (configure local IP)</p>

<p>rpc_address : 0.0.0.0</p>
","['listen_address', 'rpc_address']"
38738282,38857262,2016-08-03 08:26:06,YCSB low read throughput cassandra,"<p>The <a href=""http://www.datastax.com/wp-content/themes/datastax-2014-08/files/NoSQL_Benchmarks_EndPoint.pdf"" rel=""nofollow"">YCSB Endpoint benchmark</a> would have you believe that Cassandra is the golden child of Nosql databases.  However, recreating the results on our own boxes (8 cores with hyperthreading, 60 GB memory, 2 500 GB SSD), we are having dismal read throughput for workload b (read mostly, aka 95% read, 5% update).</p>

<p>The cassandra.yaml settings are exactly the same as the Endpoint settings, barring the different ip addresses, and our disk configuration (1 SSD for data, 1 for a commit log).  While their throughput is ~38,000 operations per second, ours is ~16,000 regardless (relatively) of the threads/number of client nodes.  I.e. one worker node with 256 threads will report ~16,000 ops/sec, while 4 nodes will each report ~4,000 ops/sec</p>

<p>I've set the readahead value to 8KB for the SSD data drive.  I'll put the custom workload file below.</p>

<p>When analyzing disk io &amp; cpu usage with iostat, it seems that the reading throughput is consistently ~200,000 KB/s, which seems to suggest that the ycsb cluster throughput should be higher (records are 100 bytes).  ~25-30% of cpu seems to be under %iowait, 10-25% in use by the user.</p>

<p>top and nload stats are not ostensibly bottlenecked (&lt;50% memory usage, and 10-50 Mbits/sec for a 10 Gb/s link).</p>

<pre><code># The name of the workload class to use
workload=com.yahoo.ycsb.workloads.CoreWorkload

# There is no default setting for recordcount but it is
# required to be set.
# The number of records in the table to be inserted in
# the load phase or the number of records already in the
# table before the run phase.
recordcount=2000000000

# There is no default setting for operationcount but it is
# required to be set.
# The number of operations to use during the run phase.
operationcount=9000000

# The offset of the first insertion
insertstart=0
insertcount=500000000

core_workload_insertion_retry_limit = 10
core_workload_insertion_retry_interval = 1

# The number of fields in a record
fieldcount=10

# The size of each field (in bytes)
fieldlength=10

# Should read all fields
readallfields=true

# Should write all fields on update
writeallfields=false

fieldlengthdistribution=constant

readproportion=0.95

updateproportion=0.05

insertproportion=0

readmodifywriteproportion=0

scanproportion=0

maxscanlength=1000

scanlengthdistribution=uniform

insertorder=hashed

requestdistribution=zipfian
hotspotdatafraction=0.2

hotspotopnfraction=0.8
table=usertable

measurementtype=histogram

histogram.buckets=1000
timeseries.granularity=1000
</code></pre>
",<cassandra><benchmarking><ycsb>,"<p>The key was increasing native_transport_max_threads in the casssandra.yaml file.</p>

<p>Along with the increased settings in the comment (increasing connections in ycsb client as well as concurrent read/writes in cassandra), Cassandra jumped to ~80,000 ops/sec.</p>
",['native_transport_max_threads']
38931909,38974587,2016-08-13 10:49:10,Cassandra : Batch write optimisation,"<p>I get bulk write request for let say some 20 keys from client.
I can either write them to C* in one batch or write them individually in async way and wait on future to get them completed.</p>

<p>Writing in batch does not seem to be a goo option as per documentation as my insertion rate will be high and if keys belong to different partitions co-ordinators will have to do extra work.</p>

<blockquote>
  <p>Is there a way in datastax java driver with which I can group keys
  which could belong to same partition and then club them into small
  batches and then do invidual unlogged batch write in async. IN that
  way i make less rpc calls to server at the same time coordinator will
  have to write locally. I will be using token aware policy.</p>
</blockquote>
",<cassandra><datastax><datastax-java-driver><cassandra-3.0>,"<p>Your idea is right, but there is no built-in way, you usually do that manually. </p>

<p>Main rule here is to use <code>TokenAwarePolicy</code>, so some coordination would happen on driver side.
Then, you could group your requests by equality of partition key, that would probably be enough, depending on your workload. </p>

<p>What I mean by 'grouping by equality of partition key` is e.g. you have some data that looks like </p>

<pre><code>MyData { partitioningKey, clusteringKey, otherValue, andAnotherOne }
</code></pre>

<p>Then when inserting several such objects, you group them by <code>MyData.partitioningKey</code>. It is, for all existsing <code>paritioningKey</code> values, you take all objects with same <code>partitioningKey</code>, and wrap them in <code>BatchStatement</code>. Now you have several <code>BatchStatements</code>, so just execute them.</p>

<p>If you wish to go further and mimic cassandra hashing, then you should look at cluster metadata via <code>getMetadata</code> method in <code>com.datastax.driver.core.Cluster</code> class, there is method <code>getTokenRanges</code> and compare them to result of <code>Murmur3Partitioner.getToken</code> or any other partitioner you configured in <code>cassandra.yaml</code>. I've never tried that myself though.</p>

<p>So, I would recommend to implement first approach, and then benchmark your application. I'm using that approach myself, and on my workload it works far better than without batches, let alone batches without grouping.</p>
",['partitioner']
38973463,38976606,2016-08-16 11:15:02,How to update configuration of a Cassandra cluster,"<p>I have a 3 node Cassandra cluster and I want to make some adjustments to the cassandra.yaml</p>

<p>My question is, how should I perform this? One node at a time or is there a way to make it happen without shutting down nodes?</p>

<p>Btw, I am using Cassandra 2.2 and this is a production cluster.</p>
",<cassandra><devops>,"<p>There are multiple approaches here:</p>

<ol>
<li><p>If you edit the cassandra.yaml file, you need to restart cassandra to re-read the contents of that file. If you restart all nodes at once, your cluster will be unavailable. Restarting one node at a time is almost always safe (provided you have sane replication-factors and consistency-levels). If your cluster is configured to survive a rack or datacenter outage, then you can safely restart more nodes concurrently.</p></li>
<li><p>Many settings can be changed without a restart via JMX, though I don't have a documentation link handy. Changing via JMX WON'T change cassandra.yml though, so you'll need to update that also or your config will revert back to what's in the file when the node restarts.</p></li>
<li><p>If you're using DSE, OpsCenter's Lifecycle Manager feature makes updating configs a simple point-and-click affair (disclaimer, I'm biased as I'm an LCM dev).</p></li>
</ol>
",['rack']
39144713,39151096,2016-08-25 11:58:51,Cassandra compaction takes too much RAM,"<p>Running an 8-node Cassandra 2.2.5 cluster with a CF about 1TB big. </p>

<p>Switching to LeveledCompactionStrategy for this CF causes thousands of compaction jobs, which doesn't seem to be problem by itself. But Cassandra starts using constantly increasing amount of RAM, eventually getting killed by the kernel.</p>

<p>What might be the reason C* uses 100G of RAM to merge some sorted files?</p>
",<cassandra><cassandra-2.0><nosql>,"<p>The initial switch to LCS will cause a massive recompaction of all the data. If you've got a TB, that's a lot of SSTables, and a lot of compactions. When Cassandra does a compaction, it's not as simple as ""merging some sorted files"" as it actually has to merge updates and tombstones across the SSTables, requiring more processing than just a simple comparison.</p>

<p>Compactions will use RAM, however unless you've configured differently the defaults should have a limit on heap size and also on number of concurrent compactions. Having said that Cassandra will utilise cached memory as best it can, however this shouldn't cause issues.</p>

<p>If you have very wide partitions Cassandra will also use more off-heap memory during compactions, however 100GB is excessive. I suggest you configure your heap size, compaction throughput, and concurrent_compactors to be lower to hopefully avoid the oom-killer.  </p>

<p>You should be switching to LCS one node/rack at a time using JMX if the cluster is under load, have a look at this guide for the info <a href=""http://blog.alteroot.org/articles/2015-04-20/change-cassandra-compaction-strategy-on-production-cluster.html"" rel=""nofollow"">http://blog.alteroot.org/articles/2015-04-20/change-cassandra-compaction-strategy-on-production-cluster.html</a></p>

<p>If there is no load on the cluster then you could also try starting cassandra with the disable_stcs_in_l0 parameter in cassandra-env.sh to see if that helps. This will disable sizetiered compaction in L0 which should reduce the total number of compactions to recompact all the data into LCS (however the recompaction will still take a long time with 1TB of data).
<code>-Dcassandra.disable_stcs_in_l0=true</code></p>
",['concurrent_compactors']
39172412,39173864,2016-08-26 18:15:08,SQL vs Cassandra Data type mappings,"<p>I am mapping some data types from SQL server to cassandra, such as int to bigint, real to float, varchar to text. Where can I get the mappings from SQL server to cassandra?</p>
",<sql-server><cassandra>,"<p>Looking at <a href=""https://docs.datastax.com/en/cql/3.0/cql/cql_reference/cql_data_types_c.html"" rel=""nofollow"">CQL Data Types</a> descriptions compared to <a href=""https://msdn.microsoft.com/en-us/library/ms187752.aspx"" rel=""nofollow"">SQL Server Data Types</a>, here are some mappings, but there's no guarantees (not overly confident considering the typos in the CQL Data Types reference) they are accurate. </p>

<p>The comparison doesn't consider settings on SQL Server that alter data type representation such as collation sets with character data types or how you are converting and passing this data to SQL Server.</p>

<p>I'm making the comparison based on the <em>values</em> that can be represented by both types. Pay close attention to the comments. </p>

<pre>
CQL Data Type |   Match?  | SQL Server Data Type | Comment
-------------------------------------------------------------------------------------
list               N        none                   A collection; no native SQL equivalent. Perhaps sql_variant or XML could be used but operations on list in CQL wouldn't apply in SQL Server. Custom data types and CLR integrations would most likely be required
map                N        none                   Similar to above except as of SQL Server 2016, [JSON Data](https://msdn.microsoft.com/en-gb/library/dn921897.aspx) handling has been introduced so it's possible it could parse CQL maps
set                N        none                   ""

int                Y        int                    Both represent 32-bit signed integers
bigint             Y        bigint                 Both represent 64-bit signed integers
varint             ?        smallint               Not clear if varint storage size will change, so if precision was -32768 to 32767, would it take 2 bytes? Also, if varint has values outside of smallint range, you may run into overflow errors. From smallint to varint, there's no indication in the above links
varint             ?        tinyint                Similar to above except if precision was 0 to 255, would it take 1 bytes?

float              Y        float

decimal            ?        decimal                Not clear of the precision and scaling limits of CQL decimal

ascii              ?        char, varchar          Not clear this mapping is accurate, more an assumption. Limits and conversion behaviour are not known
text               ?        ntext                  Based on UTF-8 encoding and that CQL seems to have varchar/text as does SQL. So it's likely text represents larger length text strings
varchar            ?        nchar, nvarchar        Based on UTF-8 encoding supported by both. Not clear what varchar limits are or the conversion behaviour

timestamp          ?        datetime               Not clear what timestamp limits are or the conversion behaviour

boolean            ?        bit                    Not clear on conversion behaviour

blob               ?        binary, varbinary      Not clear what the limits are on length of a CQL blob

uuid               ?        uniqueidentifier       uuid follows standard UUID format, most likely 128 bits (16 bytes) which is the same storage size as uniqueidentifier. Not clear on the conversion behaviour
</pre>  
",['precision']
39498313,39499421,2016-09-14 19:34:01,How to force Cassandra not to use the same node for replication in a schema with vnodes,"<p>Installing Cassandra in a single node to run some tests, we noticed that we were using a RF of 3 and everything was working correctly.</p>

<p>This is of course because that node has 256 vnodes (by default) so the same data can be replicated in the same node in different vnodes.</p>

<p>This is worrying because if one node were to fail, you'd lose all your data even though you <em>thought</em> the data was replicated in different nodes.</p>

<p>How can I be sure that in a standard installation (with a ring with several nodes) the same data will not be replicated in the same ""physical"" node? Is there a setting to avoid Cassandra from using the same node for replicating data?</p>
",<cassandra>,"<p>Replication strategy is <strong>schema</strong> dependent. You probably used the <strong>SimpleStrategy</strong> with <strong>RF=3</strong> in your schema. That means that each piece of data will be placed on the node determined by the partition key, and successive replicas will be placed on the successive nodes. In your case, the successive node is the <em>same physical</em> node, hence you get 3 copies of your data there. </p>

<p>Increasing the number of nodes solves your problem. In general, your data will be placed in different physical nodes when your replication factor <strong>RF</strong> is less than/equal to your number of nodes <strong>N</strong>.</p>

<p>The other solution is to switch replication strategy and use the <strong>NetworkTopologyStrategy</strong>, usually used in multi datacenter clusters, and where you can specify how many replicas you want in each data center. This strategy</p>

<blockquote>
  <p>places replicas in the same data center by walking the ring clockwise
  until reaching the first node in another rack. <strong>NetworkTopologyStrategy</strong>
  attempts to place replicas on distinct racks because nodes in the same
  rack (or similar physical grouping) often fail at the same time due to
  power, cooling, or network issues.</p>
</blockquote>

<p>Look at <a href=""https://docs.datastax.com/en/cassandra/2.0/cassandra/architecture/architectureDataDistributeReplication_c.html"" rel=""nofollow"">DataStax documentation</a> for more information.</p>
",['rack']
39654992,39875069,2016-09-23 07:24:08,sstableloader not loading data into DSE 4.5.1 Cassandra cluster,"<p>I have SSTables copied from a source placed here : 
<code>/dev/shm/datafiles/node1/ppr/online_inv</code></p>

<p>When I run SSTable loader to load the data , it runs and terminates within a second without loading the data .</p>

<pre><code>[cassandra@nmd bin]$ ./sstableloader --debug  -d 10.241.17.107 /dev/shm/datafiles/node1/ppr/online_inv
</code></pre>

<p>Established connection to initial hosts
Opening sstables and calculating sections to stream
Streaming relevant part of <code>/dev/shm/datafiles/node1/ppr/online_inv/ppr-online_inv-jb-546-Data.db</code> to []
Streaming session ID: <code>86e92720-815c-11e6-b0c0-45a6be0356e5</code></p>

<p>This is a new DSE 4.5.1 cluster and we just began loading data through prod sstables . Schema is already created just like prod cluster from where we have copied sstables. This is happening for all keyspaces/tables.</p>

<p>We also tried jmxsh method but this is also getting terminated in the same way as sstable loader :</p>

<p><code>INFO [RMI TCP Connection(14)-10.241.17.107] 2016-09-23 07:02:01,482 OutputHandler.java (line 42) Streaming relevant part of /dev/shm/datafiles/node3/look/look_details/look-look_details-jb-1240-Data.db /dev/shm/datafiles/node3/look/look_details/look-look_details-jb-1239-Data.db /dev/shm/datafiles/node3/look/look_details/look-look_details-jb-1237-Data.db /dev/shm/datafiles/node3/look/look_details/look-look_details-jb-1236-Data.db /dev/shm/datafiles/node3/look/look_details/look-look_details-jb-1235-Data.db to []
</code></p>
",<cassandra><datastax><cassandra-2.0><datastax-enterprise><cassandra-2.1>,"<p>The issue was related to snitch settings which picked up default names of DC and rack as 'Cassandra' &amp; 'rack1' . Altered the schema definition and problem was resolved .</p>
",['rack']
39839133,39840707,2016-10-03 19:36:41,Understanding the Token Function in Cassandra,"<p>Hello I was reading the Cassandra documentation on Token Function,</p>

<p><a href=""https://i.stack.imgur.com/PoeKh.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/PoeKh.png"" alt=""Screenshot of documentation, https://docs.datastax.com/en/cql/3.1/cql/cql_using/paging_c.html""></a></p>

<p>I am trying to achieve pagination for a Cassandra table, I am unable to understand the lines highlighted. The document speaks about the difference between k > 42 and TOKEN(k) > TOKEN(42), but I am not able to understand the ""token based comparison""</p>

<p>Looking forward for a detailed explanation of what token function does when part of a WHERE clause.</p>
",<cassandra><pagination><cql><cql3>,"<p>In order to understand in which <em>partition</em> it should put your data, C* makes some calculations on the <code>PARTITION KEY</code>s of every row. Specifically, on each node, rows are sorted by the token generated by the partitioner, (and each partition have data sorted by the cluster key). Different <a href=""https://docs.datastax.com/en/cassandra/3.x/cassandra/architecture/archPartitionerAbout.html"" rel=""noreferrer""><em>partitioners</em></a> perform different types of calculations. </p>

<p>While the <a href=""https://docs.datastax.com/en/cassandra/3.x/cassandra/architecture/archPartitionerM3P.html"" rel=""noreferrer"">Murmur3Partitioner</a> calculates the <a href=""https://en.wikipedia.org/wiki/MurmurHash"" rel=""noreferrer"">MurmurHash</a> of the partion key, the <a href=""https://docs.datastax.com/en/cassandra/3.x/cassandra/architecture/archPartitionerBOP.html"" rel=""noreferrer"">ByteOrderedPartitioner</a> uses the raw data bytes of the partition key itself: when you use the Murmur3Partitioner, your rows are sorted by their <em>hashes</em>, while when you use the <em>ByteOrderedPartitioner</em>, your rows are sorted <strong>directly</strong> by their <em>raw values</em>. </p>

<p>As an example, assume you have a table like this:</p>

<pre><code>CREATE TABLE test (
    username text,
    ...
    PRIMARY KEY (username)
);
</code></pre>

<p>And assume you're trying to locate where the rows corresponding to the usernames <code>abcd</code> and <code>abce</code> and <code>abcf</code> are stored. The hex representation of these strings are <code>0x61626364</code> and <code>0x61626365</code> and <code>0x61626366</code> respectively. Assuming we apply this <a href=""http://murmurhash.shorelabs.com"" rel=""noreferrer"">MH3</a> implementation (x86, 32-bit for simplicity, no optional seed) on both strings we get <code>‭0x‭43ED676A‬‬</code> and <code>0x‭‭E297E8AA‬‬</code> and <code>0x‭‭87E62668‬‬</code> respectively. So, in the case of MH3, the tokens of the strings will be these 3 values, while in the case of the BOP the tokens will be the raw data values themselves: <code>0x61626364</code>, <code>0x61626365</code> and <code>0x61626366</code>. </p>

<p>Now you can see that storing data sorted by <em>token</em> produces different results when different partitioners are used. A <code>SELECT * FROM test;</code> query would return rows in different order. This <em>can</em> (but <em>should not</em>) be a problem if you have data already sorted by their raw values <strong>and</strong> you need to retrieve that in the same order because when you use MH3 the order is complelety unrelated to your data. </p>

<p>Back to the question, the <code>TOKEN</code> function allows you to filter directly by the <em>tokens of your data</em> instead of <em>your data</em>. The <a href=""https://docs.datastax.com/en/cql/3.3/cql/cql_using/useToken.html"" rel=""noreferrer"">documentation</a> says:</p>

<blockquote>
  <p>ordering with the TOKEN function does not always provide the expected
  results. Use the TOKEN function to express a conditional relation on a
  partition key column. In this case, the query returns rows based on
  the token of the partition key rather than on the value.</p>
</blockquote>

<p>As an example, you could issue:</p>

<pre><code>SELECT * FROM test WHERE TOKEN(username) &lt;= TOKEN('abcf');
</code></pre>

<p>and you'd get figure what? <code>abcd</code> and <code>acbf</code> rows!!! This is because order <em>sometimes</em> matters... Like in the case of the pagination you're trying to do, which <strong>will be handled flawlessy for you by any available C* driver</strong> (eg the <a href=""https://datastax.github.io/java-driver/manual/paging/"" rel=""noreferrer"">Java driver</a>).</p>

<p>That said, the recommended partitioner for new clusters is <a href=""https://docs.datastax.com/en/cassandra/3.x/cassandra/architecture/archPartitionerM3P.html"" rel=""noreferrer""><em>Murmur3Partitioner</em></a>, you can check the <a href=""https://docs.datastax.com/en/cassandra/3.x/cassandra/architecture/archPartitionerAbout.html"" rel=""noreferrer"">documentation</a> for both pros and cons of each partitioner. Please note that the partitioner is a <strong>cluster-wide</strong> settings, and once set you cannot change it without pushing all of your data into another cluster. </p>

<p>Make your choice carefully.</p>
",['partitioner']
39893193,41800447,2016-10-06 10:08:51,cassandra cql shell window got disappears after installation in windows,"<p>cassandra cql shell window got disappears after installation in windows?
this was installed using MSI installer availalbe in planet cassandra.</p>

<p>Why this happens ? please help me..</p>

<p>Thanks in advance.</p>
",<cassandra><datastax><datastax-enterprise><cqlsh>,"<p>I had the same issue with DataStax 3.9. This is how I sorted this:</p>

<p>Step 1: Open file: DataStax-DDC\apache-cassandra\conf\cassandra.yaml</p>

<p>Step 2: Uncomment the cdc_raw_directory and set new value to (for windows)</p>

<p>cdc_raw_directory: ""C:/Program Files/DataStax-DDC/data/cdc_raw"" </p>

<p>Step 3: Goto Windows Services and Start the DataStax DDC Server 3.9.0 Service</p>
",['cdc_raw_directory']
41575900,41816383,2017-01-10 18:32:09,Accessing cassandra without hardcoded username password,"<p>I have an existing Datastax Cassandra setup that is working. We just added authentication to the system and now we can log in with our AD accounts. This is very nice and certainly works. However applications need to use a hard-coded username/password in order to connect.</p>

<p>In SQL Server we were able to setup a user to run the service as and then it would connect and work through AD. However in Cassandra it is not the same.</p>

<p>If I don't want to include usernames and especially passwords in my app.config files what are my options?</p>
",<windows><authentication><cassandra><datastax-enterprise>,"<p>You can use authentication via LDAP with DSE (Datastax Enterprise), so the authentication stage is done with LDAP instead of the internal authentication in DSE which you're using at the moment. Note that my comments here apply to DSE5.0 onwards but you can use LDAP auth with earlier versions of DSE from 4.6 onwards.</p>

<p>The documentation (link below) covers this. The basic steps are as follows:</p>

<ol>
<li><p>Configure your authenticator in the <code>cassandra.yaml</code> to use the DSE authenticator</p>

<p><code>authenticator: com.datastax.bdp.cassandra.auth.DseAuthenticator</code></p></li>
<li><p>Create an internal role in cassandra to map to the LDAP group(s) in your LDAP server using the <code>CREATE ROLE</code> command</p></li>
<li><p>Ensure all the users you need to use map to the relevant LDAP group (part of your LDAP config)</p></li>
<li><p>Configure your <code>dse.yaml</code> to have the correct settings for your LDAP server</p></li>
<li><p>Restart the DSE process for the settings to take effect</p></li>
</ol>

<p>The following documentation gives some good examples and background information:</p>

<p><a href=""https://docs.datastax.com/en/latest-dse/datastax_enterprise/unifiedAuth/unifiedAuthConfig.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/latest-dse/datastax_enterprise/unifiedAuth/unifiedAuthConfig.html</a></p>

<p><a href=""https://docs.datastax.com/en/latest-dse/datastax_enterprise/sec/authLdapConfig.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/latest-dse/datastax_enterprise/sec/authLdapConfig.html</a></p>

<p>Note: when configuring the <code>dse.yaml</code> note the comment in the docs regarding <code>user_search_filter</code>:</p>

<blockquote>
  <p>When using Active Directory set the filter to <code>(sAMAccountName={0})</code></p>
</blockquote>
",['authenticator']
41587806,41590463,2017-01-11 10:03:31,cassandra sharding and replication,"<p>I am new to Cassandra was going though <a href=""https://academy.datastax.com/resources/brief-introduction-apache-cassandra"" rel=""noreferrer"">this Article</a> explaining sharding and replication and I am stuck at a point that is - </p>

<p>I have a cluster with 6 Cassandra nodes configured at my local machine. I create a new keyspace ""TestKeySpace"" with replication factor as 6 and a table in keyspace ""employee"" and primary key is auto-increment-number named RID.
I am not able to understand how this data will be partitioned and replicated. What I want to know is since I am keeping my replication factor to be 6, and data will be distributed on multiple nodes, then will each node will be having exactly same data as the other nodes or not?</p>

<p>What If my cluster has following configuration - </p>

<pre><code>    Number of nodes - 6 (n1, n2 ,n3, n4, n5 and n6).
    replication_factor - 3. 
</code></pre>

<p>How can I determine that for any one node (let say n1), on which other two nodes the data is replicated and which other nodes are behaving as different shards.</p>

<p>Thanks in Advance.</p>

<p>Regards,
Vibhav</p>

<p>PS - If anybody down votes this question kindly do mention in comments what went wrong.</p>
",<cassandra><replication><database-replication><sharding>,"<p>I will explain this with simple example.
A keyspace in cassandra is equivalent to database schema name in RDBMS.</p>

<p>First create a keyspace - </p>

<pre><code>CREATE KEYSPACE MYKEYSPACE WITH REPLICATION = { 
 'class' : 'SimpleStrategy', 
 'replication_factor' : 3 
};
</code></pre>

<p>Lets create a simple table -</p>

<pre><code>CREATE TABLE USER_BY_USERID(
 userid int,
 name text,
 email text,
 PRIMARY KEY(userid, name)
) WITH CLUSTERING ORDER BY(name  DESC);
</code></pre>

<p>In this example, <code>userid</code> is your partition key and name is clustering key. Partition is also called row key, this key determines on which node row will be saved.</p>

<p>Your first question - </p>

<blockquote>
  <p>I am not able to understand how this data will be partitioned? </p>
</blockquote>

<p>Data will be partitioned based on your partition key. By default C* uses <code>Murmur3partitioner</code>. You can change the partitioner in  cassandra.yaml  configuration file. How partitions happens, is also depends on your configuration. You can specify range of tokens for each node, for example take a look at below cassandra.yaml configuration file. I have specified 6 node form your question.</p>

<p>cassandra.yaml for Node 0:</p>

<pre><code>cluster_name: 'MyCluster'
initial_token: 0
seed_provider:
    - seeds:  ""198.211.xxx.0""
listen_address: 198.211.xxx.0
rpc_address: 0.0.0.0
endpoint_snitch: RackInferringSnitch
</code></pre>

<p>cassandra.yaml for Node 1:</p>

<pre><code>cluster_name: 'MyCluster'
initial_token: 3074457345618258602
seed_provider:
    - seeds:  ""198.211.xxx.0""
listen_address: 192.241.xxx.0
rpc_address: 0.0.0.0
endpoint_snitch: RackInferringSnitch
</code></pre>

<p>cassandra.yaml for Node 2:</p>

<pre><code>cluster_name: 'MyCluster'
initial_token: 6148914691236517205
seed_provider:
    - seeds:  ""198.211.xxx.0""
listen_address: 37.139.xxx.0
rpc_address: 0.0.0.0
endpoint_snitch: RackInferringSnitch
</code></pre>

<p>.......Node3 ...... Node4 ....</p>

<p>cassandra.yaml for Node 5:</p>

<pre><code>cluster_name: 'MyCluster'
initial_token: {some large number}
seed_provider:
    - seeds:  ""198.211.xxx.0""
listen_address: 37.139.xxx.0
rpc_address: 0.0.0.0
endpoint_snitch: RackInferringSnitch
</code></pre>

<p>lets take this insert statement -</p>

<pre><code>INSERT INTO USER_BY_USERID VALUES(
 1,
 ""Darth Veder"",
 ""darthveder@star-wars.com""
);
</code></pre>

<p>Partitioner will calculate the hash of the PARTITION key (in above example userid - 1), and decides which node this row will be saved. Lets say calculated hash is something 12345, this row will be saved at Node 0 (look for the initial_token value for Node0 in above configuration).</p>

<p>Complete cassandra.yaml configuration <a href=""https://docs.datastax.com/en/cassandra/2.1/cassandra/configuration/configCassandra_yaml_r.html"" rel=""noreferrer"">configCassandra_yaml_r</a></p>

<p>You can go through this  <a href=""https://docs.datastax.com/en/datastax_enterprise/4.7/datastax_enterprise/deploy/deployCalcTokens.html"" rel=""noreferrer"">deployCalcTokens</a> to know how to generate tokens.</p>

<p>Second question - </p>

<blockquote>
  <p>how data gets replicated?</p>
</blockquote>

<p>Depending on your replication strategy and replication factor, the data gets replicated on each node. you have to specify Replication factor and replication strategy while creating keyspace.
For example, in above example, I have used <code>SimpleStrategy</code> as replication strategy. This strategy is suitable for small cluster. For geologically distributed application you can use <code>NetworkTopologyStrategy</code>. replication_factor specifies, how many copies of a row to be created, in this example three copies of each row will be created. With simple strategy, cassandra will use clockwise direction to copy the row. </p>

<p>In above example, the row is saved at Node0 and the same node gets copied on Node1 and Node2. 
Let's take another example -</p>

<pre><code>INSERT INTO USER_BY_USERID VALUES(
 448454,
 ""Obi wan kenobi"",
 ""obiwankenobi@star-wars.com""
);
</code></pre>

<p>For user id 448454, the calculated hash is say 3074457345618258609, so this row will be save at Node2 (look for the initial_token value for node 2 in above configuration) and also get copied in clockwise direction to Node3 and Node4 (remember we have specified replication factor of 3, so only three copies Noe2, Node3, Node4). </p>

<p>Hope this helps.</p>
","['partitioner', 'initial_token']"
41678142,41686156,2017-01-16 14:02:35,How are nodes decided for replication in Cassandra,"<p>I am trying to understand how exactly data is replicated on multiple nodes in Cassandra. Lets assume we have 6 nodes and replication factor is 3. For all simplicity, lets assume single datacenter and single rack. Since RF is 3,data is stored in 3 replicas. I want to understand how the 3 replicas are decided.</p>

<p>Referring to example in <a href=""http://www.datastax.com/dev/blog/virtual-nodes-in-cassandra-1-2"" rel=""nofollow noreferrer"">http://www.datastax.com/dev/blog/virtual-nodes-in-cassandra-1-2</a> (first image second part i.e, with virtual nodes), lets say our row falls under virtual node 'E' as decided by partitioner. So the row must be present in Node 1, 5, 6 according to distribution of virtual nodes among different nodes.</p>

<p>But coming to documentation - <a href=""http://docs.datastax.com/en/cassandra/2.1/cassandra/architecture/architectureDataDistributeReplication_c.html"" rel=""nofollow noreferrer"">http://docs.datastax.com/en/cassandra/2.1/cassandra/architecture/architectureDataDistributeReplication_c.html</a> , it says even in simple case of SimpleStrategy, first replica on a node is determined by the partitioner. Additional replicas are placed on the next nodes clockwise to the ring.  So will data be stored in E, F, G virtual nodes or may be Node 1, 2, 3 ? </p>

<p>Which one is correct ? 1st link or documentation ? </p>

<p>Thanks!</p>
",<cassandra><database-replication>,"<p>And if it really interest you where your partition data ends up in the cluster you can use:</p>

<pre><code>nodetool getendpoints
</code></pre>

<p><a href=""https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsGetEndPoints.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsGetEndPoints.html</a></p>

<p>Please take into account that documentation is simplified so that people understand it easier when seeing for the first time. In reality it's consistent hashing on steroids.</p>

<p>Previously every node had a single token and tokens were boundaries on ring that was used for consistent hashing. Basically you had a whole range divided into number of nodes that you had in the cluster. When you needed to do an operation on some partition, you took partition key, hashed it and then you knew to which node to go to. Basically after hashing you get a number in a range of -2^63 to 2^63 - 1. Then you go clockwise on the ring until you ""find"" a marker and this is how you know to which node a partition belongs initially. If you have greater replication factor, you just continue going clockwise on the ring until you ""find"" all the nodes that you need to satisfy replication factor. And this is how you know what nodes in the cluster have your partition.</p>

<p>With virtual nodes there is a property num_tokens and every node selects that many random tokens (In range previously mentioned) when joining the ring and they are then used for consistent hashing. Basically every node then sees that new node wants to have portions of the ring and streams the data to it. Also when new writes comes in they are sent to the new node that is going to own them (until the node fully joins the ring, it's responses are ignored when counted up for consistency levels).</p>

<p>This is how it was before (single token per node in cluster):
<a href=""https://i.stack.imgur.com/Mkme8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Mkme8.png"" alt=""Standard Consistent Hashing""></a></p>

<p>This is how the ring looks like with virtual nodes:
<a href=""https://i.stack.imgur.com/l977w.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/l977w.jpg"" alt=""Consistent Hashing with vnodes""></a></p>

<p>Absolutely the same rules apply with virtual nodes and ordinary consistent hashing, you go around the ring to select
the replicas. If during your going around the ring you stumble upon the same node again you just skip it and continue until you find all the nodes that own the data according to the replication factor that you desire.</p>
",['num_tokens']
41776345,41807621,2017-01-21 06:21:01,Cassandra failed to connect,"<p>I'm newbie in cassandra apache. In the tutorial video, it says type bin/nodetools status to check the status of node but when I tried to input it. Terminal returns </p>

<pre><code>Failed to connect to '127.0.0.1:7199' - ConnectException: 'Connection
refused (Connection refused)'.
</code></pre>

<p><a href=""https://i.stack.imgur.com/pUA1s.png"" rel=""nofollow noreferrer"">Check this image</a></p>

<p>I tried to change JVM_OPTS to ""$JVM_OPTS -Djava.rmi.server.hostname=localhost"" in cassandra-env.sh
but still can't connect.
What I gonna do to fix this error?</p>

<p>Debug.logs</p>

<pre><code>DEBUG [main] 2017-01-21 13:57:48,095 ColumnFamilyStore.java:881 - Enqueuing flush of local: 38.338KiB (0%) on-heap, 0.000KiB (0%) off-heap
DEBUG [PerDiskMemtableFlushWriter_0:1] 2017-01-21 13:57:48,167 Memtable.java:435 - Writing Memtable-local@858986260(8.879KiB serialized bytes, 1 ops, 0%/0% of on/off-heap limit), flushed range = (min(-9223372036854775808), max(9223372036854775807)]
DEBUG [PerDiskMemtableFlushWriter_0:1] 2017-01-21 13:57:48,168 Memtable.java:464 - Completed flushing /usr/lib/cassandra/apache-cassandra-3.9/data/data/system/local-7ad54392bcdd35a684174e047860b377/mc-56-big-Data.db (5.367KiB) for commitlog position CommitLogPosition(segmentId=1484978256521, position=32861)
DEBUG [MemtableFlushWriter:1] 2017-01-21 13:57:48,471 ColumnFamilyStore.java:1184 - Flushed to [BigTableReader(path='/usr/lib/cassandra/apache-cassandra-3.9/data/data/system/local-7ad54392bcdd35a684174e047860b377/mc-56-big-Data.db')] (1 sstables, 9.527KiB), biggest 9.527KiB, smallest 9.527KiB
DEBUG [CompactionExecutor:1] 2017-01-21 13:57:48,472 CompactionTask.java:150 - Compacting (896b3470-df9e-11e6-9508-7dc463a45cc9) [/usr/lib/cassandra/apache-cassandra-3.9/data/data/system/local-7ad54392bcdd35a684174e047860b377/mc-53-big-Data.db:level=0, /usr/lib/cassandra/apache-cassandra-3.9/data/data/system/local-7ad54392bcdd35a684174e047860b377/mc-54-big-Data.db:level=0, /usr/lib/cassandra/apache-cassandra-3.9/data/data/system/local-7ad54392bcdd35a684174e047860b377/mc-55-big-Data.db:level=0, /usr/lib/cassandra/apache-cassandra-3.9/data/data/system/local-7ad54392bcdd35a684174e047860b377/mc-56-big-Data.db:level=0, ]
DEBUG [main] 2017-01-21 13:57:48,539 StorageService.java:2084 - Node localhost/127.0.0.1 state NORMAL, token [-1035692197905104867, -1103547951527719073, -1136980347732340590, -1150272208899529050, -1184340318934652250, -1251847845785777189, -1355083122390358187,
INFO  [main] 2017-01-21 13:57:48,539 StorageService.java:2087 - Node localhost/127.0.0.1 state jump to NORMAL
DEBUG [main] 2017-01-21 13:57:48,545 StorageService.java:1336 - NORMAL
DEBUG [PendingRangeCalculator:1] 2017-01-21 13:57:48,575 PendingRangeCalculatorService.java:66 - finished calculation for 3 keyspaces in 19ms
INFO  [main] 2017-01-21 13:57:49,125 NativeTransportService.java:70 - Netty using native Epoll event loop
DEBUG [CompactionExecutor:1] 2017-01-21 13:57:49,286 CompactionTask.java:230 - Compacted (896b3470-df9e-11e6-9508-7dc463a45cc9) 4 sstables to [/usr/lib/cassandra/apache-cassandra-3.9/data/data/system/local-7ad54392bcdd35a684174e047860b377/mc-57-big,] to level=0.  9.869KiB to 4.938KiB (~50% of original) in 812ms.  Read Throughput = 12.145KiB/s, Write Throughput = 6.077KiB/s, Row Throughput = ~2/s.  4 total partitions merged to 1.  Partition merge counts were {4:1, }
INFO  [main] 2017-01-21 13:57:49,368 Server.java:159 - Using Netty Version: [netty-buffer=netty-buffer-4.0.39.Final.38bdf86, netty-codec=netty-codec-4.0.39.Final.38bdf86, netty-codec-haproxy=netty-codec-haproxy-4.0.39.Final.38bdf86, netty-codec-http=netty-codec-http-4.0.39.Final.38bdf86, netty-codec-socks=netty-codec-socks-4.0.39.Final.38bdf86, netty-common=netty-common-4.0.39.Final.38bdf86, netty-handler=netty-handler-4.0.39.Final.38bdf86, netty-tcnative=netty-tcnative-1.1.33.Fork19.fe4816e, netty-transport=netty-transport-4.0.39.Final.38bdf86, netty-transport-native-epoll=netty-transport-native-epoll-4.0.39.Final.38bdf86, netty-transport-rxtx=netty-transport-rxtx-4.0.39.Final.38bdf86, netty-transport-sctp=netty-transport-sctp-4.0.39.Final.38bdf86, netty-transport-udt=netty-transport-udt-4.0.39.Final.38bdf86]
INFO  [main] 2017-01-21 13:57:49,369 Server.java:160 - Starting listening for CQL clients on localhost/127.0.0.1:9042 (unencrypted)...
INFO  [main] 2017-01-21 13:57:49,429 CassandraDaemon.java:521 - Not starting RPC server as requested. Use JMX (StorageService-&gt;startRPCServer()) or nodetool (enablethrift) to start it
</code></pre>
",<database><cassandra><cassandra-3.0>,"<ol>
<li>Get rid of JVM_OPTS to &quot;$JVM_OPTS -Djava.rmi.server.hostname=localhost.</li>
<li>Set listen_address and broadcast_rpc_address to local ip (ifconfig &gt; ip-address-of-system).</li>
<li>Restart Cassandra.</li>
</ol>
","['listen_address', 'broadcast_rpc_address']"
42331153,42689476,2017-02-19 18:29:49,rpc_address and broadcast_rpc address for cassandra.yaml for Datastax OpsCenter,"<p>So I have a single node cassandra running on an AWS machine which also has the OpsCenter installed. I'm trying to manage it with OpsCenter GUI from a windows machine (which is in the same private network as the cassandra node)however I keep getting the following error </p>

<p>""No HTTP communication to the agent""</p>

<p>Opscenter logs show the following information - </p>

<p>2017-02-19 18:08:17,622 [Test_Cluster]  INFO: Node 172.18.51.175 changed its mode to normal (MainThread)
2017-02-19 18:08:17,773 [Test_Cluster]  INFO: Using 1.2.3.4 as the RPC address for node 172.18.51.175 (MainThread)
2017-02-19 18:09:12,046 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: User timeout caused connection failure. (MainThread)
2017-02-19 18:10:12,045 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: User timeout caused connection failure. (MainThread)
2017-02-19 18:11:12,046 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: IPv4Address(TCP, '1.2.3.4', 61621) (MainThread)
2017-02-19 18:12:12,045 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: IPv4Address(TCP, '1.2.3.4', 61621) (MainThread)
2017-02-19 18:13:12,433 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: IPv4Address(TCP, '1.2.3.4', 61621) (MainThread)
2017-02-19 18:14:12,045 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: IPv4Address(TCP, '1.2.3.4', 61621) (MainThread)
2017-02-19 18:15:12,045 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: User timeout caused connection failure. (MainThread)
2017-02-19 18:16:12,044 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: IPv4Address(TCP, '1.2.3.4', 61621) (MainThread)
2017-02-19 18:17:12,044 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: IPv4Address(TCP, '1.2.3.4', 61621) (MainThread)
2017-02-19 18:18:12,045 [Test_Cluster]  WARN: These nodes reported this message, Nodes: ['172.18.51.175'] Message: HTTP request <a href=""http://1.2.3.4:61621/connection-status"" rel=""nofollow noreferrer"">http://1.2.3.4:61621/connection-status</a>? failed: IPv4Address(TCP, '1.2.3.4', 61621) (MainThread)</p>

<p>So I guess my cassandra.yaml file needs some change ? </p>

<p>Currently I have set listen_address as private IP of my node</p>

<p>my rpc_address is 0.0.0.0</p>

<p>and my broadcast_rpc_address is set as 1.2.3.4 </p>

<p>Which is how the datastax doc recommended. </p>

<p>I tried setting the rpc_address and broadcast_rpc_address to the node's private IP and it failed in that scenario as well.</p>

<p>netstat --listen shows the below line for the port 61621 and 61620</p>

<p>tcp6       0      0 [::]:61620              [::]:*                  LISTEN
tcp6       0      0 [::]:61621              [::]:*                  LISTEN</p>

<p>I'm not sure what I'm doing wrong or how to set these parameters in cassandra.yaml for it to work with Opscenter. </p>

<p>Note : I seem to be having issues only with OpsCenter with the above config. Cassandra services start up fine and my web application is connecting to the cluster using the datastax driver. Any one have comments on what might be going wrong ? </p>

<p>Thanks</p>
",<cassandra><datastax><cql><datastax-enterprise><opscenter>,"<blockquote>
  <p>my rpc_address is 0.0.0.0</p>
  
  <p>and my broadcast_rpc_address is set as 1.2.3.4</p>
</blockquote>

<p>That is your mistake, change the rpc_address to the local IP --> 172.18.51.175 [if this is the nodes IP] </p>

<p>Check in cassandra.yaml file that the listen_address is also set to --> 172.18.51.175</p>
","['listen_address', 'rpc_address', 'broadcast_rpc_address']"
42542845,42543413,2017-03-01 21:55:15,Apache Cassandra 3.10 IllegalArgumentException - Invalid token for Murmur3Partitioner,"<p>The token value that I'm using:</p>

<pre><code>initial_token: 85070591730234615865843651857942052864
</code></pre>

<p>Is causing the following Java exception when I try to start Cassandra:</p>

<pre><code>Exception (java.lang.IllegalArgumentException) encountered during startup: Invalid token for Murmur3Partitioner. Got 85070591730234615865843651857942052864 but expected a long value (unsigned 8 bytes integer).
java.lang.IllegalArgumentException: Invalid token for Murmur3Partitioner. Got 85070591730234615865843651857942052864 but expected a long value (unsigned 8 bytes integer).
    at org.apache.cassandra.dht.Murmur3Partitioner$2.fromString(Murmur3Partitioner.java:333)
    at org.apache.cassandra.dht.Murmur3Partitioner$2.validate(Murmur3Partitioner.java:317)
    at org.apache.cassandra.config.DatabaseDescriptor.applyInitialTokens(DatabaseDescriptor.java:885)
    at org.apache.cassandra.config.DatabaseDescriptor.applyAll(DatabaseDescriptor.java:321)
    at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:141)
    at org.apache.cassandra.service.CassandraDaemon.applyConfig(CassandraDaemon.java:646)
    at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:581)
    at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:735)
ERROR [main] 2017-03-01 19:57:15,861 CassandraDaemon.java:752 - Exception encountered during startup
java.lang.IllegalArgumentException: Invalid token for Murmur3Partitioner. Got 85070591730234615865843651857942052864 but expected a long value (unsigned 8 bytes integer).
    at org.apache.cassandra.dht.Murmur3Partitioner$2.fromString(Murmur3Partitioner.java:333) ~[apache-cassandra-3.10.jar:3.10]
    at org.apache.cassandra.dht.Murmur3Partitioner$2.validate(Murmur3Partitioner.java:317) ~[apache-cassandra-3.10.jar:3.10]
    at org.apache.cassandra.config.DatabaseDescriptor.applyInitialTokens(DatabaseDescriptor.java:885) ~[apache-cassandra-3.10.jar:3.10]
    at org.apache.cassandra.config.DatabaseDescriptor.applyAll(DatabaseDescriptor.java:321) ~[apache-cassandra-3.10.jar:3.10]
    at org.apache.cassandra.config.DatabaseDescriptor.daemonInitialization(DatabaseDescriptor.java:141) ~[apache-cassandra-3.10.jar:3.10]
    at org.apache.cassandra.service.CassandraDaemon.applyConfig(CassandraDaemon.java:646) [apache-cassandra-3.10.jar:3.10]
    at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:581) [apache-cassandra-3.10.jar:3.10]
    at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:735) [apache-cassandra-3.10.jar:3.10]
</code></pre>

<p>Cassandra starts fine on my first node with <code>initial_token: 0</code></p>

<p>What am I doing wrong?</p>

<p><strong>Any help is much appreciated!</strong></p>
",<java><cassandra><yaml><virtualbox><cluster-computing>,"<p>My main question would be why are you trying to set it?</p>

<p>That token (<code>85070591730234615865843651857942052864</code>) is likely for the random partitioner, not murmur partitioner. Can check other nodes in your cluster but perhaps set in the cassandra.yaml:</p>

<pre><code>partitioner: org.apache.cassandra.dht.RandomPartitioner
</code></pre>

<p>Murmur3 partitioner is better idea though, not sure where you got that token or why you expect it to work. Is better to let it assign tokens itself if your just adding nodes. Just do not set it.</p>

<pre><code># initial_token:
</code></pre>
",['partitioner']
42694324,42695309,2017-03-09 11:33:25,"Cassandra (replication factor: 2, nodes: 3) and lightweight transactions","<p>We have a cassandra cluster running with 3 nodes and a replication factor of 2 -> maybe we should have selected 3 from the start, but this is not the case.</p>

<p>Our quorum is therefore = 2/2 + 1 = 2</p>

<p>Lets say we lose one node - so now only two cassandra nodes are online.</p>

<p>We still have the possibility to read from the cluster if we set our consistency level to ""ONE"" and then read -> so this is not a problem.</p>

<p>The thing I do not understand is the following.</p>

<p>We still have two nodes running, so why is it not possible to do a serial (lightweight transaction) insert into our keyspace? We have two nodes up, so shouldn't it be possible to get a quorum of 2 when trying to insert?</p>

<p>Is it because one of the row's is already put on the missing node?</p>
",<database><cassandra>,"<p>When you are trying to insert a data, the data is stored based on the token values(based on the partitioner configured) and replicated in a circular way.</p>

<p>For e.g. If you are inserting a data X in a keyspace with replication factor of 2 in a 3 node cluster Node1 (owning token A), Node2 (owning token B) and Node3 (Owning token C). Say if the data X is computed to token B, then Cassandra starts inserting data from Node2 and Node3 (till it completes the replicas). Say if the data X is computed to token C, then Cassandra starts inserting data from Node3 and Node1.</p>

<p>So setting consistency level of 2 means the data must be written in 2 nodes.
In your case even though you have 2 nodes up Node1 (token A) and Node2 (token B) and one node down Node3 (token C), if the data is computed and selected as token B, then Cassandra tries to insert in Node2 and Node3 and you get consistency error as it cannot insert in Node3. </p>

<p>So to insert you must either increase replication to 3 or decrease the consistency to 1.</p>

<p>To know more on consistency see this docs <a href=""https://docs.datastax.com/en/cassandra/2.1/cassandra/dml/dml_config_consistency_c.html"" rel=""noreferrer"">https://docs.datastax.com/en/cassandra/2.1/cassandra/dml/dml_config_consistency_c.html</a></p>
",['partitioner']
42878994,43495516,2017-03-18 19:40:21,Remove Duplicates without shuffle Spark,"<p>I have a Cassandra table XYX with columns(
id uuid,
insert a timestamp,
header text)</p>

<p>Where id and insert are composite primary key.</p>

<p>I'm using Dataframe and in my spark shell I'm fetching id and header column.
I want to have distinct rows based on id and header column.</p>

<p>I'm seeing lot of shuffles which not be the case since Spark Cassandra connector ensures that all rows for a given Cassandra partition are in same spark partition.</p>

<p>After fetching I'm using dropDuplicates to get distinct records.</p>
",<apache-spark><cassandra><spark-cassandra-connector>,"<p>Spark Dataframe API does not support custom partitioners yet. So the Connector could not introduce the C* partitioner to Dataframe engine.
An RDD Spark API supports custom partitioner from other hand. Thus you could load your data into RDD and then covert it to df.
Here is a Connector doc about C* partitioner usage: <a href=""https://github.com/datastax/spark-cassandra-connector/blob/master/doc/16_partitioning.md"" rel=""nofollow noreferrer"">https://github.com/datastax/spark-cassandra-connector/blob/master/doc/16_partitioning.md</a></p>

<p>keyBy() function allow you to define key columns to use for grouping</p>

<p>Here is working example. It is not short, so I expect someone could improve it:</p>

<pre><code>//load data into RDD and define a group key
val rdd = sc.cassandraTable[(String, String)] (""test"", ""test"")
   .select(""id"" as ""_1"", ""header"" as ""_2"")
   .keyBy[Tuple1[Int]](""id"")
// check that partitioner is CassandraPartitioner
rdd.partitioner
// call distinct for each group, flat it, get two column DF
val df = rdd.groupByKey.flatMap {case (key,group) =&gt; group.toSeq.distinct}
    .toDF(""id"", ""header"")
</code></pre>
",['partitioner']
42932204,42935733,2017-03-21 15:58:03,Cassandra - Which IP address do you use to connect to a cluster when using a driver?,"<p>I have deployed a 3-node Cassandra cluster on AWS (EC2).  I'm trying to connect to the cluster from a .NET console application running on my computer.  The Datastax website provides the following code sample for connecting to a local instance:</p>

<p><code>Cluster cluster = Cluster.Builder().AddContactPoint(""127.0.0.1"").Build();</code></p>

<p>I've set cassandra.yaml such that <code>nodetool status</code> displays the node's address as the EC2 instance's private IP address.  However, if I use the private address in the <code>AddContactPoint()</code> function, the .NET driver returns an error saying that <code>none of the hosts tried for query are available</code>.</p>

<p><a href=""https://i.stack.imgur.com/nsuaT.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nsuaT.jpg"" alt=""enter image description here""></a></p>

<p>Which IP address do you use (instead of 127.0.0.1) in the <code>AddContactPoint()</code> function for connecting to the Cassandra cluster in AWS?  The EC2 instance's public or private IP address?  Or something else?</p>

<p>My settings in cassandra.yaml are:</p>

<pre><code>rpc_address: 0.0.0.0
broadcast_rpc_address: *EC2's public IP address*
listen_address: *EC2's private IP address*
</code></pre>

<p>Thanks in advance.</p>
",<.net><amazon-web-services><amazon-ec2><cassandra>,"<p>For the broadcast_rpc_address you would use the EC2's Public IP address as that's the address at which all your clients be connecting. listen_address is used for internode communication between nodes in the cluster. </p>
","['listen_address', 'broadcast_rpc_address']"
43164047,43165262,2017-04-02 02:39:16,Cassandra: Who creates/distributes virtual Nodes among nodes - Leader?,"<p>In Cassandra, virtual nodes are created and distributed among nodes as given in <a href=""http://www.datastax.com/dev/blog/virtual-nodes-in-cassandra-1-2"" rel=""nofollow noreferrer"">http://www.datastax.com/dev/blog/virtual-nodes-in-cassandra-1-2</a>. But who does that process ? Creating the virtual nodes, distributing among peers. Is it some sort of leader ? How does it work ?</p>

<p>Also in case a node joins, virtual nodes are re-distributed. Lot more similar actions are present. Who does all those ?</p>

<p><strong>Edit</strong>: Is it like when a node joins, it takes up some part of virtual nodes from existing cluster thus eliminating the need of leader ?</p>
",<cassandra><distributed-system>,"<p>New node retrieves data about the cluster using seed nodes. </p>

<p>The new node will take his part of the cluster, based of num_tokens parameter (by default it will be distributed evenly between all nodes existing nodes), and will bootstrap it's part of data.
The rest of the cluster will be aware about the changes by ""gossiping"" - using gossip protocol.</p>

<p>Except the seed nodes part, there's no need for any ""master"" in the process.</p>

<p>Old nodes will not delete partitions automatically, you need to run nodetool cleanup on the old nodes after adding a new node.</p>

<p>Here's good article about it:</p>

<p><a href=""http://cassandra.apache.org/doc/latest/operating/topo_changes.html"" rel=""nofollow noreferrer"">http://cassandra.apache.org/doc/latest/operating/topo_changes.html</a></p>
",['num_tokens']
44170542,44340008,2017-05-25 00:38:45,Cassandra - how to disable memtable flush,"<p>I'm running Cassandra with a very small dataset so that the data can exist on memtable only. Below are my configurations:</p>

<p>In jvm.options: </p>

<pre><code>-Xms4G
-Xmx4G
</code></pre>

<p>In cassandra.yaml, </p>

<pre><code>memtable_cleanup_threshold: 0.50
memtable_allocation_type: heap_buffers
</code></pre>

<p>As per the documentation in cassandra.yaml, the <em>memtable_heap_space_in_mb</em> and <em>memtable_heap_space_in_mb</em> will be set of 1/4 of heap size i.e. 1000MB</p>

<p>According to the documentation here (<a href=""http://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/configCassandra_yaml.html#configCassandra_yaml__memtable_cleanup_threshold"" rel=""nofollow noreferrer"">http://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/configCassandra_yaml.html#configCassandra_yaml__memtable_cleanup_threshold</a>), the memtable flush will trigger if the total size of memtabl(s) goes beyond (1000+1000)*0.50=1000MB.</p>

<p>Now if I perform several write requests which results in almost ~300MB of the data, memtable still gets flushed since I see sstables being created on file system (Data.db etc.) and I don't understand why.</p>

<p>Could anyone explain this behavior and point out if I'm missing something here?</p>
",<cassandra><nodetool>,"<p>Below is the response I got from Cassandra user group, copying it here in case someone else is looking for the similar info.</p>

<p>After thinking about your scenario I believe your small SSTable size might be due to data compression. By default, all tables enable SSTable compression. </p>

<p>Let go through your scenario. Let's say you have allocated 4GB to your Cassandra node. Your memtable_heap_space_in_mb and 
memtable_offheap_space_in_mb  will roughly come to around 1GB. Since you have memtable_cleanup_threshold to .50 table cleanup will be triggered when total allocated memtable space exceeds 1/2GB. Note the cleanup threshold is .50 of 1GB and not a combination of heap and off heap space. This memtable allocation size is the total amount available for all tables on your node. This includes all system related keyspaces. The cleanup process will write the largest memtable to disk.</p>

<p>For your case, I am assuming that you are on a single node with only one table with insert activity. I do not think the commit log will trigger a flush in this circumstance as by default the commit log has 8192 MB of space unless the commit log is placed on a very small disk. </p>

<p>I am assuming your table on disk is smaller than 500MB because of compression. You can disable compression on your table and see if this helps get the desired size.</p>

<p>I have written up a blog post explaining memtable flushing (<a href=""http://abiasforaction.net/apache-cassandra-memtable-flush/"" rel=""nofollow noreferrer"">http://abiasforaction.net/apache-cassandra-memtable-flush/</a>)</p>

<p>Let me know if you have any other question. </p>

<p>I hope this helps.</p>
",['memtable_cleanup_threshold']
44378650,44394326,2017-06-05 22:26:28,Cassandra config change to use hostnames after ip's changed,"<p>Initial installation of Cassandra was done using IP addresses and it has been working for 6+ months.  This past weekend DevOps changed security to not allow IP addresses and also reassigned new IP addresses.  I modified the required files (cassandra.yaml, cassandra-rackdc.properties, etc) to contain hostnames.  The issue is nodetool status gives the error, Failed to connect to '127.0.0.1:7199, and I do have JVM_OPTS=""$JVM_OPTS -Djava.rmi.server.hostname=blah"" in cassandra-env.sh. Any ideas how to proceed to the environment back up?  Should I go through the same files and replace hostnames with the new IP addresses?  Thanks.  </p>
",<cassandra>,"<p>There are two options to provide listen address in Cassandra.yaml. </p>

<ul>
<li>listen_address</li>
<li>listen_interface</li>
</ul>

<p>To be completely agnostic of the IP address or hostname, use the option of listen_interface and comment the listen_address. Here is the Cassandra.yaml change required</p>

<pre><code># Address or interface to bind to and tell other Cassandra nodes to  connect to.
#
#listen_address: xx.xxx.xx.xxx

# Set listen_address OR listen_interface, not both. Interfaces must    correspond
# to a single address, IP aliasing is not supported.
listen_interface: eth0
</code></pre>

<p>To figure out the actual listen_interface, issue the command </p>

<ul>
<li><strong>ifconfig -a</strong></li>
<li>Pick the interface that shows, ""UP BROADCAST RUNNING"". (eth0 in mycase) </li>
</ul>

<p>The output should look like</p>

<pre><code>root@ip-xx-xxx-x-xxx:~# ifconfig -a
docker0   Link encap:Ethernet  HWaddr xx:xx:xx:xx:xx:xx
      inet addr:xxx.xx.x.x  Bcast:0.0.0.0  Mask:255.255.0.0
      UP BROADCAST MULTICAST  MTU:1500  Metric:1
      RX packets:2 errors:0 dropped:0 overruns:0 frame:0
      TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
      collisions:0 txqueuelen:0
      RX bytes:152 (152.0 B)  TX bytes:0 (0.0 B)

eth0      Link encap:Ethernet  HWaddr xx:xx:xx:xx:xx:xx
         inet addr:xx.xxx.xx.xx  Bcast:xx.xxx.xx.xx  Mask:255.255.0.0
         UP BROADCAST RUNNING MULTICAST  MTU:9001  Metric:1
         RX packets:169552382 errors:0 dropped:0 overruns:0 frame:0
         TX packets:185182015 errors:0 dropped:0 overruns:0 carrier:0
         collisions:0 txqueuelen:1000
         RX bytes:88406501352 (88.4 GB)  TX bytes:126516101404 (126.5 GB)

lo        Link encap:Local Loopback
          inet addr:xx.xxx.xx.xx  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:38490371 errors:0 dropped:0 overruns:0 frame:0
          TX packets:38490371 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1
          RX bytes:41155731774 (41.1 GB)  TX bytes:41155731774 (41.1 GB)
</code></pre>

<p>Restart Cassandra and you should be good to go. <strong>Another advantage is that Cassandra.yaml no longer has to be different across your nodes</strong> (assuming all have the same network interface).</p>
","['listen_address', 'listen_interface']"
44501087,44501203,2017-06-12 13:48:48,Checking health of all cassandra nodes,"<p>I am writing tests to check metadata information of cassandra keyspace and tables.
I also want to check which node is up or which is down in a cluster. how can I do it?</p>
",<node.js><cassandra><cassandra-node-driver>,"<p>The nodetool utility gives you access to diagnostic and operational information.</p>

<p><code>nodetool ring</code></p>

<p>will give you a list of the nodes in the ring and their state.</p>

<p>From the node.js driver you can also get the information. The <a href=""http://docs.datastax.com/en/developer/nodejs-driver/3.2/api/class.Client/#hosts"" rel=""noreferrer"">Client</a> has a <code>hosts</code> attribute. Each host has a <a href=""http://docs.datastax.com/en/developer/nodejs-driver/3.2/api/class.Host/#is-up"" rel=""noreferrer"">isUp</a> function you can use. An <a href=""https://github.com/datastax/nodejs-driver/blob/master/examples/metadata/metadata-hosts.js"" rel=""noreferrer"">example</a> shows using the metadata:</p>

<pre><code>""use strict"";
const cassandra = require('cassandra-driver');

const client = new cassandra.Client({ contactPoints: ['127.0.0.1'] });
client.connect()
  .then(function () {
    console.log('Connected to cluster with %d host(s): %j', client.hosts.length);
    client.hosts.forEach(function (host) {
      console.log('Host %s v%s on rack %s, dc %s, isUp: %s', host.address, host.cassandraVersion, host.rack, host.datacenter, host.isUp());
    });
    console.log('Shutting down');
    return client.shutdown();
  })
  .catch(function (err) {
    console.error('There was an error when connecting', err);
    return client.shutdown();
  });
</code></pre>
","['rack', 'dc']"
44602971,44603433,2017-06-17 09:33:58,How to re-shuffle data in Cassandra when adding a new node?,"<p>I need to add more nodes to our Cassandra cluster but it is unclear to me how to do this properly based on the doc:</p>

<p><a href=""http://docs.datastax.com/en/cassandra/2.1/cassandra/operations/ops_add_node_to_cluster_t.html"" rel=""nofollow noreferrer"">http://docs.datastax.com/en/cassandra/2.1/cassandra/operations/ops_add_node_to_cluster_t.html</a></p>

<p>How do I know if the cluster is using vnodes? We are using it with num_tokens 256 and we only have 3 nodes. I guess if you have that it means we have vnodes.</p>

<p>Is there an easy way to re-shuffle the data?</p>
",<cassandra>,"<p>Cassandra version 1.2 and higher by default uses vnodes (256 vnodes), which splits a nodes token into multiple sub tokens to make data distribution evenly to all nodes in a balanced manner.</p>

<p>Each vnode will be assigned a token. So you can find how many vnodes assigned in configuration file or using nodetool.</p>

<p>As you have said ""num_tokens"" tells number of vnodes in that Cassandra node.</p>

<p>(or) </p>

<p>Execute nodetool ring command which will list the tokens in your cluster for each node.</p>

<pre><code>nodetool ring
</code></pre>

<p>It is recommended to use vnodes which will balance your cluster. Earlier Cassandra versions lesser than 1.1 does not have vnodes, So we used to generate the tokens and configured in initial_token parameter available in cassandra.yaml file. </p>

<p>Hence in Cassandra versions 1.2 or higher, using of vnodes is enough to balance the cluster, no need for re-shuffle data. </p>
",['initial_token']
44664028,44664640,2017-06-20 22:31:34,Access Cassandra from separate docker container using docker-compose,"<p>I am trying to connect to a cassandra container from a separate container (named main). </p>

<p>This is my docker-compose.yml</p>

<pre><code>version: '3.2' 
services:   
  main:
    build:
      context: .
    image: main-container:latest
    depends_on:
      - cassandra
    links:
      - cassandra
    stdin_open: true
    tty: true

  cassandra:
    build:
      context: .
      dockerfile: Dockerfile-cassandra
    ports:
      - ""9042:9042""
      - ""9160:9160""
    image: ""customer-core-cassandra:latest""
</code></pre>

<p>Once I run this using docker-compose up, I run this command:</p>

<p><code>docker-compose exec main cqlsh cassandra 9042</code></p>

<p>but I get this error:</p>

<p><code>Connection error: ('Unable to connect to any servers', {'172.18.0.2': error(111, ""Tried connecting to [('172.18.0.2', 9042)]. Last error: Connection refused"")})</code></p>
",<docker><cassandra><docker-compose>,"<p>I figured out the answer. Basically, in the cassandra.yaml file it sets the default rpc_address to localhost. If this is the case, Cassandra will only listen for requests on localhost, and will not allow connections from anywhere else. In order to change this, I had to set rpc_address to my ""cassandra"" container so my main container (and any other containers) could access Cassandra using the cassandra container ip address.</p>

<p><code>rpc_address: cassandra</code></p>
",['rpc_address']
44792836,44793619,2017-06-28 02:47:50,How to getendpoints of a composite partition key which has blob datatype in it,"<p>I have a select query which is timing out, so i tried querying it using consistency all with tracing enabled, so that read_repair will fix it but that didn't helped much and at consistency all i was getting 3 responses out of 9; so i have decided to identify partition and run a repair on it but when i ran getendpoints on composite partition key which has blob datatype it is throwing an exception ""java.lang.NumberFormatException: Non-hex characters"" i also tried using token from cql select statement which also timing out. How can i identify the partition and repair it ??</p>
",<cassandra><datastax><datastax-enterprise><cassandra-2.1>,"<p>If you just run a repair all partitions will be fixed. To repair an individual partition just read it with <code>CL.ALL</code> and read repairs will fix any differences.</p>

<p>That said.</p>

<p><code>nodetool getendpoints</code> takes a <em>token</em> not a partition key. The murmur3 partitioner expects a long token so a large blob wont work. You can get it with CQL with something like a</p>

<pre><code>select token(k1, k2 ...) from table where ...
</code></pre>

<p>and it will give you the token. Alternatively you can get the token from most of the drivers (java driver: <code>cluster.getMetadata().newToken(string)</code>) or from the Cassandra's java api itself (<code>new Murmur3Partitioner().getToken(bytebuffer)</code>)</p>
",['partitioner']
45139240,45139390,2017-07-17 08:23:04,Python Cassandra floating precision loss,"<p>I'm sending data back and forth Python and Cassandra. I'm using both builtin  <code>float</code> types in my python program and the data type for my Cassandra table. If I send a number <code>955.99</code> from python to Cassandra, in the database it shows <code>955.989999</code>. When I send a query in python to return the value I just sent, it is now <code>955.989990234375</code>.</p>

<p>I understand the issue with precision loss in python, I just wanted to know if there's any built-in mechanisms in Cassandra that could prevent this issue.  </p>
",<python><cassandra><floating-point><precision><cassandra-python-driver>,"<p>Python <code>float</code> is an 64-bit IEEE-754 <strong>double</strong> precision binary floating point number. Use <a href=""http://cassandra.apache.org/doc/latest/cql/types.html"" rel=""noreferrer""><code>double</code></a> in Cassandra for a matching type.</p>
",['precision']
45306061,45403269,2017-07-25 14:19:56,Cassandra WriteTimeoutException exception in CounterMutationStage - node dies eventually,"<p>I'm getting the following exception in my cassandra system.log:</p>

<pre><code>WARN  [CounterMutationStage-25] 2017-07-25 13:25:35,874 AbstractLocalAwareExecutorService.java:169 - Uncaught exception on thread Thread[CounterMutationStage-25,5,main]: {}
java.lang.RuntimeException: org.apache.cassandra.exceptions.WriteTimeoutException: Operation timed out - received only 0 responses.
    at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2490) ~[apache-cassandra-3.9.jar:3.9]
    at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) ~[na:1.8.0_112]
    at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) ~[apache-cassandra-3.9.jar:3.9]
    at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) [apache-cassandra-3.9.jar:3.9]
    at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:109) [apache-cassandra-3.9.jar:3.9]
    at java.lang.Thread.run(Unknown Source) [na:1.8.0_112]
Caused by: org.apache.cassandra.exceptions.WriteTimeoutException: Operation timed out - received only 0 responses.
    at org.apache.cassandra.db.CounterMutation.grabCounterLocks(CounterMutation.java:150) ~[apache-cassandra-3.9.jar:3.9]
    at org.apache.cassandra.db.CounterMutation.applyCounterMutation(CounterMutation.java:122) ~[apache-cassandra-3.9.jar:3.9]
    at org.apache.cassandra.service.StorageProxy$9.runMayThrow(StorageProxy.java:1473) ~[apache-cassandra-3.9.jar:3.9]
    at org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2486) ~[apache-cassandra-3.9.jar:3.9]
    ... 5 common frames omitted
</code></pre>

<p>Whenever this happens, CPU goes down to 0% for a minute or so, node becomes unresponsive but recovers after that. 
But eventually, the node will die completely (i.e. the process keeps running, but it will not respond to commands any more, even shutdown does not work, have to kill the process).</p>

<p>Some more information:</p>

<ul>
<li>Cassandra 3.9</li>
<li>G1 garbage collector</li>
<li>Single Node on Windows Server 2012 R2 (20 Cores, 256 GB RAM)</li>
<li>using a lot of counters and counter mutations</li>
</ul>

<p>Things I have tried:</p>

<ul>
<li>eleminated all other warnings from the log. Used to have warnings about counter batches being too large, rewrote code to not use batching at all. This eleminated the warning, but not the exception problem.</li>
<li>migrated to a bigger machine, used bigger heap and fine tuned GC to make sure the problem is not the machine being overstressed. CPU load is &lt; 20%.</li>
</ul>

<p>Does anyone have an idea what else to do? My main concern is the node dying completely. I am not sure that this exception is causing it but it is the only hint I have...</p>

<p><strong>Update 1:</strong></p>

<p>Updated to Cassandra 3.11 and the node does not seem to die any more now. However, write timeouts presists, node is unresponsive for several minutes but at least recovers now.</p>

<p><strong>Update 2:</strong></p>

<p>Solved the problem (with the help of a professional consultant). Disc I/O speed on our node was terrible, leading to a growing queue of flush writers. Reason is unknown, I/O speed tests on the drive (Raid 1 SSDs) were actually super good.
Moving the node from Windows to Linux (and configuring it according to <a href=""http://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettings.html"" rel=""nofollow noreferrer"">http://docs.datastax.com/en/landing_page/doc/landing_page/recommendedSettings.html</a>) solved the problem.</p>

<p>Real reason for the problem is unknown; might have been Windows per se or just some freak incompatibility with the RAID setup. In any case, Cassandra is only really tested on Linux and it is far easier to find help for Linux setups. Lesson learned.</p>
",<cassandra><cassandra-3.0>,"<p>It sounds like a beefy machine with 20cores and 256GB RAM. Cassandra is a distributed system aimed to scale horizontally. Rather than pushing the load at a single node, try adding more commodity hardware and scale horizontally. Also you can run multiple nodes of Cassandra within the same box. </p>

<p>Atleast try running a couple of nodes within this box to scale from the unresponsiveness. Most often CPU is not the bottleneck for Cassandra. Its the I/O that a single node can perform. </p>

<ul>
<li>Check the values on concurrent_writes in cassandra.yaml, I guess based on the recommendation for 20 cores it would be 160 (20 * 8).</li>
<li>If feasible, try separating the commitlog directory and data directory storage drives.</li>
<li>Best bet to scale writes is to add more boxes (which could be smaller in configuration).</li>
</ul>
",['concurrent_writes']
46166650,46174958,2017-09-12 01:41:58,View Cassandra Partitions using CQLSH,"<p>Using Cassandra, how do i see how many partitions were created base on how i created the primary key? I have been following a tutorial and it mentions to go to <code>bin/cassandra-cli</code> and use the <code>LIST</code> command. However, the latest Cassandra install does not come with this and I have read other articles online that have indicated that cli is now deprecated. </p>

<p>Is there anyway for me to see the partitions that were created using cqlsh? </p>

<p>Thanks in advance!</p>
",<cassandra><cassandra-2.0><cqlsh><cassandra-2.1><cassandra-3.0>,"<p>First of all you have to investigate your <code>cassandra.yaml</code> file to see the <strong>number of tokens</strong> that are currently configured. This tells you how many partitions each node will own:</p>

<pre><code>$ grep num_tokens conf/cassandra.yaml
...
num_tokens: 128
...
$ grep initial_token conf/cassandra.yaml
...
# initial_token: 1
...
</code></pre>

<p>If initial token is commented out, that means that the node will figure out it's own partition ranges during start-up.</p>

<p>Next you can check partition ranges using <code>nodetool ring</code> command:</p>

<pre><code>$ bin/nodetool ring

Datacenter: DC1
==========
Address    Rack        Status State   Load            Owns                Token                                       
                                                                          9167006318991683417                         
127.0.0.2  r1          Down   Normal  ?               ?                   -9178420363247798328                        
127.0.0.2  r1          Down   Normal  ?               ?                   -9127364991967065057                        
127.0.0.3  r1          Down   Normal  ?               ?                   -9063041387589326037 
</code></pre>

<p>This shows you which partition range belongs to which node in the cluster. </p>

<p>In the example above each node owns <strong>128</strong> partition ranges. The range between <strong>-9178420363247798327</strong> and <strong>-9127364991967065057</strong> belongs to the node <strong>127.0.0.2</strong>.</p>

<p>You can use this simple select to tell each row's partition key:</p>

<pre><code>cqlsh:mykeyspace&gt; select token(key), key, added_date, title from mytable;

 system.token(key)    | key       | added_date               | title
----------------------+-----------+--------------------------+----------------------
 -1651127669401031945 |  first    | 2013-10-16 00:00:00+0000 | Hello World
 -1651127669401031945 |  first    | 2013-04-16 00:00:00+0000 | Bye World
   356242581507269238 | second    | 2014-01-29 00:00:00+0000 | Lorem Ipsum
   356242581507269238 | second    | 2013-03-17 00:00:00+0000 | Today tomorrow
   356242581507269238 | second    | 2012-04-03 00:00:00+0000 | It's good to meet you

(5 rows)
</code></pre>

<p>Finding the partition key in partition ranges will tell you where the record is stored.</p>

<p>Also you can use <code>nodetool</code> to do the same in one simple step:</p>

<pre><code>$ bin/nodetool getendpoints mykeyspace mytable 'first'
127.0.0.1
127.0.0.2
</code></pre>

<p>This tells where the records with the partition key 'first' are located.</p>

<p><strong>NOTE:</strong> If some of the nodes are down, <code>getendpoints</code> command won't list those nodes, even though they should store the record based on replication settings.</p>
","['num_tokens', 'initial_token']"
46370588,46375005,2017-09-22 17:54:17,Spark CassandraTableScanRDD KeyBy not retaining all columns,"<pre><code>CASSANDRA_TABLE has (some_other_column, itemid) as primary key.

val cassandraRdd: CassandraTableScanRDD[CassandraRow] = sparkSession.sparkContext
  .cassandraTable(cassandraKeyspace, cassandraTable)

cassandraRdd.take(10).foreach(println)
</code></pre>

<p>This cassandraRdd has all columns read from my cassandra table</p>

<pre><code>val temp1: CassandraTableScanRDD[((String), CassandraRow)] = cassandraRdd
  .select(""itemid"", ""column2"", ""column3"")
  .keyBy[(String)](""itemid"")
val temp2: CassandraTableScanRDD[((String), CassandraRow)] = cassandraRdd
  .keyBy[(String)](""itemid"")
temp1.take(10).foreach(println)
temp2.take(10).foreach(println)
</code></pre>

<p>Both temp1 and temp2 are not retaining all columns after that keyBy operation</p>

<pre><code>((988230014),CassandraRow{itemid: 988230014})
</code></pre>

<p>How can I keyBy on certain column and have CassandraRow retain all columns?</p>
",<apache-spark><cassandra><rdd><spark-cassandra-connector>,"<p>To retain partitioner and get selected rows I have to read cassandra rows something like this below</p>

<pre><code>val cassandraRdd: CassandraTableScanRDD[((String, String), (String, String, String))] = {
  sparkSession.sparkContext
    .cassandraTable[(String, String, String)](cassandraKeyspace, cassandraTable)
    .select(""some_other_column"" as ""_1"", ""itemid"" as ""_2"", ""column3"" as ""_3"", ""some_other_column"", ""itemid"")
    .keyBy[(String, String)](""some_other_column"", ""itemid"")
} 
</code></pre>
",['partitioner']
47442426,47465001,2017-11-22 19:23:52,DataStax Python Cassandra Driver wrongly discovering Cassandra on localhost,"<p>I have this little university project and I have developed a simple Python app  with Bokeh frontend and Cassandra backend. I have been prototyping it and developing on a single Cassandra node and then scaled up to three nodes, one native, two virtualized. Therefore the development was on localhost, then I migrated to using a Host-only network named vboxnet0 with IP addresses:</p>

<ul>
<li>192.168.56.1 for master</li>
<li>192.168.56.101/102 for slaves.</li>
</ul>

<p>Cassandra version is 3.11.1
<br>Bokeh server version is 0.12.10 (running on Tornado 4.4.3)</p>

<p><br> I have changed the code accordingly, so my app code begins with:</p>

<pre><code>from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
from cassandra.query import dict_factory`

def pandas_factory(colnames, rows):
    return pd.DataFrame(rows, columns=colnames)
auth_provider = PlainTextAuthProvider(username='', password='')
cluster = Cluster(contact_points=['192.168.56.1'], port=9042, auth_provider=auth_provider)
session = cluster.connect()
session.row_factory = pandas_factory
session.default_fetch_size = None
</code></pre>

<p>Cassandra is <strong>not</strong> running on localhost:</p>

<pre><code>username@hostname:~&gt; cqlsh
Connection error: ('Unable to connect to any servers', {'127.0.0.1': error(111, ""Tried connecting to [('127.0.0.1', 9042)]. Last error: Connection refused"")})
</code></pre>

<p>And yet Python driver somehow thinks it discovered a Cassandra host on 127.0.0.1 and tries to connect to it:</p>

<pre><code>username@hostname:~/Folder/subfolder&gt; bokeh serve Appname &gt; ~/bokeh.output
2017-11-22 19:24:49,230 Starting Bokeh server version 0.12.10 (running on Tornado 4.4.3)
2017-11-22 19:24:49,233 Bokeh app running at: http://localhost:5006/Appname
2017-11-22 19:24:49,233 Starting Bokeh server with process id: 5819
2017-11-22 19:25:03,281 Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '192.168.56.1'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
2017-11-22 19:25:03,281 New Cassandra host &lt;Host: 127.0.0.1 datacenter1&gt; discovered
2017-11-22 19:25:03,282 Found multiple hosts with the same rpc_address (127.0.0.1). Excluding peer 192.168.56.101
2017-11-22 19:25:03,368 Failed to create connection pool for new host 127.0.0.1:
Traceback (most recent call last):
  File ""cassandra/cluster.py"", line 2343, in cassandra.cluster.Session.add_or_renew_pool.run_add_or_renew_pool (cassandra/cluster.c:44919)
  File ""cassandra/pool.py"", line 332, in cassandra.pool.HostConnection.__init__ (cassandra/pool.c:6757)
  File ""cassandra/cluster.py"", line 1119, in cassandra.cluster.Cluster.connection_factory (cassandra/cluster.c:16094)
  File ""cassandra/connection.py"", line 330, in cassandra.connection.Connection.factory (cassandra/connection.c:5963)
  File ""/usr/lib64/python3.6/site-packages/cassandra/io/asyncorereactor.py"", line 307, in __init__
    self._connect_socket()
  File ""cassandra/connection.py"", line 369, in cassandra.connection.Connection._connect_socket (cassandra/connection.c:7477)
ConnectionRefusedError: [Errno 111] Tried connecting to [('127.0.0.1', 9042)]. Last error: Connection refused
2017-11-22 19:25:03,403 Host 127.0.0.1 has been marked down
2017-11-22 19:25:04,406 Error attempting to reconnect to 127.0.0.1, scheduling retry in 2.0 seconds: [Errno 111] Tried connecting to [('127.0.0.1', 9042)]. Last error: Connection refused
2017-11-22 19:25:06,414 Error attempting to reconnect to 127.0.0.1, scheduling retry in 4.0 seconds: [Errno 111] Tried connecting to [('127.0.0.1', 9042)]. Last error: Connection refused
2017-11-22 19:28:14,994 Error attempting to reconnect to 127.0.0.1, scheduling retry in 8.0 seconds: [Errno 111] Tried connecting to [('127.0.0.1', 9042)]. Last error: Connection refused
2017-11-22 19:28:16,489 Host 127.0.0.1 may be up; will prepare queries and open connection pool
2017-11-22 19:28:16,808 Failed to create connection pool for new host 127.0.0.1:
</code></pre>

<p><br>
<br>And then it goes on and on. On the front it looks OK, the app works and 192.168.56.1 is queried correctly, but this is just  annoying that something is not right and I don't know if it's a bug or my own fault.</p>
",<python><cassandra><bokeh>,"<p>First of all Cassandra does not use master/slave relationship. All nodes are equal in the sense that any of your nodes can act as coordinator. The coordinator is chosen based on the request and the client will pick the best coordinator to use. The coordinator will then coordinate with other nodes responsible for the data you're reading/writing and respond back to the client. The contact point that you're specifying in the client is just what it says, a contact point. It is only used to make an initial connection to the Cassandraa cluster. When that is done the client will keep a connection for each node in your Cassandra cluster (because any node is a potential coordinator for your request).</p>

<p>To answer your question. Your cassandra.yaml file is wrong.</p>

<pre><code>2017-11-22 19:25:03,282 Found multiple hosts with the same rpc_address (127.0.0.1). Excluding peer 192.168.56.101
</code></pre>

<p>You need to set rpc_address to the address of the machine. Make sure to do this on each of your nodes in the cluster. Follow these steps to make sure you're not missing any configuration: <a href=""http://cassandra.apache.org/doc/latest/getting_started/configuring.html#main-runtime-properties"" rel=""nofollow noreferrer"">http://cassandra.apache.org/doc/latest/getting_started/configuring.html#main-runtime-properties</a></p>

<p>Also make sure to set the seed to the same ip/ips for all nodes. The seed is simply just the ip of one/many nodes in the cluster that the nodes will connect to when starting up. It's recommended to have two seeds per DC and it should be the same for all nodes.</p>
",['rpc_address']
47467491,47482316,2017-11-24 06:26:44,Cassandra - Dev center not able to connect to all the 3 nodes of Cassandra cluster,"<p>I'm new to Cassandra and EC2 configuration.</p>

<p>I have configured 3 nodes in AWS EC2 instances with Cassandra 3.0 and all the three nodes are connected to each other .</p>

<p>Following things have been configured in .yaml fie.</p>

<p>Broadcast_add: Private ip ec2 add of instance
seeds : public ip add of all the three nodes.
rpc_add : blank</p>

<p>When I try to connect to this cluster from Datastax dev centre it shows only connected to one node. When individually connecting to all the 3 ip's it gets connected to all the nodes. But when connecting to cluster with 3 ip's in connection file, it connects to only one node.</p>

<p>Could any one help with this issue ?</p>

<p>Thanks
Uttkarsh</p>
",<amazon-ec2><cassandra><datastax><cassandra-3.0>,"<pre><code>open cassandra.yaml file and change the

1) listen_address        :-   private IP
2) broadcast_address     :-   blank
3) listen_on_broadcast_address:- true
4) rpc_address           :-   0.0.0.0
5) broadcast_rpc_address :-   public IP
6) seeds ip              :-   public IP for node.    

it's working finally


Thanks Utpal
</code></pre>
","['listen_address', 'broadcast_address', 'rpc_address', 'broadcast_rpc_address']"
48060940,48071599,2018-01-02 12:22:27,Unable to run cqlsh(connection refused),"<p>I'm getting a connection error ""unable to connect to any server"" when I run .cqlsh command from the bin directory of my node. </p>

<p>I'm using an edited yaml file containing only the following(rest all values present in the default yaml have been omitted) :</p>

<p>cluster name, num tokens,  partitioner, data file directories,  commitlog directory, commitlog sync, commitlog sync period, saved cache directory, seed provider info,  listen address and endpoint snitch. </p>

<p>Is this error because I've not included some important parameter in the yaml like rpc address? Please help. </p>

<p>OS: RHEL 6.9
Cassandra: 3.0.14</p>
",<cassandra><cassandra-3.0>,"<ol>
<li>The cassandra yaml file can have modified values, but you should not delete the rows and make your own yaml file. And yes, rpc address is needed in yaml file.</li>
<li><p>In writing the directories like data_file_directories, you should follow the same indentation as:</p>

<pre><code> data_file_directories - 
      /path/to/access
</code></pre></li>
</ol>

<p>Cassandra is very strict at it's indentation in yaml file. I once faced an issue due to this wrong indentation in data_file_directories.</p>

<ol start=""3"">
<li>Finally, run ./cqlsh , provide ip_address if it is a remote server.</li>
<li>Check the nodetool status and confirm whether the node is up and normal.</li>
</ol>
",['data_file_directories']
48257958,48271228,2018-01-15 06:31:20,What is the best way to clear unused Cassandra directories,"<p>Why cassandra's gc didn't delete unused directories of column family during compaction? How can I delete them safely?</p>

<p>I have a 5 nodes Cassandra cluster:</p>

<pre><code># nodetool status
Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address      Load       Tokens       Owns (effective)  Host ID                               Rack
UN  10.97.18.21  5.13 GiB   256          60.4%             8a6828d8-db43-4722-82fd-dd37ec1c25a1  rack1
UN  10.97.18.23  7.53 GiB   256          60.4%             adb18dfd-3cef-4ae3-9766-1e3f17d68588  rack1
UN  10.97.18.22  8.3 GiB    256          62.8%             1d6c453a-e3fb-4b3b-b7c1-689e7c8fbbbb  rack1
UN  10.97.18.25  5.1 GiB    256          60.1%             c8e4a4dc-4a05-4bac-b4d2-669fae9282b0  rack1
UN  10.97.18.24  7.97 GiB   256          56.3%             f2732a23-b70a-41a5-aaaa-1be95002ee8a  rack1
</code></pre>

<p>I have a keyspace 'loan_products' with only one column family 'events':</p>

<pre><code>[cqlsh 5.0.1 | Cassandra 3.11.1 | CQL spec 3.4.4 | Native protocol v4]
Use HELP for help.
cqlsh&gt; 
cqlsh&gt; DESCRIBE KEYSPACE loan_products ;

CREATE KEYSPACE loan_products WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '3'}  AND durable_writes = true;

CREATE TABLE loan_products.events (
    persistence_id text,
    partition_nr bigint,
    sequence_nr bigint,
    timestamp timeuuid,
    timebucket text,
    event blob,
    event_manifest text,
    message blob,
    meta blob,
    meta_ser_id int,
    meta_ser_manifest text,
    ser_id int,
    ser_manifest text,
    tag1 text,
    tag2 text,
    tag3 text,
    used boolean static,
    writer_uuid text,
    PRIMARY KEY ((persistence_id, partition_nr), sequence_nr, timestamp, timebucket)
) WITH CLUSTERING ORDER BY (sequence_nr ASC, timestamp ASC, timebucket ASC)
    AND bloom_filter_fp_chance = 0.01
    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}
    AND comment = ''
    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}
    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}
    AND crc_check_chance = 1.0
    AND dclocal_read_repair_chance = 0.1
    AND default_time_to_live = 0
    AND gc_grace_seconds = 864000
    AND max_index_interval = 2048
    AND memtable_flush_period_in_ms = 0
    AND min_index_interval = 128
    AND read_repair_chance = 0.0
    AND speculative_retry = '99PERCENTILE';
</code></pre>

<p>I have no snapshots at all:</p>

<pre><code># nodetool listsnapshots
Snapshot Details: 
There are no snapshots
</code></pre>

<p>Column family has default <strong>gc_grace_seconds = 864000</strong> (10 days), so gc had to remove tombstones etc., but they are still exist on filesystem. Parallel-ssh shows:</p>

<pre><code>[1] 11:50:34 [SUCCESS] 10.97.18.21
total 20
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 13:01 events-a83b3be0e61711e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 13:02 events-bbedb500e61c11e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 19:08 events-48c2b750e61d11e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 19:19 events-16c0b670e65011e7a2863103117dd196
drwxr-xr-x. 3 cassandra cassandra 4096 янв 15 11:46 events-c156cc40e65111e7a2863103117dd196

[2] 11:50:34 [SUCCESS] 10.97.18.22
total 20
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 13:00 events-a83b3be0e61711e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 13:01 events-bbedb500e61c11e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 19:08 events-48c2b750e61d11e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 19:19 events-16c0b670e65011e7a2863103117dd196
drwxr-xr-x. 3 cassandra cassandra 4096 янв 15 11:49 events-c156cc40e65111e7a2863103117dd196

[3] 11:50:34 [SUCCESS] 10.97.18.23
total 20
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 13:00 events-a83b3be0e61711e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 13:01 events-bbedb500e61c11e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 19:07 events-48c2b750e61d11e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 19:19 events-16c0b670e65011e7a2863103117dd196
drwxr-xr-x. 3 cassandra cassandra 4096 янв 15 11:48 events-c156cc40e65111e7a2863103117dd196

[4] 11:50:34 [SUCCESS] 10.97.18.25
total 20
drwxr-xr-x. 3 cassandra cassandra 4096 янв  9 15:08 events-a83b3be0e61711e7a2863103117dd196
drwxr-xr-x. 3 cassandra cassandra 4096 янв  9 15:08 events-bbedb500e61c11e7a2863103117dd196
drwxr-xr-x. 3 cassandra cassandra 4096 янв  9 15:08 events-48c2b750e61d11e7a2863103117dd196
drwxr-xr-x. 3 cassandra cassandra 4096 янв  9 15:08 events-16c0b670e65011e7a2863103117dd196
drwxr-xr-x. 3 cassandra cassandra 4096 янв 15 11:45 events-c156cc40e65111e7a2863103117dd196

[5] 11:50:34 [SUCCESS] 10.97.18.24
total 20
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 13:00 events-a83b3be0e61711e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 13:01 events-bbedb500e61c11e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 19:08 events-48c2b750e61d11e7a2863103117dd196
drwxr-xr-x. 4 cassandra cassandra 4096 дек 21 19:19 events-16c0b670e65011e7a2863103117dd196
drwxr-xr-x. 3 cassandra cassandra 4096 янв 15 11:50 events-c156cc40e65111e7a2863103117dd196
</code></pre>

<p>As i see only one directory with id <strong>c156cc40e65111e7a2863103117dd196</strong> is in use, last update was on January 15</p>
",<database><cassandra><cassandra-3.0>,"<p>By default Cassandra takes a snapshot whenever a column family is dropped. This is by design to protect accidental truncation (deletion of all records in a table) or accidental drop of that table. The parameter in Cassandra.yaml controlling this is auto_snapshot </p>

<blockquote>
  <p>Whether or not a snapshot is taken of the data before keyspace truncation
  or dropping of column families. The STRONGLY advised default of true
  should be used to provide data safety. If you set this flag to false, you will
  lose data on truncation or drop. 
  <strong>auto_snapshot: true</strong></p>
</blockquote>

<p>So based on the screenshot you have shown, looks like the ""events"" table was dropped atleast 4 times and recreated. So the proper way to clean this up would be to first figure out the correct UUID used by Cassandra for a given table in keyspace. In your case, the query would be</p>

<pre><code>select id from system_schema.tables where keyspace_name = 'loan_products' and table_name = 'events' ;
</code></pre>

<p>Now remove the other table directories manually by ""rm -rf"" for the UUID's that doesn't correspond in the above output.</p>

<p>Also the reason ""nodetool listsnapshots"" isn't giving any snapshots, because the active table doesn't have any. But if you go to any of the other 4 ""events"" table directory and do a ""ls -ltr"" you should be able to find snapshot directories inside them, which were created as the table was dropped.</p>
",['auto_snapshot']
48560390,48565375,2018-02-01 10:23:37,Connect remote scylla db server shows error,"<p>I have installed scylla-db in google cloud servers.</p>

<p><strong>Steps i have followed:</strong></p>

<pre><code>sudo yum install epel-release

sudo curl -o /etc/yum.repos.d/scylla.repo -L http://repositories.scylladb.com/scylla/repo/a2a0ba89d456770dfdc1cd70325e3291/centos/scylladb-2.0.repo

sudo yum install scylla

sudo scylla_setup

(Given yes to ""verify supportable version"" , "" verify packages"" , ""core dump"", "" fstim ssd ""
For remaining : Given NO)

IN  file :/etc/scylla.d/io.conf

SEASTAR_IO=""--max-io-requests=12 --num-io-queues=1""
( edited this file manually )

sudo systemctl start scylla-server
</code></pre>

<p>It shows: Cannot able to read yaml file. Then google it and downgraded the yaml-cpp version to 0.5.1 from 0.5.3 version.
<em>then 
scylla-server started running .</em></p>

<pre><code>[root@scylla ~]# nodetool status
Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address    Load       Tokens       Owns    Host ID                               Rack
UN  127.0.0.1  208.69 KB  256          ?       888e91da-9385-4c61-8417-dd59c1a979b8  rack1
Note: Non-system keyspaces don't have the same replication settings, effective ownership information is meaningless


[root@scylla ~]# cat /etc/scylla/scylla.yaml | grep seeds:
          - seeds: ""127.0.0.1""
[root@scylla ~]# cat /etc/scylla/scylla.yaml | grep rpc_address:
rpc_address: localhost
#broadcast_rpc_address: 
[root@scylla ~]# cat /etc/scylla/scylla.yaml | grep listen_address:
listen_address: localhost

[root@scylla ~]# cqlsh
Connected to Test Cluster at 127.0.0.1:9042.
[cqlsh 5.0.1 | Cassandra 3.0.8 | CQL spec 3.3.1 | Native protocol v4]
Use HELP for help.
cqlsh&gt; exit



[root@scylla ~]# netstat -tupln | grep LISTEN
tcp        0      0 127.0.0.1:10000         0.0.0.0:*               LISTEN      6387/scylla         
tcp        0      0 127.0.0.1:9042          0.0.0.0:*               LISTEN      6387/scylla         
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      1105/sshd           
tcp        0      0 127.0.0.1:7000          0.0.0.0:*               LISTEN      6387/scylla         
tcp        0      0 127.0.0.1:25            0.0.0.0:*               LISTEN      1119/master         
tcp        0      0 0.0.0.0:9180            0.0.0.0:*               LISTEN      6387/scylla         
tcp        0      0 127.0.0.1:9160          0.0.0.0:*               LISTEN      6387/scylla         
tcp6       0      0 :::80                   :::*                    LISTEN      5217/httpd          
tcp6       0      0 :::22                   :::*                    LISTEN      1105/sshd           
tcp6       0      0 :::35063                :::*                    LISTEN      6412/scylla-jmx     
tcp6       0      0 ::1:25                  :::*                    LISTEN      1119/master         
tcp6       0      0 127.0.0.1:7199          :::*                    LISTEN      6412/scylla-jmx     
</code></pre>

<p>scylla-server is running.</p>

<p>Same setup was done another server 
Server Name scylla-db-1</p>

<p>I need to connect to the server scylla ( IP: xx.xx.xxx) from this server.</p>

<p>when i execute the below :</p>

<pre><code>[root@scylla-db-1 ~]# cqlsh xx.xx.xxx
Connection error: ('Unable to connect to any servers', {'xx.xx.xxx': error(111, ""Tried connecting to [('xx.xx.xxx', 9042)]. Last error: Connection refused"")})
</code></pre>

<p><strong>How to connect the remote server from this server?</strong></p>

<p>Also 
while checking the <a href=""http://xx.xx.xxx:10000"" rel=""nofollow noreferrer"">http://xx.xx.xxx:10000</a>  and <a href=""http://xx.xx.xxx:10000/ui"" rel=""nofollow noreferrer"">http://xx.xx.xxx:10000/ui</a> in the browser , I m getting problem loading page.</p>

<p>Note :</p>

<blockquote>
  <p>I have done editing the /etc/scylla.d/io.conf file for assigning the
  max-io-requests manually </p>
</blockquote>
",<cassandra><scylla>,"<p>Port 10000 is the rest api for scylla and is usually left bounded to the 127.0.0.1 - thats why you can not access it</p>

<p>To gain access via cql you need to edit the /etc/scylla/scylla.yaml file and set the rpc_address </p>

<p>Please follow the instructions for configuring scylla for a cluster deployment: single dc <a href=""http://docs.scylladb.com/procedures/create_cluster/"" rel=""noreferrer"">http://docs.scylladb.com/procedures/create_cluster/</a> or multi dc <a href=""http://docs.scylladb.com/procedures/create_cluster_multidc/"" rel=""noreferrer"">http://docs.scylladb.com/procedures/create_cluster_multidc/</a>.</p>
","['rpc_address', 'dc']"
48608390,48616848,2018-02-04 13:09:41,"Yaml change not detected,Exception encountered during startup: Invalid yaml: file:/etc/cassandra/cassandra.yaml","<p>I have changed Cassandra configuration file</p>

<pre><code>cat /etc/cassandra/cassandra.yaml | grep -n 'seed'
416:seed_provider:
423:          # seeds is actually a comma-delimited list of addresses.
425:          - seeds:""84.208.89.132,192.168.0.23,192.168.0.25,192.168.0.28""
</code></pre>

<p>and also cluster name</p>

<pre><code>10:cluster_name: 'Petter Cluster'
</code></pre>

<p>I am surprised to see what the system.log shows</p>

<pre><code>INFO  [main] 2018-01-27 17:20:51,343 YamlConfigurationLoader.java:89 - Configuration location: file:/etc/cassandra/cassandra.yaml
ERROR [main] 2018-01-27 17:20:51,427 CassandraDaemon.java:706 - Exception encountered during startup: Invalid yaml: file:/etc/cassandra/cassandra.yaml
 Error: while parsing a block mapping; expected &lt;block end&gt;, but found FlowEntry;  in 'reader', line 425, column 34:
              - seeds: ""192.168.0.13"",""192.168.0.23"",""192.168.0.25"","" ... 
                                     ^
INFO  [main] 2018-02-03 20:35:48,528 YamlConfigurationLoader.java:89 - Configuration location: file:/etc/cassandra/cassandra.yaml
ERROR [main] 2018-02-03 20:35:48,844 CassandraDaemon.java:706 - Exception encountered during startup: Invalid yaml: file:/etc/cassandra/cassandra.yaml
 Error: null; Can't construct a java object for tag:yaml.org,2002:org.apache.cassandra.config.Config; exception=Cannot create property=seed_provider for JavaBean=org.apache.cassandra.config.Config@551bdc27; java.lang.reflect.InvocationTargetException;  in 'reader', line 10, column 1:
    cluster_name: 'Test Cluster'
    ^
INFO  [main] 2018-02-03 20:39:08,311 YamlConfigurationLoader.java:89 - Configuration location: file:/etc/cassandra/cassandra.yaml
ERROR [main] 2018-02-03 20:39:08,647 CassandraDaemon.java:706 - Exception encountered during startup: Invalid yaml: file:/etc/cassandra/cassandra.yaml
 Error: null; Can't construct a java object for tag:yaml.org,2002:org.apache.cassandra.config.Config; exception=Cannot create property=seed_provider for JavaBean=org.apache.cassandra.config.Config@551bdc27; java.lang.reflect.InvocationTargetException;  in 'reader', line 10, column 1:
    cluster_name: 'Test Cluster'
</code></pre>

<p>How to fix this?How to initialize system after the changes?</p>
",<java><cassandra><yaml>,"<p>It seems you have got into a issue with Cluster name,it is supposed be changed on all the nodes if you willing to change it. </p>

<p>Here are instruction to change Cluster name :
1. Log into cqlsh
2. cqlsh> UPDATE system.local SET cluster_name = 'Petter Cluster' where key='local';  (You need to issue this command on each of the nodes where you would like to change the cluster name. )
system.local gets changed only locally
3. cqlsh> exit;
4. $ nodetool flush system
5. edit cassandra.yaml cluster name to YOUR_CLUSTER_NAME.
6. Restart cassandra.</p>

<p>Please check this link as well:
<a href=""https://surbhinosqldba.wordpress.com/2015/07/23/how-to-rename-modify-cassandra-cluster-name/"" rel=""nofollow noreferrer"">https://surbhinosqldba.wordpress.com/2015/07/23/how-to-rename-modify-cassandra-cluster-name/</a></p>
",['cluster_name']
48732843,48732954,2018-02-11 14:58:49,Secondary index relating to Replication Factor,"<p>I am using the Secondary index for one of the column in Cassandra table.,</p>

<p>Say I have a <strong>5 node cluster</strong> (192.168.1.1, 192.168.1.2, 192.168.1.3, 192.168.1.4, 192.168.1.5) with the Keyspace <strong>replication factor as '3'</strong> and considering the following table,</p>

<pre><code>CREATE TABLE nodestat (
    uniqueId text,
    totalCapacity int,
    physicalUsage int,
    flashMode text,
    timestamp timestamp,
    primary key (uniqueId, timestamp)) 
    with clustering order by (timestamp desc);
</code></pre>

<p>In this, I have the value of uniqueId as '<strong>test</strong>', which means I just have <strong>only one partition named 'test'</strong>. </p>

<p>When I perform the getEndPoints, I could see that the data resides in only 3 nodes.</p>

<pre><code>./nodetool getendpoints keyspacename nodestat test
</code></pre>

<p>192.168.1.1
192.168.1.2
192.168.1.3</p>

<p>So my partition data is available in 3 nodes, I did the secondary index on one of the columns,</p>

<pre><code>CREATE CUSTOM INDEX nodeIp_idx ON nodestat(flashMode)
</code></pre>

<p>So now when I perform </p>

<pre><code>select * from nodestat where uniqueId = 'test' AND flashMode = 'yes'
</code></pre>

<p><strong>How many nodes will it go to collect the data?</strong> </p>
",<cassandra><cassandra-3.0>,"<pre><code>select * from nodestat where uniqueId = 'test' AND flashMode = 'yes'
</code></pre>

<p>Based on this query, you are using partition key along with a secondary index. Hence it will behave like a normal query based on the chosen consistency level. That is if ""local_one"" only one node will be enough to respond and if ""local_quorum"" a quorum of nodes in that dc will have to respond. Secondary index will further assist to narrow down the resultset.</p>

<p>Remember secondary index are local to data in every node of that cluster and hence present in all nodes of the cluster. Additional reference <a href=""https://stackoverflow.com/questions/48729254/high-availability-on-secondary-index-in-cassandra"">here</a>.</p>

<p><strong>In short, there is no direct correlation of Replication factor to Secondary index.</strong></p>
",['dc']
49061398,49067290,2018-03-02 01:29:33,"Cassandra Geolocation, to index or not to index?","<p>My goal is to be able to write a query such that I can find all of the rows in a table between a certain radius of a lat and long.</p>

<p>So a query like this:</p>

<pre><code>SELECT * FROM some_table WHERE lat &gt; someVariableMinLat AND 
    lat &lt; someVariableMaxLat AND
    lng &gt; someVariableMinLng AND lng &lt; someVariableMaxLng;
</code></pre>

<p>along those lines.</p>

<p>Now, my thought is of course these should be an index, and I just wanted to confirm that, and related reading or info would be great, thank you!</p>
",<database><database-design><cassandra>,"<p>Your query requires <code>ALLOW FILTERING</code> to run, assuming you've set <strong>lat</strong> and <strong>lng</strong> as secondary indices.</p>

<p>Since you're interested in related readings and information, I would gladly shere my little knowledge with you. let me start with <em>Allow Filtering</em>. You've created a rather complex query that <em>(1)</em> uses <strong>&lt;</strong> and <strong>></strong> instead of <strong>=</strong> <em>(2)</em> on more than one non-primary-key column.</p>

<p>What <em>Allow Filtering</em> does is that it will query a database first, and then it applies <strong>some</strong> part of your conditions on it. Therefore, it's far from efficient if performance is your concern.</p>

<p>Speaking of performance, it's important to note that a column that tends to have more distinct values is not a good candidate to be set as a secondary index. You may find out more about this topic <a href=""https://docs.datastax.com/en/cql/3.3/cql/cql_using/useWhenIndex.html"" rel=""nofollow noreferrer"">here</a>.</p>

<p>How would I do that?</p>

<p>I'm not sure about your requirements. But you could consider using <a href=""https://en.wikipedia.org/wiki/Geohash"" rel=""nofollow noreferrer"">Geohash</a>. Geohash is the encoded form of both longitude and latitude. It can get pretty precise as well. By using geohash strings, you can play a tradeoff game between the length of your geohash in characters and their precision <em>(the lengthier the string, the more pricise they become)</em>. Perhaps you may set the geohash as your index column which implies that the lengthier the geohash, the more distinct values the column would have. You may even consider setting it as the primary key to take the performace to a higher level.</p>

<p><em>Or maybe, you could set two primary keys. One, to keep short geohash, and another one to keep the longer hash for the same location if you want different level of precision :)</em></p>
",['precision']
49103434,49103548,2018-03-05 04:20:00,Which node a replica is stored in the cassandra ring?,"<p>The data is stored on the ring based on rowkeys, but the replica's row key is the same with the original, then the replica would be stored in the same node in the ring. How does cassandra decide where to store the replica? </p>
",<cassandra>,"<p>Data partitioner determines coordinator node for each key. The coordinator node is the fist replica for a key which is also called primary replica. If replication factor is N, a key's coordinator node replicates it to other N-1 replicas.</p>

<p>In <strong>SimpleStrategy</strong>, successor nodes or the nodes on the ring immediate following in clockwise direction to the coordinator node are selected as  replicas. </p>

<p>This link may help you: <a href=""http://distributeddatastore.blogspot.com/2015/08/cassandra-replication.html"" rel=""nofollow noreferrer"">http://distributeddatastore.blogspot.com/2015/08/cassandra-replication.html</a></p>

<p>You can use <code>nodetool getendpoints</code> to get the node_ip of the replicas. For example:</p>

<pre><code>nodetool getendpoints &lt;keyspace_name&gt; &lt;table_name&gt; &lt;partition_key&gt;
</code></pre>

<blockquote>
  <p>Sample:</p>
</blockquote>

<pre><code>nodetool getendpoints musicdb artist 1
</code></pre>

<blockquote>
  <p>Result:</p>
</blockquote>

<pre><code>192.168.122.13
192.168.122.14
192.168.122.12
</code></pre>
",['partitioner']
49274714,49275834,2018-03-14 10:02:16,How to take advantage of Cassandra partitioner using DataFrames?,"<p>According to <a href=""https://github.com/datastax/spark-cassandra-connector/blob/master/doc/16_partitioning.md"" rel=""nofollow noreferrer"">documentation</a>, Cassandra Partitioner can help to reduce shuffles improving overall performance. To take advantage of partitioner I should use <code>keyBy</code> method. Given table:</p>

<pre><code>CREATE TABLE data_storage.dummy (
id text,
value bigint,
PRIMARY KEY (id)
) 
</code></pre>

<p>I can query a table using RDD API and DataFrame API</p>

<pre><code>  val keySpace = ""data_storage""
  val table = ""dummy""

  //option 1
  private val df: DataFrame = session.read.format(""org.apache.spark.sql.cassandra"")
    .option(""keyspace"", keySpace)
    .option(""table"", table)
    .load
  println(df.rdd.partitioner) //prints None

  //option 2
  val rdd = session.sparkContext.cassandraTable(keySpace, table).keyBy(""id"")
  println(rdd.partitioner) //prints Some(CassandraPartitioner)
</code></pre>

<p>Is there any way to pass information to DataFrame reader about how data should be queried (something like <code>keyBy()</code> method for DataFrame)</p>
",<scala><apache-spark><cassandra><spark-dataframe><spark-cassandra-connector>,"<p>You don't need to specify partitioner in case of DataFrame. You just need to make sure <code>pushdown</code> is set to <code>true</code> for the Cassandra DataFrame.
Check this doc <a href=""https://github.com/datastax/spark-cassandra-connector/blob/master/doc/14_data_frames.md#automatic--predicate-pushdown-and-column-pruning"" rel=""nofollow noreferrer"">Automatic Predicate Pushdown and Column Pruning</a>.</p>
",['partitioner']
49393722,49394516,2018-03-20 20:40:51,Cassandra: dropping keyspace with tables containing numerous user defined types,"<p>I am in a situation where I would like to drop a keyspace which can also <em>safely</em> delete all the contained tables' various user defined types. </p>

<p>The official document of CQL Cassandra states: </p>

<blockquote>
  <p>""Immediate, irreversible removal of the keyspace, including objects
  such as tables, functions, and data it contains. ""</p>
</blockquote>

<p>However, from the document I cannot make out if it also highlights removal of user defined types. Could someone confirm this?</p>
",<cassandra><cassandra-3.0>,"<p>The DROP KEYSPACE command drops the keyspace and all objects that are part of that keyspace: data, tables/colum families, user defined types, indexes.</p>

<p>Before the actual drop,  snapshot of the keyspace is taken. This can be enabled/disabled using auto_snapshot parameter in cassandra.yaml. Default value for this parameter is true.</p>
",['auto_snapshot']
49653634,49678555,2018-04-04 14:27:03,Can username and password be passed in connection url for cassandra,"<p>I want to ask if we can pass username and password in database connection url
Example:</p>

<pre><code>jdbc:cassandra:keyspace=keyspace1;host=host;port=port;user=user;password=password;
</code></pre>

<p>I'm using cdata drivers for apache cassandra.
And if yes, how can i create a user with password whom I'll via the connection url?
And no, the documentation on datastax is not helping me out.</p>
",<cassandra><database-connection><cdata>,"<p>In short, yes. Set the <em>AuthScheme</em> Connection property to 'Basic' and set the <em>User</em> and <em>Password</em> connection properties, in addition to the other necessary properties:</p>

<pre><code>jdbc:cassandra:AuthSchem=BASIC;User=&lt;username&gt;;Password=&lt;password&gt;;...
</code></pre>

<p>@Aaron offers the solution for creating the first user: <a href=""https://stackoverflow.com/questions/22213786/how-do-you-create-the-first-user-in-cassandra-db"">How do you create the first user in Cassandra DB</a></p>

<p>From the <a href=""http://cdn.cdata.com/help/RCC/jdbc/pg_connectionj.htm"" rel=""nofollow noreferrer"">online CData JDBC Driver for Cassandra help</a>:</p>

<blockquote>
  <p>The driver supports Basic authentication with login credentials and
  the additional authentication features of DataStax Enterprise (DSE)
  Cassandra. The following sections detail connection properties your
  authentication method may require.</p>
  
  <p>You need to set <em>AuthScheme</em> to the value corresponding to the
  authenticator configured for your system. You specify the
  authenticator in the authenticator property in the cassandra.yaml
  file. This file is typically found in <code>/etc/dse/cassandra</code>. or through
  the DSE Unified Authenticator on DSE Cassandra.</p>
  
  <p><strong>Basic Authentication</strong></p>
  
  <p>Basic authentication is supported through Cassandra's built-in default
  PasswordAuthenticator.</p>
  
  <ul>
  <li>Set the AuthScheme property to 'BASIC' and set the <em>User</em> and <em>Password</em>    properties. </li>
  <li>In the cassandra.yaml file, set the authenticator    property to 'PasswordAuthenticator'.</li>
  </ul>
  
  <p><strong>Kerberos Authentication</strong></p>
  
  <p>Kerberos authentication is supported through DataStax Enterprise
  Unified Authentication.</p>
  
  <ul>
  <li>Set the <em>AuthScheme</em> property to 'KERBEROS' and set the <em>User</em> and <em>Password</em> properties.</li>
  <li>Set the KerberosKDC, KerberosRealm, and KerberosSPN properties.</li>
  <li>In the cassandra.yaml file, set the authenticator property to ""com.datastax.bdp.cassandra.auth.DseAuthenticator"".</li>
  <li>Modify the authentication_options section in the dse.yaml file, specifying the default_schema and other_schemas properties as
  'kerberos'.</li>
  <li>Modify the kerberos_options section in the dse.yaml file, specifying the keytab, service_principle, http_principle and qop
  properties</li>
  </ul>
  
  <p><strong>LDAP Authentication</strong></p>
  
  <p>LDAP authentication is supported through DataStax Enterprise Unified
  Authentication.</p>
  
  <ul>
  <li>Set the <em>AuthScheme</em> property to 'LDAP' and set the User and Password properties.</li>
  <li>In the cassandra.yaml file, set the authenticator property to ""com.datastax.bdp.cassandra.auth.DseAuthenticator"".</li>
  <li>Modify the authentication_options section in the dse.yaml file, specifying the default_schema and other_schemas properties as 'ldap'.</li>
  <li>Modify the ldap_options section in the dse.yaml file, specifying the server_host, server_port, search_dn, search_password,
  user_search_base, and user_search_filter properties</li>
  </ul>
  
  <p><strong>Using PKI</strong></p>
  
  <p>You can specify a client certificate to authenticate the driver with
  <em>SSLClientCert</em>, <em>SSLClientCertType</em>, <em>SSLClientCertSubject</em>, and <em>SSLClientCertPassword</em>.</p>
</blockquote>
",['authenticator']
49720493,49724461,2018-04-08 17:09:58,Cassandra: how to define a table with auto uuid key?,"<p>I know that cqlsh has uuid() function I can use doing INSERT using cqlsh. But I want to do INSERTs (or creating data from app with driver) without generating uuid on client side.</p>
",<cassandra>,"<p>You can use uuid() in your queries outside of cqlsh which would generate them on the coordinator. You dont need to specify them, ie:</p>

<pre><code>session.execute(""INSERT INTO blah (id, value) VALUES (now(), 'bob')"");

# id being a timeuuid type, or can use uuid() for a random
</code></pre>

<p>That said it can actually be better to do them on client side. If you do them client side your inserts are idempotent. If you have the function providing the key to be generated on coordinator you cannot retry it on a different coordinator if there are write timeouts. Write timeouts may or may not have been applied so its better if you can just retry.</p>

<p>Theres no concern of collisions by the way. Particularly if you use type 1 uuid's, its impossible for them to collide. Even with >10,000 a millisecond a host (which is the precision of timeuuids, since its number of 100 nanoseconds since creation of Gregorian calendar), most libraries are monotonically increasing and will just progress into future milliseconds ensuring you will never have duplicates.</p>
",['precision']
49747222,49767192,2018-04-10 06:54:46,Possibility of using 2 different snitches in the Multiple Data Centers cluster in cassandra,"<p>We have a multiple data centers cluster spanning across our own network and AWS.</p>

<p>We are currently using GossipingPropertFileSnitch snitch across our network.</p>

<p>Is it possible to use GossipingPropertFileSnitch on datacenter in our private network and Ec2MultiRegionSnitch in AWS ? </p>
",<cassandra><cassandra-3.0>,"<p>You can continue to use <strong>GossipingPropertyFileSnitch</strong> in the AWS cluster as well. Just remember to automate or setup proper values for dc and rack in ""cassandra-rackdc.properties"" on the AWS nodes (just like you did in your own datacenter nodes).</p>

<p>Ec2MultiRegionSnitch gets this information free for you. Its rack and DC aware. But bad part about it is that the discovery of the nodes mandates public ip/internet and then future communications happen through private ips.</p>

<p>In short GossipingPropertyFileSnitch continue to work great.</p>
","['rack', 'dc']"
49749573,49767856,2018-04-10 09:04:27,Cassandra Partition vs NoSql Partition,"<p>I've understood difference b/w Cassandra Partition key, Composite key, Clustering key. But not finding enough information to understand how partition is handled in cassandra.<br/>
In cassandra, range of partition keys are stored on a node like a partition/shard. Is my understanding is correct or not..?<br/>
Is each partition key has different file(at the system level) in DB..? If so, won't the reads be slower..?<br/>
If each partition key is not having different file in DB. How it's handled..?</p>
",<cassandra><nosql><cassandra-3.0>,"<p>Data is stored in Cassandra in wide rows called partitions. Each row has a partition key used for identifying that partition. For distributing the data across the cluster, Cassandra is using partitioners which are basically computing hashes of the partition key and the data is distributed across the cluster based on these values. The default partitioner in Cassandra is Murmur3Partitioner.</p>

<p>At OS level, the data is stored in sstables files. A partition can be spread across many sstables. That's why you also need compaction, which is the process of consolidating those sstables, so your partitions won't be spread across a lot of sstables. Reducing the number of sstables a partitions is spread across, will also improve read time. It's worth noting that sstables are immutable.</p>

<p>I suggest reading <a href=""https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlDatabaseInternalsTOC.html"" rel=""nofollow noreferrer"">this</a>, especially ""How Cassandra reads and writes data"".</p>
",['partitioner']
50224203,50225546,2018-05-08 00:35:32,Configure cassandra 3.11.2 to accept remote connection on ec2,"<p>Hey guys i tried many of the solutions posted on different sites and stackoverflow too, but none of them worked for me.
I have eximented with the following cassandra.yaml paramters-</p>

<ol>
<li>rpc_address</li>
<li>rpc_broadcast_address</li>
<li>listen_address</li>
</ol>

<p>Most of the solutions are out dated, little help is highly appreciated</p>
",<cassandra><cassandra-3.0>,"<p>As discussed in chat, there was a typo while adding private ip address for listen_address in the cassandra.yaml. Due to this error, Cassandra never got started and hence no output for the following commands.</p>

<pre><code>nodetool status
  - Failed to connect to '127.0.0.1:7199' - ConnectException: 'Connection refused (Connection refused)

netstat -an | grep 9042 
  - returns nothing
</code></pre>

<p>As always, the first place to look at the errors is cassandra system log. And it clearly indicated the following problem.</p>

<pre><code>ERROR [main] 2018-05-08 02:01:26,541 CassandraDaemon.java:708 - Exception encountered during startup: Invalid yaml: file:/etc/cassandra/cassan$ 
Error: while scanning a simple key; could not found expected ':'; in 'reader', line 678, column 1: 
# Set rpc_address OR rpc_interfa ...
</code></pre>

<p>After fixing the "":"" error in cassandra.yaml file, Cassandra came up smoothly. </p>
","['listen_address', 'rpc_address']"
50521935,50522478,2018-05-25 05:14:59,How to recover data deleted using truncate in Cassandra,"<p>I have accidentally truncated a table in Cassandra. I would like to know whether there is any tool available to restore data in it. Any help would be appreciated. Thanks.</p>
",<cassandra><restore><truncate><cassandra-3.0>,"<blockquote>
<p>auto_snapshot  (Default: true)</p>
<p>Whether Cassandra takes a snapshot of
the data before truncating a keyspace or dropping a table. To prevent
data loss, DataStax strongly advises using the default setting. If you
set auto_snapshot to false, data loss occurs on truncation or drop.</p>
</blockquote>
<p>(taken from <a href=""https://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/configCassandra_yaml.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/configCassandra_yaml.html</a>)</p>
<p>If you are in luck, look into the snapshot directories for your old sstables. For restoring they &quot;only&quot; need to be copied back to their original locations.</p>
<p>Here is what happens:</p>
<pre><code>./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/backups
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/mc-1-big-Data.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/mc-1-big-Index.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/mc-1-big-Filter.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/mc-1-big-Summary.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/mc-1-big-Digest.crc32
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/mc-1-big-CompressionInfo.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/mc-1-big-Statistics.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/mc-1-big-TOC.txt
</code></pre>
<p>Then I issued <code>TRUNCATE demokeyspace.demo</code> - after that it is something like this:</p>
<pre><code>./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/backups
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots/truncated-1527228644868-demo
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots/truncated-1527228644868-demo/mc-1-big-Summary.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots/truncated-1527228644868-demo/mc-1-big-TOC.txt
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots/truncated-1527228644868-demo/mc-1-big-Digest.crc32
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots/truncated-1527228644868-demo/mc-1-big-Filter.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots/truncated-1527228644868-demo/mc-1-big-CompressionInfo.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots/truncated-1527228644868-demo/mc-1-big-Index.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots/truncated-1527228644868-demo/mc-1-big-Data.db
./data1/demokeyspace/demo-0d1a38b05fe211e8875d13cbb58d64f2/snapshots/truncated-1527228644868-demo/mc-1-big-Statistics.db
</code></pre>
<p>Simply copy those files back. But keep in mind that you need to do this on all nodes and run <code>nodetool refresh demokeyspace demo</code> afterwards to reread the tables (of course with your keyspace and columnfamily).</p>
",['auto_snapshot']
50923469,50933324,2018-06-19 08:04:27,uneven data size on cassandra nodes,"<p>I am struggling to understand why my Cassandra nodes have uneven data size.</p>

<p>I have a cluster of three nodes. According to <code>nodetool ring</code>, each node owns 33.33%. Still disk space usages are uneven.</p>

<pre><code>Node1: 4.7 GB (DC: logg_2, RAC: RAC1)
Node2: 13.9 GB (DC: logg_2, RAC:RAC2)
Node3: 9.3 GB (DC: logg_2, RAC:RAC1)
</code></pre>

<p>There is only one keysapce.</p>

<pre><code>keyspace_definition: |
 CREATE KEYSPACE stresscql_cass_logg WITH replication = { 'class': 'NetworkTopologyStrategy', 'logg_2' : 2, 'logg_1' : 1};
</code></pre>

<p>And there is only one table named <code>blogposts</code>.</p>

<pre><code>table_definition: |
  CREATE TABLE blogposts (
        domain text,
        published_date timeuuid,
        url text,
        author text,
        title text,
        body text,
        PRIMARY KEY(domain, published_date)
  ) WITH CLUSTERING ORDER BY (published_date DESC)
    AND compaction = { 'class':'LeveledCompactionStrategy' }
    AND comment='A table to hold blog posts'
</code></pre>

<p>Please help me to understand it why each node has uneven datasize.</p>
",<cassandra><cassandra-2.0>,"<p>Ownership is how much data is owned by the node.</p>
<blockquote>
<p>The percentage of the data owned by the node per datacenter times the
replication factor. For example, a node can own 33% of the ring, but
show 100% if the replication factor is 3.</p>
<p>Attention: If your cluster uses keyspaces having different replication
strategies or replication factors, specify a keyspace when you run
nodetool status to get meaningful ownship information.</p>
</blockquote>
<p>More information can be found here:
<a href=""https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsStatus.html#toolsStatus__description"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsStatus.html#toolsStatus__description</a></p>
<blockquote>
<p>NetworkTopologyStrategy places replicas in the same datacenter by walking the ring clockwise until reaching the first node in another rack.</p>
<p>NetworkTopologyStrategy attempts to place replicas on distinct racks because nodes in the same rack (or similar physical grouping) often fail at the same time due to power, cooling, or network issues.</p>
</blockquote>
<p>Because you only have two racks(RAC1 and RAC2), you are placing node 1 and node 3's replicas in node 2, which is why it is bigger.</p>
<p><a href=""https://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archDataDistributeReplication.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/cassandra/3.0/cassandra/architecture/archDataDistributeReplication.html</a></p>
",['rack']
50992427,50992654,2018-06-22 16:49:16,Alter Keyspace on cassandra 3.11 production cluster to switch to NetworkTopologyStrategy,"<p>I have a cassandra 3.11 production cluster with 15 nodes. Each node has ~500GB total with replication factor 3. Unfortunately the cluster is setup with Replication 'SimpleStrategy'. I am switching it to 'NetworkTopologyStrategy'. I am looking to understand the caveats of doing so on a production cluster. What should I expect?</p>
",<cassandra><cassandra-3.0>,"<p>Switching from m<code>SimpleStrategy</code> to <code>NetworkTopologyStrategy</code> in a single data center configuration is very simple.  The only caveat of which I would warn, is to make sure you spell the data center name correctly.  Failure to do so will cause operations to fail.</p>

<p>One way to ensure that you use the right data center, is to query it from <code>system.local</code>.</p>

<pre><code>cassdba@cqlsh&gt; SELECT data_center FROM system.local;

 data_center
-------------
 west_dc

(1 rows)
</code></pre>

<p>Then adjust your keyspace to replicate to that DC:</p>

<pre><code>ALTER KEYSPACE stackoverflow WITH replication = {'class': 'NetworkTopologyStrategy',
    'west_dc': '3'};
</code></pre>

<p>Now for <em>multiple</em> data centers, you'll want to make sure that you specify your new data center names correctly, AND that you run a repair (on all nodes) when you're done.  This is because <code>SimpleStrategy</code> treats all nodes as a single data center, regardless of their actual DC definition.  So you could have 2 replicas in one DC, and only 1 in another.</p>

<p>I have changed RFs for keyspaces on-the-fly several times.  Usually, there are no issues.  But it's a good idea to run <code>nodetool describecluster</code> when you're done, just to make sure all nodes have schema agreement.</p>

<p><strong>Pro-tip:</strong> For future googlers, there is NO BENEFIT to creating keyspaces using <code>SimpleStrategy</code>.  All it does, is put you in a position where you have to fix it later.  In fact, I would argue that <code>SimpleStrategy</code> should <strong>NEVER BE USED.</strong></p>

<blockquote>
  <p>so when will the data movement commence? In my case since I have specific rack ids now, so I expect my replicas to switch nodes upon this alter keyspace action.</p>
</blockquote>

<p>This alone will not cause any adjustments of token range responsibility. If you already have a RF of 3 and so does your new DC definition, you won't need to run a repair, so nothing will stream.</p>

<blockquote>
  <p>I have a 15 nodes cluster which is divided into 5 racks. So each rack has 3 nodes belonging to it. Since I previously have replication factor 3 and SimpleStrategy, more than 1 replica could have belonged to the same rack. Whereas NetworkStrategy guarantees that no two replicas will belong to the same rack. So shouldn't this cause data to move?</p>
</blockquote>

<p>In that case, if you run a repair your secondary or ternary replicas may find a new home. But your primaries will stay the same.</p>

<blockquote>
  <p>So are you saying that nothing changes until I run a repair?</p>
</blockquote>

<p>Correct.</p>
",['rack']
51143313,51213411,2018-07-02 20:27:24,Cassandra data persistence with and without flushing the node,"<p>Does Cassandra not persist the tables to disk if I don't do <code>nodetool flush</code>
I created the table and keyspace using CQL but I only saw the *-data.db file when I did a flush.
Without it, the data will be lost?</p>
",<cassandra><cassandra-3.0>,"<p>When data is written to a node it is first written to the commitlog on disk, and then it is written to a memtable in RAM. </p>

<p>Cassandra will flush the memtable from RAM and write it to an SSTable on disk when its data footprint exceeds the memtable_cleanup_threshold. Only when this happens will the commitlog be cleared. Nodetool flush converts all memtables to SSTables, even if the memtable_cleanup_threshold is not met.</p>

<p>So the answer is no, your data will not be lost. Eventually the memtable size will meet the threshold, and be written to an SSTable on the disk. </p>
",['memtable_cleanup_threshold']
51479124,51612990,2018-07-23 12:43:17,Extending Cassandra cluster with datacenter in China (CGF),"<p>I need to extend my cluster with a new datacenter to be present in China mainland, behind the Great Firewall. Currently I have datacenters in the US and Europe - so the cluster already matches to the requirements of the <a href=""https://www.datastax.com/dev/blog/multi-datacenter-replication"" rel=""noreferrer"">Geographical Location Scenario</a>.</p>

<p>At this point I have the chinese infrastructure ready for Cassandra, but the network statistics from the past few days are bit troublesome and I am a bit afraid: <strong><em>if and how this can effect my current cluster</em></strong> and will be the new datacenter functional at all?</p>

<p>My actual questions regarding this are:</p>

<ul>
<li>How does Cassandra handle huge packet-loss during replication? (occasionally up to 40%)</li>
<li>How does it effect the cluster when the network connection between two datacenters are really bad (only few kilobits/sec and latency as above) for hours?

<ul>
<li>Will the chinese dc considered as dead? Or Cassandra will still try to use the limited bandwidth? </li>
<li>Can this cause any problem on the non-chinese datacenters? e.g. they get slow, which results in client request timeouts.</li>
</ul></li>
<li>Is it possible to enforce somehow, that only one of my non-chinese datacenter communicates with the chinese one? Or should I trust that Cassandra will handle this? (trying to avoid to possible harm all my datacenters)</li>
<li>Is there any way to fasten up the initial data replication (<code>nodetool rebuild</code>), because with the current speed it would take weeks to replicate our current data.</li>
</ul>

<p>Any suggestion or remark is welcomed, thanks!</p>
",<cassandra><cassandra-3.0>,"<blockquote>
  <p>How does Cassandra handle huge packet-loss during replication? (occasionally up to 40%)</p>
</blockquote>

<p>Usually packet loss will cause a large number of read repairs. In some cases it can cause requests to fail depending on replication factor and consistency. Also, be prepared to have very costly repairs which will create a lot of tiny SSTables and a substansial amount of IO.</p>

<p>I would suggest to run a test on a development requirement to see the actual behavior in your system. There are plenty of <a href=""https://wiki.linuxfoundation.org/networking/netem"" rel=""nofollow noreferrer"">tools</a> to simulate bad network.</p>

<blockquote>
  <p>How does it effect the cluster when the network connection between two datacenters are really bad (only few kilobits/sec and latency as above) for hours? Will the chinese dc considered as dead? Or Cassandra will still try to use the limited bandwidth? Can this cause any problem on the non-chinese datacenters?</p>
</blockquote>

<p>It largely depends on <em>how bad</em> and what consistency level/replication factor you are running with. In some cases it will just cause rather high latency between clusters. However, if the connection is bad enough that the nodes will start marking the other as down - Then you are looking at issues in all datacenters. Your existing datacenters will struggle with performance caused by requests timing out. This will in turn cause requests to be held longer in memory which can lead to GC. (It can cause a number of other issues in your other cluster as well)</p>

<p>The threshold on how sensitive the failure detector is can be adjusted and fine tuned to suit your use case. phi_convict_threshold is a setting that can decrease the likelihood of a node being marked as down. You can find more about that <a href=""https://docs.datastax.com/en/cassandra/2.1/cassandra/architecture/architectureDataDistributeFailDetect_c.html"" rel=""nofollow noreferrer"">here</a>. If you find that sweet spot where your nodes are not marked down due to being unresponsive, you can have Cassandra leverage what little it has to work with.</p>

<blockquote>
  <p>Is it possible to enforce somehow, that only one of my non-chinese datacenter communicates with the chinese one? Or should I trust that Cassandra will handle this? (trying to avoid to possible harm all my datacenters)</p>
</blockquote>

<p>There is not really a way to tell Cassandra to limit what datacenters to speak to. You are kind of stuck with communicating between the datacenters you include in your replication factor.</p>

<blockquote>
  <p>Is there any way to fasten up the initial data replication (nodetool rebuild), because with the current speed it would take weeks to replicate our current data.</p>
</blockquote>

<p>I would recommend against the solution of using sstableloader for it functions very similar as rebuild does and requires a snapshot to operate. If network is what is causing the slow speed, then changing the way of streaming is not going to make much difference.</p>

<p>In my opinion, the first thing to do would be to measure where the bottleneck is for your system. If the slow network is really the bottleneck, one could add more nodes to stream from more sources at the same time but ultimately you will still be hampered by the slow network connection.</p>
","['phi_convict_threshold', 'dc']"
51793195,51800521,2018-08-10 19:45:46,Data Partitioning and Replication on Cassandra cluster,"<p>I have a 3 node Cassandra cluster with RF=3. Now when I do <code>nodetool status</code> I get the <strong>owns</strong> for each node in the cluster as 100%.</p>

<p>But when I have 5 nodes in the cluster wit RF=3. The <strong>owns</strong> is 60%(approx as shown in image below).</p>

<p>Now as per my understanding the partitioner will calculate the hash corresponding to first replica node and the data will also be replicated as per the RF on the other nodes. 
Now we have a 5 node cluster and RF is 3. </p>

<p>Shouldn't 3 nodes be owning all the data evenly(100%) as partitioner will point to one node as per the partitoning strategy and then same data be replicated to remaining nodes which equals RF-1? It's like the data is getting evenly distributed among all the nodes(5) even though RF is 3.</p>

<p><a href=""https://i.stack.imgur.com/BU4K5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BU4K5.png"" alt=""enter image description here""></a></p>

<p><strong>Edit1</strong>:</p>

<p>As per my understanding the reason for 60%(approx) <strong>owns</strong> for each node is because the RF is 3. It means there will be 3 replicas for each row. It means there will be 300% data. Now there are 5 nodes in the cluster and partitioner will be using the default random hashing algorithm which will distribute the data evenly across all the nodes in the cluster.</p>

<p><strong>But now the issue is that we checked all the nodes of our cluster and all the nodes contain all the data even though the RF is 3.</strong> </p>

<p><strong>Edit2</strong>:</p>

<p>@Aaron I did as specified in the comment. I created a new cluster with 3 nodes.</p>

<p><a href=""https://i.stack.imgur.com/GwMbq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GwMbq.png"" alt=""enter image description here""></a> </p>

<p>I created a Keyspace ""test"" and set the class to simplestrategy and RF to 2.</p>

<p><a href=""https://i.stack.imgur.com/ytYBl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ytYBl.png"" alt=""enter image description here""></a></p>

<p>Then I created a table ""emp"" having partition key (id,name).</p>

<p><a href=""https://i.stack.imgur.com/yt6cv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yt6cv.png"" alt=""enter image description here""></a></p>

<p>Now I inserted a single row into the first node.</p>

<p>As per your explanation, It should only be in 2 nodes as RF=2.</p>

<p>But when I logged into all the 3 nodes, i could see the row replicated in all the nodes.</p>

<p>I think since the keyspace is getting replicated in all the nodes therefore, the data is also getting replicated.</p>
",<database><cassandra><nosql><cassandra-3.0>,"<p>Percent ownership is not affected (at all) by actual data being present.  You could add a new node to a single node cluster (RF=1) and it would <em>instantly</em> say 50% on each.</p>

<p>Percent ownership is purely about the percentage of token ranges which a node is responsible for.  When a node is added, the token ranges are recalculated, but data doesn't actually move until a streaming event happens.  Likewise, data isn't actually removed from its original node until <code>cleanup</code>.</p>

<p>For example, if you have a 3 node cluster with a RF of 3, each node will be at 100%.  Add one node (with RF=3), and percent ownership drops to about 75%.  Add a 5th node (again, keep RF=3) and ownership for each node correctly drops to about 3/5, or 60%.  Again, with a RF of 3 it's all about each node being responsible for a set of primary, secondary, and tertiary token ranges.</p>

<blockquote>
  <p>the default random hashing algorithm which will distribute the data evenly across all the nodes in the cluster.</p>
</blockquote>

<p>Actually, the distributed hash with Murmur3 partitioner will evenly distribute the token ranges, <strong><em>not</em></strong> the data.  That's an important distinction.  If you wrote all of your data to a single partition, I guarantee that you would <em>not</em> get even distribution of data.</p>
",['partitioner']
52266171,52266457,2018-09-10 22:11:24,Golang gocql cannot connect to Cassandra (using Docker),"<p>I am trying to setup and connect to a Cassandra single node instance using docker and Golang and it is not working.</p>

<p>The closest information I could find to addressing connection issues between the golang <code>gocql</code> package and Cassandra is available here: <a href=""https://stackoverflow.com/questions/29121904/cassandra-cqlsh-connection-refused"">Cassandra cqlsh - connection refused</a>, however there are many different upvote answers with no clear indication of which is preferred. It is also a protected question (no ""me toos""), so a lot of community members seem to be having trouble with this.</p>

<p>This problem should be slightly different, as it is using Docker and I have tried most (if not all of the solutions linked to above). </p>

<pre><code>version: ""3""  
services:  
  cassandra00:
    restart: always
    image: cassandra:latest
    volumes: 
      - ./db/casdata:/var/lib/cassandra
    ports: 
      - 7000:7000
      - 7001:7001
      - 7199:7199
      - 9042:9042
      - 9160:9160
    environment:
      - CASSANDRA_RPC_ADDRESS=127.0.0.1
      - CASSANDRA_BROADCAST_ADDRESS=127.0.0.1
      - CASSANDRA_LISTEN_ADDRESS=127.0.0.1
      - CASSANDRA_START_RPC=true
  db:
    restart: always
    build: ./db
    environment:
      POSTGRES_USER: patientplatypus
      POSTGRES_PASSWORD: SUPERSECRETFAKEPASSD00T
      POSTGRES_DB: zennify
    expose:
      - ""5432""
    ports:
      - 5432:5432
    volumes:
      - ./db/pgdata:/var/lib/postgresql/data
  app:
    restart: always
    build: 
      context: .
      dockerfile: Dockerfile
    command: bash -c 'while !&lt;/dev/tcp/db/5432; do sleep 10; done; realize start --run'
    # command: bash -c 'while !&lt;/dev/tcp/db/5432; do sleep 10; done; go run main.go'
    ports:
      - 8000:8000
    depends_on:
      - db
      - cassandra00
    links:
      - db
      - cassandra00
    volumes:
      - ./:/go/src/github.com/patientplatypus/webserver/
</code></pre>

<p>Admittedly, I am a little shaky on what listening addresses I should pass to Cassandra in the environment section, so I just passed 'home':</p>

<pre><code>  - CASSANDRA_RPC_ADDRESS=127.0.0.1
  - CASSANDRA_BROADCAST_ADDRESS=127.0.0.1
  - CASSANDRA_LISTEN_ADDRESS=127.0.0.1
</code></pre>

<p>If you try and pass <code>0.0.0.0</code> you get the following error:</p>

<pre><code>cassandra00_1  | Exception (org.apache.cassandra.exceptions.ConfigurationException) encountered during startup: listen_address cannot be a wildcard address (0.0.0.0)!
cassandra00_1  | listen_address cannot be a wildcard address (0.0.0.0)!
cassandra00_1  | ERROR [main] 2018-09-10 21:50:44,530 CassandraDaemon.java:708 - Exception encountered during startup: listen_address cannot be a wildcard address (0.0.0.0)!
</code></pre>

<p>Overall, however I think that I am getting the correct start up procedure for Cassandra (afaict) because my terminal outputs that Cassandra started up as normal and is listening on the appropriate ports:</p>

<pre><code>cassandra00_1  | INFO  [main] 2018-09-10 22:06:28,920 StorageService.java:1446 - JOINING: Finish joining ring
cassandra00_1  | INFO  [main] 2018-09-10 22:06:29,179 StorageService.java:2289 - Node /127.0.0.1 state jump to NORMAL
cassandra00_1  | INFO  [main] 2018-09-10 22:06:29,607 NativeTransportService.java:70 - Netty using native Epoll event loop
cassandra00_1  | INFO  [main] 2018-09-10 22:06:29,750 Server.java:155 - Using Netty Version: [netty-buffer=netty-buffer-4.0.44.Final.452812a, netty-codec=netty-codec-4.0.44.Final.452812a, netty-codec-haproxy=netty-codec-haproxy-4.0.44.Final.452812a, netty-codec-http=netty-codec-http-4.0.44.Final.452812a, netty-codec-socks=netty-codec-socks-4.0.44.Final.452812a, netty-common=netty-common-4.0.44.Final.452812a, netty-handler=netty-handler-4.0.44.Final.452812a, netty-tcnative=netty-tcnative-1.1.33.Fork26.142ecbb, netty-transport=netty-transport-4.0.44.Final.452812a, netty-transport-native-epoll=netty-transport-native-epoll-4.0.44.Final.452812a, netty-transport-rxtx=netty-transport-rxtx-4.0.44.Final.452812a, netty-transport-sctp=netty-transport-sctp-4.0.44.Final.452812a, netty-transport-udt=netty-transport-udt-4.0.44.Final.452812a]
cassandra00_1  | INFO  [main] 2018-09-10 22:06:29,754 Server.java:156 - Starting listening for CQL clients on /127.0.0.1:9042 (unencrypted)...
cassandra00_1  | INFO  [main] 2018-09-10 22:06:29,990 ThriftServer.java:116 - Binding thrift service to /127.0.0.1:9160
</code></pre>

<p>In my golang code I have the following package that is being called (simplified to show relevant section):</p>

<pre><code>package data

import(
    ""fmt""
    ""github.com/gocql/gocql""
)

func create_userinfo_table() {
    &lt;...&gt;
    fmt.Println(""replicating table in cassandra"")
    cluster := gocql.NewCluster(""localhost"") //&lt;---error here!
    cluster.ProtoVersion = 4
    &lt;...&gt;
}
</code></pre>

<p>Which results in the following error in my terminal:</p>

<pre><code>app_1          | [21:52:38][WEBSERVER] : 2018/09/10 
21:52:38 gocql: unable to dial control conn 127.0.0.1: 
dial tcp 127.0.0.1:9042: connect: connection refused

app_1          | [21:52:38][WEBSERVER] : 2018/09/10 
21:52:38 gocql: unable to dial control conn ::1: 
dial tcp [::1]:9042: connect: cannot assign requested address

app_1          | [21:52:38][WEBSERVER] : 2018/09/10 
21:52:38 Could not connect to cassandra cluster: gocql: 
unable to create session: control: unable to connect to initial hosts: 
dial tcp [::1]:9042: connect: cannot assign requested address
</code></pre>

<p>I have tried several variations on the connection address </p>

<p><code>cluster := gocql.NewCluster(""localhost"")</code></p>

<p><code>cluster := gocql.NewCluster(""127.0.0.1"")</code></p>

<p><code>cluster := gocql.NewCluster(""127.0.0.1:9042"")</code></p>

<p><code>cluster := gocql.NewCluster(""127.0.0.1:9160"")</code></p>

<p>These seemed likely candidates for example, but no luck.</p>

<p>Does anyone have any idea what I am doing wrong?</p>
",<database><docker><go><cassandra><docker-compose>,"<p>Use the service name <code>cassandra00</code> for the hostname per the docker-compose documentation <a href=""https://docs.docker.com/compose/compose-file/#links"" rel=""nofollow noreferrer"">https://docs.docker.com/compose/compose-file/#links</a></p>

<blockquote>
  <p>Containers for the linked service are reachable at a hostname identical to the alias, or the service name if no alias was specified.</p>
</blockquote>

<p>Leave the <code>CASSANDRA_LISTEN_ADDRESS</code> envvar unset (or pass <code>auto</code>) per <a href=""https://docs.docker.com/samples/library/cassandra/"" rel=""nofollow noreferrer"">https://docs.docker.com/samples/library/cassandra/</a> </p>

<blockquote>
  <p>The default value is auto, which will set the listen_address option in cassandra.yaml to the IP address of the container as it starts. This default should work in most use cases.</p>
</blockquote>
",['listen_address']
52402907,52435581,2018-09-19 09:45:00,Cassandra 2.1 changing snitch from EC2Snitch to GossipingPropertyFileSnitch,"<p>Currently we have used EC2Snitch using two AZs in a single AWS region. The goal was to provide resiliency even when one AZ is not available. Most data are replicated with RF=2, so each AZ gets a copy based on Ec2Snitch.</p>

<p>Now we have come to a conclusion to move to GossipingPropertyFileSnitch. Reason primarily is that we have realized that one AZ going down is a remote occurrence and even if it happens, there are other systems in our stack that don't support this; so eventually whole app goes down if that happens.</p>

<p>Other reason is that with EC2Snitch and two AZs, we had to scale in factor of 2 (one in each AZ). With GossipingPropertyFileSnitch using just one rack, we can scale in factor of 1. </p>

<p>When we change this snitch setting, will the topology change? I want to avoid having a need to run nodetool repair. We always had failures with running nodetool repair and it runs forever.</p>
",<cassandra><nodetool>,"<p>Whether the topology changes depends on how you carry out the change. If you assign the same logical dc and rack to the node as what it's currently configured to, you shouldn't get a topology change.</p>

<p>You have to match the rack to the AZ after updating to <code>GossipingPropertyFileSnitch</code>. You need to do a rolling restart for the re-configuration to take place.</p>

<p>Example <code>cassandra-rackdc.properties</code> for 2 nodes in 1 dc across 2 AZs:</p>



<pre class=""lang-sh prettyprint-override""><code># node=10.0.0.1, dc=first, AZ=1
dc_suffix=first
# Becomes
dc=first
rack=1

# node=10.0.0.2, dc=first, AZ=2
dc_suffix=first
# Becomes
dc=first
rack=2
</code></pre>

<p>On a side note you need to explore why repairs are failing. Unfortunately they are very important for cluster health. </p>
","['rack', 'dc']"
54222010,54222176,2019-01-16 17:07:16,On Cassandra how to enable LDAP authentication,"<p>I have a Cassandra cluster running on Ubuntu. I would like to enable authentication so that not everyone will have access to the Cassandra database and run queries.</p>

<p>Enabling simple authentication is available at <a href=""https://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/secureConfigNativeAuth.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/secureConfigNativeAuth.html</a></p>

<p>But, I am looking for integrating Cassandra with LDAP, Active Directory</p>
",<cassandra><nosql><cassandra-3.0><wide-column-store>,"<p>You will have to change the default authenticator from AllowAllAuthenticator to PasswordAuthenticator or some custom authenticator.</p>

<p>You can also enable roles for a finer grained access.</p>

<p>Check the following:</p>

<ul>
<li><a href=""http://cassandra.apache.org/doc/latest/operating/security.html?highlight=authenticator#authentication"" rel=""nofollow noreferrer"">http://cassandra.apache.org/doc/latest/operating/security.html?highlight=authenticator#authentication</a></li>
<li><a href=""https://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/secureConfigNativeAuth.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/cassandra/3.0/cassandra/configuration/secureConfigNativeAuth.html</a></li>
</ul>

<p>Later edit: since you need LDAP autentication you can use the one created by Instaclustr. Details - <a href=""https://www.instaclustr.com/apache-cassandra-ldap-authentication/"" rel=""nofollow noreferrer"">Apache Cassandra LDAP Authentication</a> and the <a href=""https://github.com/instaclustr/cassandra-ldap"" rel=""nofollow noreferrer"">source code</a>.</p>
",['authenticator']
54637593,54673425,2019-02-11 19:18:14,What should I try when cassandra appears to be running and listening but cqlsh can't connect?,"<p>I'm new to Cassandra and was trying it out. Despite Cassandra apparently running and listening (according to <code>lsof</code>) I can't connect to it. <code>sudo systemctl status cassandr</code> also reports <code>active (running)</code>.</p>

<pre><code>$ sudo lsof -Pnl +M -i4 
COMMAND  PID     USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
(omitting unrelated services - nothing here about cassandra)

$ sudo lsof -Pnl +M -i6
COMMAND   PID     USER   FD   TYPE DEVICE SIZE/OFF NODE NAME
sshd      752        0    4u  IPv6  16234      0t0  TCP *:22 (LISTEN)
java    23659      300   68u  IPv6 158110      0t0  TCP 127.0.0.1:7199 (LISTEN)
java    23659      300   69u  IPv6 158122      0t0  TCP 127.0.0.1:36921 (LISTEN)
java    23659      300   84u  IPv6 158212      0t0  TCP 127.0.0.1:9160 (LISTEN)
java    23659      300  151u  IPv6 158205      0t0  TCP 127.0.0.1:7000 (LISTEN)



$ sudo nodetool status
Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address    Load       Owns (effective)  Host ID                               Token                                    Rack
UN  127.0.0.1  125.98 KiB  100.0%            e0bbc831-8686-43a6-b99c-8ea5596c8581  3840369556391221198                      rack1
</code></pre>

<p>For Nix users who might be reading this (also easy to grasp for non-Nix users), my config is just:</p>

<pre><code>  services.cassandra = {
    enable = true;
    listenAddress = ""127.0.0.1"";
    rpcAddress = ""127.0.0.1"";
  };
</code></pre>

<p>The error I get is:</p>

<pre><code>$ cqlsh 127.0.0.1 9160
Connection error: ('Unable to connect to any servers', {'127.0.0.1': error(111, ""Tried connecting to [('127.0.0.1', 9160)]. Last error: Connection refused"")})
</code></pre>
",<cassandra><nixos>,"<p>I should have checked on the nixpks issue tracker, as I found the <a href=""https://github.com/NixOS/nixpkgs/issues/50954#issuecomment-441270430"" rel=""nofollow noreferrer"">answer there</a>; I needed:</p>

<pre><code>extraConfig = {
  start_native_transport = true;
};
</code></pre>
",['start_native_transport']
54787579,54800860,2019-02-20 13:34:03,ReadTimeout: Error from server: code=1200 [Coordinator node timed out waiting for replica nodes,"<p>I am getting below error on,</p>

<pre><code>ReadTimeout: Error from server: code=1200 [Coordinator node timed out waiting for replica nodes' responses] message=""Operation timed out - received only 0 responses."" info={'received_responses': 0, 'required_responses': 1, 'consistency': 'ONE'}
</code></pre>

<p>version details, [cqlsh 5.0.1 | Cassandra 3.11.4 | CQL spec 3.4.4 | Native protocol v4]</p>

<pre><code>cqlsh:infinito&gt; select count(id) from list_subscriber;
</code></pre>

<p>This table contains only 10 lacks of records, and primary key is on 'Id' column only having int type.</p>

<p>I am trying to increase some timeout params <code>(request_timeout_in_ms:)</code> but no luck</p>

<p>Any help is appreciated.</p>
",<cassandra><cassandra-3.0><cqlsh>,"<p>I ended up doing below options, increased below options value by 10 times.</p>

<p>edited /etc/cassandra/cassandra.yaml file</p>

<pre><code>sudo nano /etc/cassandra/cassandra.yaml

# How long the coordinator should wait for read operations to complete
read_request_timeout_in_ms: 50000
# How long the coordinator should wait for seq or index scans to complete
range_request_timeout_in_ms: 100000
# How long the coordinator should wait for writes to complete
write_request_timeout_in_ms: 20000
# How long the coordinator should wait for counter writes to complete
counter_write_request_timeout_in_ms: 50000
# How long a coordinator should continue to retry a CAS operation
# that contends with other proposals for the same row
cas_contention_timeout_in_ms: 10000
# How long the coordinator should wait for truncates to complete
# (This can be much longer, because unless auto_snapshot is disabled
# we need to flush first so we can snapshot before removing the data.)
truncate_request_timeout_in_ms: 600000
# The default timeout for other, miscellaneous operations
request_timeout_in_ms: 100000

# How long before a node logs slow queries. Select queries that take longer than
# this timeout to execute, will generate an aggregated log message, so that slow queries
# can be identified. Set this value to zero to disable slow query logging.
slow_query_log_timeout_in_ms: 5000
</code></pre>

<p>And then opened terminal and executed below command</p>

<pre><code>cqlsh --request-timeout=6000
</code></pre>

<p>Everything looks ok.</p>
",['auto_snapshot']
54938850,55132608,2019-03-01 06:06:52,Configuration for cassandra with rac and vnodes in single data center,"<p>I was wondering which configuration will be best suited for even distribution of data among nodes.</p>

<ol>
<li>5 nodes with 3 racs (2 nodes(node 1,node4) on rac1 , 2 nodes on rac2 (node2,node4) , 1 node on rac3 (node3))
Replication factor 3 and Read / Write on Quorum</li>
</ol>

<p>In this case I am wondering whether the node3 which is the only node in rac3 will have more data than other nodes since replication strategy suggests that replicas will be but in nodes on different rac.</p>

<ol start=""2"">
<li>6 nodes with 3 racs (2 nodes(node 1,node4) on rac1 , 2 nodes on rac2 (node2,node4) , 2 nodes on rac3 (node3, node6)) 
Replication factor 3 and Read / Write on Quorum</li>
</ol>

<p>In this case data will be distributed equally among all nodes.</p>

<p>Want to know whether my understanding is correct or not?</p>
",<cassandra>,"<p>In the case of 5 nodes across 3 racks, yes, one node will be under greater load/stress.</p>

<p>It's a good idea to scale the cluster in multiples of the rack count to keep the data balanced across nodes. For example, in a 3 rack cluster you should add 3 nodes each time you expand the cluster.</p>

<p>If you choose to use multiple racks the ideal rack count should be ≥ your chosen <em>replication factor</em>. This allows Cassandra to store each replica in a separate rack.</p>

<p>In the case of a rack outage the other replicas would be still available.</p>

<p>For example, with RF=3 and 3 racks and queries at <code>QUORUM</code>, you can sustain the failure of a single rack. Whereas, with RF=3 and 2 racks at <code>QUORUM</code>, there is no guarantee that 2 replicas will still be available in the case of a rack failure.</p>

<p>Racks are for informing Cassandra about fault domains. If your running in your own data center, as the name implies, racks should be assigned based on the rack the node is located in. If you're running in the cloud, the best option is to map racks to AWS <em>availability zones</em> (or whatever is equivalent for your provider).</p>
",['rack']
54983225,54985822,2019-03-04 12:24:37,Group by on Primary Partition,"<p>I am not able to perform Group by on a primary partition. I am using Cassandra 3.10. When I group by I get the following error.
<code>InvalidReqeust: Error from server: code=2200 [Invalid query] message=""Group by currently only support groups of columns following their declared order in the Primary Key</code>. My column is a primary key even still I am facing the problem.</p>

<p>My schema is</p>

<pre><code>Table trends{
name text,
price int,
quantity int,
code text,
code_name text,
cluster_id text
uitime timeuuid,
primary key((name,price),code,uitime))
with clustering order by (code DESC, uitime DESC)
</code></pre>

<p>And the command that I run is: <code>select sum(quantity) from trends group by code;</code></p>
",<cassandra>,"<p>For starters your schema is invalid. You cannot set clustering order on code because it is the partition key. The order is going to be determined by the hash of it (unless using byte order partitioner - but don't do that).</p>

<p>The query and thing your talking about does work though. For example you can run</p>

<pre><code>&gt; SELECT keyspace_name, sum(partitions_count) AS approx_partitions FROM system.size_estimates GROUP BY keyspace_name;

 keyspace_name      | approx_partitions
--------------------+-------------------
        system_auth |               128
              basic |           4936508
          keyspace1 |               870
 system_distributed |                 0
      system_traces |                 0
</code></pre>

<p>where they schema is:</p>

<pre><code>CREATE TABLE system.size_estimates (
    keyspace_name text,
    table_name text,
    range_start text,
    range_end text,
    mean_partition_size bigint,
    partitions_count bigint,
    PRIMARY KEY ((keyspace_name), table_name, range_start, range_end)
) WITH CLUSTERING ORDER BY (table_name ASC, range_start ASC, range_end ASC)
</code></pre>

<p>Perhaps the pseudo-schema you provided differs from the actual one. Can you provide output of <code>describe table xxxxx</code> in your question?</p>
",['partitioner']
55243714,55445088,2019-03-19 14:46:27,Cassandra-stress : how to install and set it up outside cassandra cluster,"<p>I am about to use simple cassnadra cluster (3 nodes, x.x.x.104-106). I'm using CentOS7, so i used datastax repository, Cassandra 3.0. 
I read on forum, it is better to install the cassandra-stress outside the cluster, otherwise it consumes CPU of the node.</p>

<p>Could you please help me, how to install it? </p>

<p>I tried to copied cassandra-stress.sh separately, but it is dependent on some cassandra files (probably created during installation). </p>

<p>So I decided to install whole Cassandra on separate server, in the same network space. Now, I'm struggling with the correct setup, how to run cassandra-stress tool against the cassandra cluster.</p>

<p>In cassandra.yaml I setup Cassandra name, listen_adress to public_ip, rpc_address to loopback address, I set seeds to cassandra cluster nodes (x.x.x.104-106)... but in general it does not make sense to set it up, since I dont wan't create another node in the Cassandra cluster.</p>

<p>Could you please help me?</p>

<p>Edit: Maybe using something like this might be the correct way?</p>

<p>cassandra-stress user profile=/usr/cassandra/stress-file.yaml ops(insert=1,books=1) n=10000 -node x.x.x.104,x.x.x.105,x.x.x.106 -port native= ?
Telnet [cassandra_node_ip_ddress] 7000 works fine</p>
",<cassandra><cassandra-3.0><cassandra-stress>,"<p>on every node:
in cassandra.yaml set rpc_address to IP address
in cassanda-env.sh set LOCAL_JMX=no and jmx options autenticate=false 
open firewall port 7199
restart firewall and cassandra</p>

<p>on cassandra-stress server:</p>

<pre><code>cassandra-stress user profile=/usr/cassandra/stress-books.yaml ops\ 
(insert=1,books=1\) 
n=10000 -node 172.16.20.104,172.16.20.105,172.16.20.106 -port native=9042 
thrift=9160 jmx=7199
</code></pre>

<p>Note! JMX communication is not secured</p>
",['rpc_address']
56802034,56829845,2019-06-28 06:38:34,restore with AWS EBS' snapshots on separate cluster,"<p>I have a cluster with 3 nodes - say cluster1 on AWS EC2 instances. The cluster is up and running, took snapshot of the keyspace's volume. </p>

<p>Now I want to restore few tables/keyspaces from the snapshot volumes, so I created another cluster say cluster2 and attached the snapshot volumes on to the new cluster's ec2 nodes (same number of nodes). Cluster2 is not starting bcz the system keyspace in the snapshot taken was having cluster name as cluster1 and the cluster on which it is being restored is cluster2. How do I do a restore in this case? I do not want to do any modifications to the existing cluster.</p>

<p>Also when I do restore do I need to think about the token ranges of the old and new cluster's mapping?</p>
",<amazon-ec2><cassandra>,"<p>Before starting the cluster2, it's important to ensure that none of the IP addresses of the cluster1 are included in the seed list of the cluster2 to ensure that they are kept unaware between them. Also, to remove from the path <code>data_file_directories</code> (as defined in the cassandra.yaml), the following directories:</p>

<ul>
<li>system</li>
<li>system_auth</li>
<li>system_distributed</li>
<li>system_traces</li>
</ul>

<p><strong><code>system_schema</code> should not be touched, as it contains the schema definition of the keyspaces and tables.</strong></p>

<p>Start the cluster, one node at a time; the first node should include its own IP address at the beginning of the seed list; This will be a one time change, and the change should be removed once that the cluster is up and running.</p>

<p>At this moment you should have a separate cluster, with the information and structure of the original cluster at the time that the snapshot was taken. To test this, execute <code>nodetool gossipinfo</code> and only the nodes of the cluster2 should be listed, login into cqlsh <code>describe keyspaces</code> should list all your keyspaces, and executing queries of your application should retrieve your data. You will note that Cassandra already generated the system* keyspaces, as well as dealt with the token distribution.</p>

<p>The next step is to update the name of the restored cluster, in each one of the nodes:</p>

<ol>
<li>Log into cqlsh</li>
<li>Execute <code>UPDATE system.local SET cluster_name = 'cluster2' where key='local';</code></li>
<li>exit cqlsh</li>
<li>run <code>nodetool flush</code></li>
<li>run <code>nodetool drain</code></li>
<li>edit the cassandra.yaml file, update <code>cluster_name</code> with the name 'cluster2'</li>
<li>restart the cassandra service</li>
<li>wait until the node is reported as NORMAL with <code>nodetool status</code> or <code>nodetool netstats</code></li>
<li>repeat with a different node</li>
</ol>

<p>At this point you will have 2 independent clusters, with different name.</p>
",['cluster_name']
57241604,57242883,2019-07-28 13:58:33,Cassandra Says Listening on Port 9042 But Couldn't Connect It,"<p>I've running cassandra on my local machine. </p>

<p>I've starting it <code>sudo service cassandra start</code>. And then check logs under <code>var/log/cassandra/system-log</code> and it says:</p>

<pre><code>INFO  [main] 2019-07-28 13:13:17,226 Server.java:162 - Starting listening for CQL clients on localhost/127.0.0.1:9042 (unencrypted)...
INFO  [main] 2019-07-28 13:13:17,270 CassandraDaemon.java:501 - Not starting RPC server as requested. Use JMX (StorageService-&gt;startRPCServer()) or nodetool (enablethrift) to start it
INFO  [SharedPool-Worker-1] 2019-07-28 13:13:27,133 ApproximateTime.java:44 - Scheduling approximate time-check task with a precision of 10 milliseconds
INFO  [OptionalTasks:1] 2019-07-28 13:13:27,298 CassandraRoleManager.java:339 - Created default superuser role 'cassandra'
</code></pre>

<p>Then I try to connect with <code>cqlsh</code> in terminal and it says: 
<code>Connection error: ('Unable to connect to any servers', {'127.0.0.1:9042': error(111, ""Tried connecting to [('127.0.0.1', 9042)]. Last error: Connection refused"")})</code></p>

<p>What is wrong? Also I couldn't see 9042 port with <code>netstat -tulpn</code> command.</p>
",<cassandra><cqlsh>,"<ol>
<li>Go to /etc/cassandra/cassandra-env.sh</li>
</ol>

<p>Uncomment  </p>

<p><code># JVM_OPTS=""$JVM_OPTS -Djava.rmi.server.hostname=&lt;public name&gt;""</code>   </p>

<p>and change it to </p>

<pre><code>JVM_OPTS=""$JVM_OPTS -Djava.rmi.server.hostname==localhost""
</code></pre>

<ol start=""2"">
<li>Set listen_address and broadcast_rpc_address to local ip (get ip address from ifconfig).</li>
<li>Restart Cassandra.</li>
</ol>
","['listen_address', 'broadcast_rpc_address']"
57691436,57698599,2019-08-28 11:32:45,Datastax Java driver 4.x : How to get cluster name?,"<p>After upgrading java driver for cassandra from 3.7 to 4.0 (or above) - I am unable to resolve the cluster name.</p>

<p>I need the name of the cassandra cluster to which the my application is connected using java driver. Earlier it was available as ""Cluster.getMetadata().getClusterName()"". But after upgrading to datastax-driver-core-4.0 or above- I am unable to resolve the Cluster name from CqlSession.getMetadata()..</p>

<p>This is very important because I have segregated operations based on different cluster.</p>
",<cassandra><datastax><datastax-java-driver><cassandra-cluster>,"<p>I believe cluster name is no longer provided by the java api.
Instead just query it from the system.local :</p>

<pre><code>SimpleStatement statement =SimpleStatement.newInstance(""SELECT cluster_name FROM system.local"");
ResultSet resultSet = session.execute(statement);
Row row = resultSet.one();
System.out.println(row.getString(""cluster_name""));
</code></pre>
",['cluster_name']
58406145,58409061,2019-10-16 05:14:11,Migrating data from a single node cassandra cluster to another single node cassandra cluster,"<p>I have a Single Node Cassandra Cluster which has around 44gb of data on it(/var/lib/cassandra/data/my_keyspace). The current storage is 1 tb and I need to migrate all the data to another VM which will have the same setup(single node cluster). My data-node has data being pushed to it every second so I can't afford any downtime(Some sensors are pushing time-series data).</p>

<pre><code>Keyspace :- CREATE KEYSPACE my_keysopace WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1'}  AND durable_writes = true;

Datacenter: datacenter1
=======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address    Load       Tokens       Owns (effective)  Host ID                               Rack

UN  127.0.0.1  43.4 GiB   256          100.0%            e0ae36db-f639-430c-91ad-6af3ffb6f906  rack1
</code></pre>

<p>After a bit of research I decided it's best to add the new node to existing cluster and then let the old node stream all the data and after streaming is done, decommission the old node.</p>

<p>Source :- <a href=""https://docs.datastax.com/en/archived/cassandra/2.0/cassandra/operations/ops_add_node_to_cluster_t.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/archived/cassandra/2.0/cassandra/operations/ops_add_node_to_cluster_t.html</a></p>

<ol>
<li>Configure old node as seed node for the new node    </li>
<li><strong>Add</strong> new node node to the ring(auto_bootstrap = true)    </li>
<li>Once the status is UN for both nodes, run nodetool <strong>cleanup</strong> on old node    </li>
<li><strong>Decommission</strong> the old node</li>
</ol>

<p>My only concern is will I be facing any <strong>data loss</strong>/ is this approach appropriate ?
Please let me know if I am missing anything here </p>

<p>Thanks</p>
",<cassandra><database-migration>,"<p><em>Firstly</em>, disclaimer, using a single node of C* voids the purpose of the distributed database. Minimal cluster size tends to be 3 so some nodes can go offline without downtime (I'm sure you've seen this warning before). Now with that out the way, let's discuss the process.</p>

<blockquote>
  <ol>
  <li>Configure old node as seed node for the new node</li>
  </ol>
</blockquote>

<p>Yep.</p>

<p>1.5. (Potentially missing step) The step you're missing is the consistency level of your queries needs to be verified. I see you're using <code>replication_factor</code> 1 for all keyspaces in use so make sure you're using a CONSISTENCY_LEVEL of ONE for your queries. </p>

<blockquote>
  <ol start=""2"">
  <li>Add new node node to the ring(auto_bootstrap = true)</li>
  </ol>
</blockquote>

<p>Sounds good. Make sure you've configured various ports / listen_address etc.</p>

<blockquote>
  <ol start=""3"">
  <li>Once the status is UN for both nodes, </li>
  </ol>
</blockquote>

<p>Once you reach UN double-check that the client isn't seeing any consistency errors.</p>

<blockquote>
  <p>3.5. run nodetool cleanup on old node</p>
</blockquote>

<p>3.5. (Redundant step) You don't need to run <code>nodetool cleanup</code>. You won't care about left over data from the decommissioned node, as all the data will be moved to the new node replacing it. </p>

<blockquote>
  <ol start=""4"">
  <li>Decommission the old node</li>
  </ol>
</blockquote>

<p>Yep. </p>

<ol start=""5"">
<li>(Missing step) You'll have to modify the new node to see itself as a seed once you've decomissioned the old node or it wont be able to re-start.</li>
</ol>
",['listen_address']
58409127,58409830,2019-10-16 08:39:20,Cassandra: Shipping Disk to New DC in order to sync 50TB of data,"<p>We're adding a new datacenter to our Cassandra cluster. Currently, we have a 15-node DC with RF=3 resulting in about 50TB~ of data.</p>

<p>We are adding another datacenter in a different country and we want both data centers to contain all the data. Obviously, synchronizing 50TB of data across the internet will take a gargantuan amount of time.</p>

<p>Is it possible to copy a full back to a few disks, ship that to the new DC and then recover? I'm just wondering what would be the procedure to do so.</p>

<p>Could someone give me a few pointers on this operation, if possible at all?
Or any other tips?</p>

<p>Our new DC is going to be smaller (6 nodes) for the time being, although enough space will be available. The new DC is mostly meant as a live-backup/failover and will not be the primary cluster for writing, generally speaking.</p>
",<database><cassandra><replication><database-replication><cassandra-3.0>,"<p>TL;DR; Due to the topology (node count) change between the two DCs, avoiding streaming the data in isn't possible AFAIK. </p>

<blockquote>
  <p>Our new DC is going to be smaller (6 nodes) for the time being</p>
</blockquote>

<p>The typical process isn't going to work due to token alignment on the nodes being different (new cluster's ring will change). So just copying the existing SSTables wont work, as the nodes that hold those tables, might not have the tokens corresponding to the data in the files and so C* wont be able to find said data.</p>

<p>Bulk loading the data to the new DC is out too, as you'll be overwriting the old data if you re-insert it. </p>

<p>To give you an overview of the process if you were to retain the topology:</p>

<ol>
<li>snapshot the data from the original DC</li>
<li>Configure the new DC. It's extremely important that you set initial_token for each machine. You can get a list of what tokens you need by running <code>nodetool ring</code> on the original cluster. This is why you need the same number of nodes. As importantly, when copying the SSTable files over, you need the files and the tokens to be from the same node.</li>
<li>ship the data to the new DC (Remember if the new node 10.0.0.1 got it's tokens from 192.168.0.100 in the old dc, then it also has to get it's snapshot data from 192.168.0.100).  </li>
<li>Start the new DC and ensure both DCs see eachother ok.</li>
<li>Rebuild and repair <code>system_distributed</code> and <code>system_auth</code> (assuming you have authentication enabled)</li>
<li>Update client consistency to whatever you need. (Do you want to write to both DCs? From your description sounds like a no so you might be all good). </li>
<li>Update the schema, ensure that you're using <code>NetworkTopologyStrategy</code> for any keyspce that you want to be shared, then add some replication for the new DC.</li>
</ol>

<pre><code>    ALTER KEYSPACE ks WITH REPLICATION = { 'class' : 'NetworkTopologyStrategy', 'oldDC' : 3, 'newDC':3 };
</code></pre>

<ol start=""8"">
<li>Run a full repair on each node in the new dc. </li>
</ol>
",['initial_token']
58466825,58492704,2019-10-19 18:32:07,How do I connect to a Cassandra VM,"<p>The following code works if Cassandra and the code are on the same machine:</p>

<pre><code>using System;
using Cassandra;

namespace CassandraInsertTest
{
    class Program
    {
        static void Main(string[] args)
        {
            var cluster = Cluster.Builder()
            .AddContactPoint(""127.0.0.1"")
            .Build();

            var session = cluster.Connect(""test_keyspace"");

            session.Execute(""INSERT INTO test_table (id, col1, col2) VALUES (1, 'data1', 'data2')"");

            Console.WriteLine($""Finished"");
            Console.ReadKey();
        }
    }
}
</code></pre>

<p>Assuming a username and password is needed if the code is on one machine and cassandra is on a different machine (different ip address)?  So I have tried:</p>

<pre><code>        var cluster = Cluster.Builder()
        .AddContactPoint(""192.168.0.18"") &lt;- the ip address for the cassandra node
        .WithPort(9042)
        .WithCredentials(""username to log into the cassandra node"",""password to log into the cassandra node"")
        .Build();
</code></pre>

<p>I get the following error message:</p>

<pre><code>userone@desktop:~/Desktop/vsc$ dotnet run
Unhandled exception. Cassandra.NoHostAvailableException: All hosts tried for query failed (tried 192.168.0.18:9042: SocketException 'Connection refused')
   at Cassandra.Connections.ControlConnection.Connect(Boolean isInitializing)
   at Cassandra.Connections.ControlConnection.InitAsync()
   at Cassandra.Tasks.TaskHelper.WaitToCompleteAsync(Task task, Int32 timeout)
   at Cassandra.Cluster.Cassandra.SessionManagement.IInternalCluster.OnInitializeAsync()
   at Cassandra.ClusterLifecycleManager.InitializeAsync()
   at Cassandra.Cluster.Cassandra.SessionManagement.IInternalCluster.ConnectAsync[TSession](ISessionFactory`1 sessionFactory, String keyspace)
   at Cassandra.Cluster.ConnectAsync(String keyspace)
   at Cassandra.Tasks.TaskHelper.WaitToComplete(Task task, Int32 timeout)
   at Cassandra.Tasks.TaskHelper.WaitToComplete[T](Task`1 task, Int32 timeout)
   at Cassandra.Cluster.Connect(String keyspace)
   at HelloWorld.Program.Main(String[] args) in /home/userone/Desktop/vsc/Program.cs:line 17
userone@desktop:~/Desktop/vsc$ 
</code></pre>

<p>The iptables on the node (the cassandra server) is currently set as follows:</p>

<pre><code>node1@node1:~$ sudo iptables -S
-P INPUT ACCEPT
-P FORWARD ACCEPT
-P OUTPUT ACCEPT
-A INPUT -i lo -j ACCEPT
-A IMPUT -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
-A INPUT -p tcp -m tcp --dport 22 -j ACCEPT
-A INPUT -p tcp -m tcp --dport 80 -j ACCEPT
-A INPUT -s 192.168.0.73/32 -p tcp -m multiport --dports 7000,7001,7199,9042,9160,9142 -m state --state NEW,ESTABLISHED -j ACCEPT
node1@node1:~$
</code></pre>

<p>Note 1: Both the machine with the app and the machine with cassandra installed can be pinged and tracerouted in both directions.</p>

<p>Note 2: I have tested the username and password and can log into the cassandra server without any issues when tried directly on the server.</p>

<p>Note 3: Cassandra is running in a VM which I just created today.  The VM is a guest machine on the host machine which runs the code.</p>

<p>Note 4: Both the Host OS and Guest OS are Linux.</p>
",<c#><.net><.net-core><cassandra>,"<pre><code>.AddContactPoint(""127.0.0.1"")
</code></pre>

<p>If that works from the same machine, then you probably have Cassandra <em>bound</em> to that IP.  If you need to connect to your node(s) remotely, then you need to bind a routeable IP to that node.</p>

<p>Run a <code>nodetool status</code>.  If you see your cluster status showing your node with an IP of 127.0.0.1, then connecting <em>to</em> the local machine <em>from</em> the local machine is the only scenario that will <em>ever</em> work.</p>

<p>Try running the following command on your node:</p>

<pre><code>grep _address cassandra.yaml
</code></pre>

<p>The IP address returned in the output is the only one that an application is allowed to connect to.  If you want to be able to connect to 192.168.0.18, then the <code>listen</code> and <code>rpc</code> addresses should look something like this:</p>

<pre><code>listen_address: 192.168.0.18
rpc_address: 192.168.0.18
</code></pre>

<p>Note that you'll need to change your <code>seeds</code> list, too.</p>

<p>Also, if you're on a VM/provider that has both internal and external IP addresses, then you'll also need to set your <code>broadcast_</code> addresses to the external IP:</p>

<pre><code>broadcast_address: 10.6.5.5
broadcast_rpc_address: 10.6.5.5
listen_address: 192.168.0.18
rpc_address: 192.168.0.18
</code></pre>

<p>But try setting just <code>listen</code> and <code>rpc</code> to 192.168.0.18 first.</p>

<p><strong>Edit 20191022</strong></p>

<blockquote>
  <p>Just wanted to double check, do I add 192.168.0.18 as the listen_address and rpc_address to the cassandra node where the cassandra node has the ip address 192.168.0.18?</p>
</blockquote>

<p>Yes.  Also make sure that your node's seed list is set like this:</p>

<pre><code>- seeds: ""192.168.0.18""
</code></pre>

<blockquote>
  <p>Before I did that, the value of the listen_address and rpc_address were set to localhost</p>
</blockquote>

<p>I thought so.</p>

<blockquote>
  <p>However, after making the changes you suggested, nodetool status now gives me</p>
</blockquote>

<pre><code>Failed to connect to 127.0.0.1:7199 - connection refused
</code></pre>

<p>Ironically, that's the same message nodetool returns when Cassandra is not running.  At this point I would check the system log and see if it is returning errors that may be preventing it from starting.  I suspect that the seed list still reads ""127.0.0.1"".</p>

<p><strong>tl;dr;</strong></p>

<p>If you intend to connect to your cluster/node remotely, then you <em>cannot</em> use the default configurations which bind Cassandra to the home IP (127.0.0.1/localhost).  And that includes all <code>_address</code> settings, as well as your <code>seeds</code> list.</p>
","['listen_address', 'rpc_address']"
59617657,59618346,2020-01-06 19:11:28,EACH_QUORUM VS QUORUM,"<p>This is a screenshot from the consistency level table according <a href=""https://docs.datastax.com/en/dse/5.1/cql/cql/cql_reference/cqlsh_commands/cqlshConsistency.html"" rel=""nofollow noreferrer"">to Datastax documentation</a>:</p>

<p><a href=""https://i.stack.imgur.com/6WxoS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6WxoS.png"" alt=""enter image description here""></a></p>

<p>What is the difference between EACH_QUORUM and QUORUM? <code>Each</code> and <code>all</code> DC's are the same AFAIK. In the QUORUM row the following is stated:</p>

<blockquote>
  <p>Some level of failure is possible</p>
</blockquote>

<p>Why? If one node is down in each DC? The same applies for EACH_QUORUM right? Why does EACH_QUORUM does not have some level of failure, since it is ALL_QUORUM and not ALL?</p>

<p>Both levels have the same in common (AFAIK):</p>

<ul>
<li>All/each (same right?) DC's needs to be online</li>
<li>51% or more of the nodes need to confirm the read/write.</li>
</ul>
",<cassandra>,"<p>The difference between QUORUM and EACH_QUORUM is as follows.</p>

<p>Assume you have 6 nodes in your cluster - 2 DCs with 3 nodes each and RF=3 for both DCs (all nodes have all data).</p>

<p>The QUORUM and EACH_QUORUM value is the same = 4 (6/2 + 1). However, which nodes can respond varies slightly. EACH_QUORUM has less combinations of what will satisfy the condition.</p>

<p>QUORUM requires 4 nodes to respond but with any combination of nodes. So for example, maybe 3 nodes from the local DC and 1 node from the remote DC respond. That's perfectly fine. </p>

<p>Now, with QUORUM_EACH, each DC must have a quorum respond. What the means is that 2 nodes from each DC must respond in this case, that's it (which 2 nodes in each DC is irrelevant) . 3 nodes from the local DC and 1 node from a remote DC does not qualify as 1 node in the remote dc is not a quorum of that dc. </p>

<p>Let's change the cluster node count to 7 instead of 6. DC1 has 4 nodes, DC2 has 3 nodes. DC1 RF = 4 and DC2 RF = 3 (all nodes have the data again). Here's where the fun begins with the odd number total in the RF.</p>

<p>While I'm not sure about the word ""failure"", but I can see certain scenarios where this could be problematic.</p>

<p>For QUORUM, 4 nodes need to respond (7/2 + 1 = 4) - any 4 nodes - including the scenario when all nodes from the local/larger DC responds (DC1 in this case). What if the most current data is on DC2? In this scenario, you could end up with undesirable results.</p>

<p>With QUORUM_EACH, 5 nodes would need to respond (Quorum of DC1 = 4/2+1 = 3, Quorum of DC2 = 3/2+1 = 2 ==> total = 5). With this scenario, you're forcing cassandra to return data from both DCs - and a QUORUM level from each DC which should give you good results.</p>

<p>Again, I'm trying in my head to determine where the additional ""failures"" could come with QUORUM v.s. QUORUM_EACH and I can't at the top of my head see it. It would seem if anything, QUORUM_EACH with an odd node count, is less flexible in unavailable nodes as a quorum in each DC must respond v.s. any quorum number of nodes from any DC. I can see where QUORUM may give you undesirable results though (explained above).</p>
",['dc']
59671310,59965580,2020-01-09 20:01:03,Databricks Spark Cassandra connectivity throwing exception: com.datastax.driver.core.exceptions.NoHostAvailableException,"<p>I have installed the Cassandra DB in Azure Virtual Machine and want to perform read/write operation through the Azure Databricks. I am going through the Databricks offcial <a href=""https://docs.databricks.com/data/data-sources/cassandra.html"" rel=""nofollow noreferrer"">documentation</a> which does not help me in configuration.<br>
I am sharing below my code cum configurations details:</p>

<pre><code>%sh
ping -c 2 vmname.westeurope.cloudapp.azure.com
</code></pre>

<p><strong>Response received:</strong></p>

<pre><code>PING vmname.westeurope.cloudapp.azure.com (13.69.10.10): 56 data bytes
--- vmname.westeurope.cloudapp.azure.com ping statistics ---
2 packets transmitted, 0 packets received, 100% packet loss
</code></pre>

<pre><code>// define the cluster name and cassandra host name
val sparkClusterName = ""adbazewdobucluster""
val cassandraHostIP = ""vmname.westeurope.cloudapp.azure.com""

dbutils.fs.put(s""/databricks/init/$sparkClusterName/cassandra.sh"",
  s""""""
     #!/usr/bin/bash
     echo '[driver].""spark.cassandra.connection.host"" = ""$cassandraHostIP""' &gt;&gt; /home/ubuntu/databricks/common/conf/cassandra.conf
   """""".trim, true)

// setting IP of the Cassandra server
spark.conf.set(""spark.cassandra.connection.host"", ""127.0.0.1"")

//verify sparkconf is set properly
spark.conf.get(""spark.cassandra.connection.host"")

</code></pre>

<p>and after applying all the configuration in spark I am trying to retrieve the records from the table resides in Cassandra DB, which is throwing the exception.</p>

<pre><code>val df = sqlContext
  .read
  .format(""org.apache.spark.sql.cassandra"")
  .options(Map( ""table"" -&gt; ""words_new"", ""keyspace"" -&gt; ""test""))
  .load
df.explain
</code></pre>

<p><strong>Exception:</strong></p>

<pre><code>com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /127.0.0.1:9042 (com.datastax.driver.core.exceptions.TransportException: [/127.0.0.1:9042] Cannot connect))
</code></pre>

<p>I have checked the my Cassandra DB is running and read/write operation working fine directly.<br>
So my <strong>question is</strong>: Am I applying the configuration in a right way? If not so then How do I access the Cassandra from the Databricks notebook.<br>
I am using Scala for the Spark framework and my cluster and driver versions are as following:</p>

<pre><code>Databricks Runtime Version
6.2 (includes Apache Spark 2.4.4, Scala 2.11)

spark-cassandra-connector
com.datastax.spark:spark-cassandra-connector_2.11:2.4.1

cassandra version: 3.11.4
</code></pre>
",<apache-spark><cassandra><apache-spark-sql><azure-databricks><spark-cassandra-connector>,"<p>If you're running on Azure.. make sure to set broadcast_rpc_address to public IP address or dns hostname these settings must work for you -</p>

<p>Set rpc address to ip address of your network interface attached to your VM..on Windows - Hyper V Interface.</p>

<pre><code>rpc_address: &lt;**private ip** of your vm &gt; 
</code></pre>

<p>broadcast rpc address to public ip, on this ip external clients should get response from cassandra on port 9042</p>

<pre><code>broadcast_rpc_address: &lt;**public ip** or hostname.westeurope.cloudapp.azure.com&gt;
</code></pre>

<p>listen address as default to localhost / 127.0.0.1</p>

<pre><code>listen_address: **localhost**
</code></pre>
",['broadcast_rpc_address']
59830846,59834889,2020-01-20 21:06:33,Cassandra Virtual Nodes,"<p>Although it is asked many times and answered many times, I did not find a good answer anyway.
Neither in forums nor in cassandra docs.</p>

<p>How do virtual nodes work?</p>

<p>Suppose a node having 256 virtual nodes.
And docs say they are distributed randomly.
(put away how that ""randomly"" done...I have another,more urgent question):</p>

<ol>
<li><p>Is that right that every cassandra node (""physical"") actually responsible for several distinct locations in the ring? (for 256 locations)? Does that mean the ""physical"" node sort of ""spread"" on the whole circle? </p></li>
<li><p>How in that case re-balancing works? If I add a new node?
The ring will get an additional 256 nodes.
How those additional nodes will divide the data with the old nodes?
Will they, basically, appear as additional ""bicycle spokes"" randomly spread through the whole ring?</p></li>
</ol>

<p>A lot of info on the internet, but nobody makes a clear explanation...</p>
",<cassandra>,"<p>Vnodes break up the available range of tokens into smaller ranges, defined by the num_tokens setting in the cassandra.yaml file. The vnode ranges are randomly distributed across the cluster and are generally non-contiguous. If we use a large number for num_tokens to break up the token ranges, the random distribution means it is less likely that we will have hot spots.Using statistical computation, the point where all clusters of any size always had a good token range balance was when 256 vnodes were used. Hence, the num_tokens default value of 256 was the recommended by the community to prevent hot spots in a cluster.</p>

<p><strong>Ans 1:-</strong> It is a range of tokens based on num_tokens. if you have set 256 the you will get 256 token ranges which is default.</p>

<p><strong>Ans 2:-</strong> Yes, when you are adding or removing the nodes the tokens will distribute again in the cluster based on vnodes configurations.</p>

<p>you may refer for more details are here <a href=""https://docs.datastax.com/en/ddac/doc/datastax_enterprise/dbArch/archDataDistributeVnodesUsing.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/ddac/doc/datastax_enterprise/dbArch/archDataDistributeVnodesUsing.html</a></p>
",['num_tokens']
59961978,59965495,2020-01-29 07:03:40,unable to access cassandra from azure data bricks,"<p>whenever i am trying to access my cassandra cluster from azure databricks getting below error,</p>

<p>java.io.IOException: Failed to open native connection to Cassandra at {xx.xx.xx.xx}:9142</p>

<p>Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried for query failed (tried: /xx.xx.xx.xx:9142 (com.datastax.driver.core.exceptions.TransportException: [/xx.xx.xx.xx:9142] Cannot connect))</p>

<p>Cassandra was installed on azure vm ,both my azure vm &amp; data bricks are in same VNET.</p>

<p>can you please someone help me on this?</p>
",<azure><apache-spark><cassandra><databricks>,"<p>If you're running on Azure or AWS.. make sure to set broadcast_rpc_address to public IP address or dns hostname
these settings must work for you -</p>

<p>rpc_address: &lt;<strong>private ip of your vm</strong> > </p>

<p>broadcast_rpc_address: &lt;<strong>public ip</strong> or <strong>hostname.westeurope.cloudapp.azure.com</strong>></p>

<p>listen_address: <strong>localhost</strong> </p>
",['broadcast_rpc_address']
60635798,60638898,2020-03-11 12:13:39,Issues with new node bootstrap,"<p>We are using Cassandra 3.11.2 and when trying to bootstrap a new node, the streaming takes a lot of time. The cluster is a three node one, and we are in the process of adding the fourth one. The data available on the other three nodes is close to 190GB, and the instance size is 5 core, 5GB running on spinning drives.</p>

<p><code>nodetool netstats</code> on the new node says streaming files, and of 106 files, 15 received from node A.  But same <code>netstats</code> on node A claims all 106 files have been sent.</p>

<p>Also, we were running into some keep alive related issues and we did increase the same on the new node. This is our second attempt, and in the first attempt, the bootstrap kept failing, and we either resume it or restart the Cassandra on the new node, and the data grew close to 500GB, and then compaction happened and came down to 236GB.</p>

<p>But then bootstrap kept failing. So we discarded it and started fresh again. This time, as suggested in the hardware choices doc, we went with a different physical disk for commit log and data to see if iops was the issue.</p>

<p>And the process never ends. Meaning, it fails in-between with connection reset by peer or IO exception and we have been struggling with this for almost a week now.</p>

<p>How much do you think it ideally takes for bootstrapping a node with data close to 190GB? Any advice/suggestions would be of great help. 
The new node is started with auto_bootstrap flag set to true.</p>
",<cassandra>,"<blockquote>
  <p>How much do you think it ideally takes for bootstrapping a node with data close to 190GB?</p>
</blockquote>

<p>Unfortunately, there's no easy way to answer this.  A lot of factors go into determining how quickly new nodes will bootstrap, essentially being very specific to the underlying infra.</p>

<blockquote>
  <p>We are using Cassandra 3.11.2 </p>
</blockquote>

<p>I recommend upgrading (at least) to 3.11.4.  It's a simple binary upgrade that does not require running a <code>nodetool upgradesstables</code>.  The reason, is that 3.11.4 has a feature which allows failed bootstrapping to resume where it left off.  At least then, you won't have to completely start over each time.</p>

<blockquote>
  <p>data grew close to 500GB, and then compaction happened and came down to 236GB.</p>
</blockquote>

<p>So there are some reasons that this can happen.  Are the rack definitions (cassandra-rackdc.properties) the same or different?  If you're bootstrapping the node as a new logical rack, you might see the one new node being responsible for owning 100% of available token ranges.  Whereas, if you join a new node with the same logical rack as the others, the ownership percentage (and disk footprint) will go down.</p>

<blockquote>
  <p>Any advice/suggestions would be of great help.</p>
</blockquote>

<p>I've encountered issues like this as well, when bootstrapping nodes into new physical data centers. One thing that I've had success with, was setting <code>auto_bootstrap: false</code> and running a <code>nodetool rebuild</code> to stream from the remote DC.  Of course, if you don't have another DC to stream from, that's not going to work.</p>

<p>You could also start the node without bootstrapping enabled, and run a <code>nodetool repair</code> once it comes up.  This has some drawbacks in that the new node will still try to serve client requests, regardless of whether or not it actually has the data.  But it would let you at least get the node joined, and stream the data over on a more gradual basis.</p>

<p>That's why <strong>upgrading to 3.11.4</strong> is probably your best option.  Then you can restart the node when the streams fail, it'll pick up where it left off, and it won't take client requests until data streaming completes.</p>
",['rack']
61178735,61182424,2020-04-12 21:57:20,What is the difference between Consistent Hashing and Partitioner in Cassandra,"<p>I'm new to Cassandra, I got confused between <code>consistent hashing</code> and <code>partitioner</code>.
Are they both same ?</p>
<p>Please find the definitions from Datastax documentation:</p>
<blockquote>
<p>A partitioner determines how data is distributed across the nodes in the cluster (including replicas). Basically, a partitioner is a function for deriving a token representing a row from its partition key, typically by hashing. Each row of data is then distributed across the cluster by the value of the token.</p>
<p>Consistent hashing allows distribution of data across a cluster to minimize reorganization when nodes are added or removed. Consistent hashing partitions data based on the partition key. (For an explanation of partition keys and primary keys, see the Data modeling example in CQL for Cassandra 2.2 and later.)</p>
</blockquote>
",<cassandra>,"<p>With consistent hashing, the buckets are arranged in a ring with a predefined range; the exact range depends on the partitioner being used. Keys are then hashed to produce a value that lies somewhere along the ring.</p>

<p>I think you have already got the definition that is correct but for other ways you can understand the things from below.
<a href=""https://dzone.com/articles/introduction-apache-cassandras"" rel=""nofollow noreferrer"">https://dzone.com/articles/introduction-apache-cassandras</a>. There is good explanation about both. </p>
",['partitioner']
62086888,62103361,2020-05-29 13:16:13,How should I set the replication factor in Cassandra to account for node failure?,"<p>Lets say we have a cassandra deployment with a replication factor of 2. By this I mean that we can tolerate the total loss of one node of persistent storage without overall data loss. I understand this to mean that each of the values are stored on at least two different nodes at any given time. Therefore the total storage required is at least the total data of the values x 2. Ie, if we need to store 100TB in the cluster, we would need at least 200TB persistent storage across the nodes. </p>

<p>However, as the node count increases, so does the likelyhood of more than 1 node failing. Therefore, do we need to increase the replication factor as the number of nodes increases?</p>

<p>For example:</p>

<p>Lets assume that all components are 100% reliable, except for my nodes local storage controllers, which for time to time completely corrupt all local storage with no possibility for restoration (ie, data loss is total). All rack equipment, switches, power, cooling etc are all perfect. I know this is not realistic.</p>

<p>Lets also assume that any data loss is really, really bad for this application. </p>

<p>Lets say my nodes have 1TB each of storage. For 100TB of values, I would need 200 machines to achieve a replication factor of 2 (ie, I can lose any one node and still retain data). However, if I believe that the simultaneous failure of 2 nodes in that set of 200 is likely I will need to raise the replication factor to 3. Therefore now I need three copies of each value (on three different nodes) and now I need 300 nodes. I now feel that the simultaneous loss of 3 or more nodes is likely, so I have to add more nodes again, etc...</p>

<p>Surely this isn't actually how this scales? What is wrong with my logic?</p>
",<cassandra><replication><distributed>,"<p>There are several types of failures that you need to take into account:</p>

<ol>
<li>Individual node failure (hardware/os/...) - your node is failed, either completely (data is lost), or partially (for example, power adapter has failed)</li>
<li>Rack/data center failure - when nodes in specific part of data center, or data center completely failed, or not available over network</li>
</ol>

<p>Replication helps to avoid complete data unavailability, but it may also depend on the deployment strategy.</p>

<p>For example, if all your servers in one data center, if it's not available, you'll lose access to the data. Or if you didn't setup cluster to have rack-aware data placement, replicas could be put into the same rack, and if it's going down, you lose your replica.</p>

<p>Typically, it's recommended to use replication factor 3, and if you're planning big deployment, definitely use rack-aware data placement - but you should be careful, so number of racks should match RF (in cloud deployments, usually the rack is mapped to the availability zone). </p>

<p>Availability is also depends on your business requirements - in simplest case, if you use  consistency levels <code>ONE</code> or <code>LOCAL_ONE</code>, your data is available even only one replica is available, but if your business logic requires stronger consistency, you need to have more replicas available. And replication factor also affects the consistency levels - if you use RF=2, and require CL=QUORUM, you can't tolerate single node failure, while it's possible to achieve that CL with RF=3 and one node failed.</p>
",['rack']
63068006,63068254,2020-07-24 06:24:30,Cassandra configuration config by cqlsh,"<p>Cassandra version: <code>3.9</code>, CQLSH version: <code>5.0.1</code></p>
<p>Can I query Cassandra configuration (<code>cassandra.yaml</code>) using <code>cqlsh</code>?</p>
",<cassandra><cql><cassandra-3.0><cqlsh>,"<p>No, it's not possible in your version.  It's possible only starting with Cassandra 4.0 that has so-called virtual tables, and there is a special table for configurations: <code>system_views.settings</code>:</p>
<pre><code>cqlsh:test&gt; select * from system_views.settings ;
 name                                            | value
-------------------------------------------------+-------
     transparent_data_encryption_options_enabled | false
   transparent_data_encryption_options_iv_length |    16
                                   trickle_fsync | false
                    trickle_fsync_interval_in_kb | 10240
                  truncate_request_timeout_in_ms | 60000
....
</code></pre>
<p>You can find more information on the virtual tables in the <a href=""https://thelastpickle.com/blog/2019/03/08/virtual-tables-in-cassandra-4_0.html"" rel=""nofollow noreferrer"">following blog post from TLP</a>.</p>
<p>In the meantime, you can access configuration parameters via JMX.</p>
",['trickle_fsync']
63072179,63072663,2020-07-24 10:56:15,"Adding a new cassandra node to an existing cluster, with a different snitch","<p>I have a cassandra cluster with 5 nodes that is using EC2 snitch but for the new node I want to add I want to use GossipingPropertyFileSnitch. Is it okay to have this node with a different snitch, will it cause any impact to the schema or schema versions?</p>
",<database><cassandra><datastax>,"<p>All nodes in a cluster should use the same snitch since it is critical in determining the cluster topology and position of the replicas (to avoid them all being on the same rack for example.).</p>
<p>Just as an experiment, I changed a node in a 3 node sandbox cluster to use a different snitch and while it did start up, when running nodetool status on the 2 nodes with different snitches, they reported very different topologies - as you would know, this is not a good thing at all.</p>
<p>If you wish to move the whole cluster to GossipingPropertyFileSnitch, then there is a documented process on how to change the snitch of a cluster:
<a href=""https://docs.datastax.com/en/dse/6.8/dse-admin/datastax_enterprise/operations/opsSwitchSnitch.html"" rel=""nofollow noreferrer"">https://docs.datastax.com/en/dse/6.8/dse-admin/datastax_enterprise/operations/opsSwitchSnitch.html</a></p>
<p>You will find that there are versions of that page for different versions of DSE. You would change the snitch first via the process, then add the additional node.</p>
",['rack']
63565125,63566831,2020-08-24 16:34:47,"Writing JSON data into Cassandra using python client, issue with primary key choice","<p>So I want to write data, which is coded as a JSON string into a Cassandra table. I did the following steps:</p>
<ul>
<li>Create a Cassandra table containing columns with all the attributes of my JSON string. Here is the cql for that:</li>
</ul>
<pre><code>CREATE TABLE on_equipment (
  ChnID varchar,
  StgID varchar,
  EquipID varchar,
  SenID varchar,
  value1 float,
  value2 float,
  value3 float,
  electric_consumption float,
  timestamp float,
  measurement_location varchar,
  PRIMARY KEY ((timestamp))
) WITH comment = 'A table for the on equipment readings';
</code></pre>
<ul>
<li>Write a python Cassandra client to write the data into Cassandra from a JSON payload.
Here is the code snippet to make the INSERt query (msg.value is the json string):</li>
</ul>
<pre><code>session.execute('INSERT INTO ' + table_name + ' JSON ' + &quot;'&quot; + msg.value + &quot;';&quot;)
</code></pre>
<p>I get no writing errors when doing this.</p>
<p>However, I ran into a problem:</p>
<p>The JSON data I have is from IoT sources, and one of the attributed I have is a unix timestamp. An example of a JSON record is as follows (notice the timestamp attribute):</p>
<pre><code>{'timestamp': 1598279069.441547, 'value1': 0.36809349674042857, 'value2': 18.284579388599308, 'value3': 39.95615809003724, 'electric_consumption': 1.2468644044844224, 'SenID': '1', 'EquipID': 'MID-1', 'StgID': '1', 'ChnID': '1', 'measurement_location': 'OnEquipment'}
</code></pre>
<p>In order to insert many records, I have defined the timestamp value as the primary key of the data in the Cassandra table. The problem is that not all records are being written into Cassandra, only records who's timestamps fall into a certain group. I know this because I have produced around 100 messages and received zero write errors, yet the contents of the table only has 4 rows:</p>
<pre><code> timestamp  | chnid | electric_consumption | equipid | measurement_location | senid | stgid | value1   | value2   | value3
------------+-------+----------------------+---------+----------------------+-------+-------+----------+----------+----------
 1.5983e+09 |     1 |             0.149826 |   MID-1 |          OnEquipment |     1 |     1 | 0.702309 | 19.92813 | 21.47207
 1.5983e+09 |     1 |              1.10219 |   MID-1 |          OnEquipment |     1 |     1 | 0.141921 |  5.11319 | 78.17094
 1.5983e+09 |     1 |              1.24686 |   MID-1 |          OnEquipment |     1 |     1 | 0.368093 | 18.28458 | 39.95616
 1.5983e+09 |     1 |              1.22841 |   MID-1 |          OnEquipment |     1 |     1 | 0.318357 |  16.9013 |  71.5506
</code></pre>
<p>In other words, Cassandra is updating the values of these four rows, when it should be writing all the 100 messages.</p>
<p>My guess is that I incorrectly using the Cassandra primary key. The timestamp column is type float.</p>
<p>My questions:
Does this behaviour make sense? Can you explain it?
What can I use as the primary key to solve this?
Is there a way to make the primary key a Cassandra writing or arrival time?</p>
<p>Thank you in advance for your help!</p>
",<json><cassandra><cassandra-3.0>,"<p>You have defined the primary key as just the timestamp - if you insert data into a Cassandra table, and the data you are writing has the same primary key as data already in the table, you will overwrite it. All inserts are in effect insert/update, so when you use the same primary key value a 2nd time, it will update.</p>
<p>As to the solution - this is tricker - the primary key has to hold true to it's name - it is primary, e.g. unique - even if it was a timestamp instead of a float you should also have at least 1 other field (such as the IoT unique identifier) within the primary key so that 2 readings from two different devices made at the exact same time do not clash.</p>
<p>In Cassandra you model the data and the keys based on how you intend to access the data - without knowing that it would not be possible to know what the primary key (Partition + Clustering key) should be. You also ideally need to know something about the data cardinality and selectivity.</p>
<p>Identify and define the queries you intend to run against the data, that should guide your partition key and clustering key choices - which together make the primary key.</p>
<p>The specific issue here to add to the above is that the data is exceeding the precision that the float can be stored at - capping the value in effect and making them all identical. If you change the float to a double, it then stores the data without capping the values into the same value - which then causes the upsert instead of a new row inserted. (The JSON insert part is not relevant to the issue as it happens)</p>
<p>Recreating the issue as follows:</p>
<pre><code> CREATE TABLE on_equipment (
  ChnID varchar,
  timestamp float,
  PRIMARY KEY ((timestamp))
) ;

insert into on_equipment(timestamp, chnid) values (1598279061,'1');
insert into on_equipment(timestamp, chnid) values (1598279062,'2');
insert into on_equipment(timestamp, chnid) values (1598279063,'3');
insert into on_equipment(timestamp, chnid) values (1598279064,'4');

select count(*) from on_equipment;

1

select timestamp from on_equipment;

1.59827904E9
</code></pre>
<p>You can see the value has been rounded and capped, all 4 values capped the same, if you use smaller numbers for the timestamps it works, but isn't very useful to do so.</p>
<p>Changing it to a double:</p>
<pre><code>CREATE TABLE on_equipment (
  ChnID varchar,
  timestamp double,
  PRIMARY KEY ((timestamp))
) ;

insert into on_equipment(timestamp, chnid) values (1598279061,'1');
insert into on_equipment(timestamp, chnid) values (1598279062,'2');
insert into on_equipment(timestamp, chnid) values (1598279063,'3');
insert into on_equipment(timestamp, chnid) values (1598279064,'4');

select count(*) from on_equipment;

4
</code></pre>
",['precision']
67353944,67354375,2021-05-02 07:23:35,Will the Write-Ahead-Log become the bottleneck of Cassandra?,"<p>In a Cassandra database, a write needs to be logged in the Write Ahead Log first and then added to the memtable in memory. Since the Write Ahead Log is on disk, although it performs sequential writes（i.e., append only）, will it still be much slower than memory access, thus become the performance bottleneck for the writes？</p>
<p>If I understand it correctly, Cassandra supports the mechanism to store the Write Ahead Log in OS cache, and then flush it to disk every pre-configured amount of time(say 10 seconds). However, does it mean the data changes made within this 10 seconds could be all lost if the machine crashes?</p>
",<cassandra>,"<p>You can control if the sync of commit log using the <a href=""https://cassandra.apache.org/doc/latest/configuration/cass_yaml_file.html#commitlog-sync"" rel=""nofollow noreferrer"">commitlog-sync</a> configuration.  By default it's <code>periodic</code>, and synced to disk every 10 seconds (controlled by <code>commitlog_sync_period_in_ms</code> setting).</p>
<p>And yes, if you lose the power there is a risk that data in the commit log is lost.  But Cassandra relies on the fact that you have multiple replicas, and if you did setup correctly, each replica should be in separate rack (at least, better if you have additional data centers) with separate power, etc.</p>
",['rack']
67614729,67619564,2021-05-20 05:59:08,How cassandra handles new node ( how tokens are redistributed)?,"<p>I recently started exploring Cassandra for a new project. Here is my understanding of Cassandra as of now (based on numerous blogs available online)</p>
<ol>
<li>Cassandra (C*) is AP (CAP theorem), i.e. it is highly available and partition tolerant</li>
<li>C* is logically ring topology. Not in real networking sense (as all nodes can speak to each other) but in data replication sense (data is replicated to neighboring nodes)</li>
<li>C* uses <em>Murmur3</em> Partition algorithm to map out Partition keys to integer range ( roughly -2^63 to 2^63)</li>
<li>Every node is responsible for a few ranges (Vnodes enabled), i.e.
node1: [<em>-2^63</em> to <em>-2^61</em>],  [<em>2^31</em>  to <em>2^33</em>] ....
node2: [<em>-2^61</em> <em>- 1</em> to <em>2^59</em>], [<em>2^33 + 1</em> to <em>2^35</em>]....</li>
</ol>
<p>Now my questions are, suppose I create a cluster with 3 nodes and RF = 2, then</p>
<ol>
<li>In this case whole token range (I believe I am using the right terminology here) -2^63 to 2^63 will be distributed evenly in these 3 nodes?</li>
<li>What happens if I add another node in this running cluster? My assumption is that, C* will rebalance the ring because it uses consistent hashing and thus the range -2^63 to 2^63 will be re-distributed and corresponding data will be copied to new node. (Copied data from existing node won't be deleted till a repair happens?)</li>
<li>What happens when a node goes down? Does C* rebalanced the ring by re-distributing the tokens and moving data around?</li>
<li>Are tokens a fancy word for Murmur3hash(partition Key)? And what exactly it means by partition range? Is it like partition range1= <em>-2^63</em> to <em>-2^61</em>, partition range2 = <em>-2^61 + 1</em> to <em>-2^59</em> and so on.</li>
<li>What information is actually shared during gossip?</li>
</ol>
<p>Sorry if these questions seem very basic but I spent quite some time but could not find definitive answers.</p>
",<cassandra>,"<p>I will try to explain in simple way</p>
<p>Cassandra provides a simple way for configuration, all the configuration is done in cassandra.yaml. You can also go through <a href=""https://stackoverflow.com/questions/41587806/cassandra-sharding-and-replication/41590463#41590463"">THIS</a> to get a some picture of the partitioning in cluster.</p>
<p>Let's start with the basics, instead of using three nodes let's use only one node for now.
With the default configuration of cassandra we get below values in cassandra.yaml file</p>
<pre><code>num_tokens: 1
initial_token: 0
</code></pre>
<p>This means only one node and all the partitions will reside on this one node.
Now, the concept of virtual node is, in simple terms cassandra divides the tokens into multiple ranges, even though there are no physical nodes. Now, how to enable the virtual nodes feature in configuration file cassandra.yaml. The answer is num_token value.</p>
<pre><code>num_tokens: 128
#initial_token: 0
</code></pre>
<p>This configuration makes 128 token ranges, for example 0-10, 11-20, 20-30 and so on. Keep the value of initial_token commented, this means we want cassandra to decide value of initial token (One less thing to worry about).</p>
<p>Now lets add another node in to cluster. Below is the simple configuration of new node. Consider the first node IP as 127.0.0.1 and second node IP as 127.0.0.2 for simplicity.</p>
<pre><code>num_tokens: 128
#initial_token: 0
seed_provider:
- class_name: org.apache.cassandra.locator.SimpleSeedProvider
  parameters:
      - seeds: &quot;127.0.0.1, 127.0.0.2&quot;
</code></pre>
<p>We have just added a new node to our cluster, node1 will serve as seed node. The num_token value is 128, that means 128 token ranges. The value of initial_token is commented, that means cassandra will decide the initial token and range. Data transfer will start as soon as the new node joins cluster.</p>
<p>For third node, configuration shall be as below -</p>
<pre><code>num_tokens: 128
#initial_token: 0
seed_provider:
- class_name: org.apache.cassandra.locator.SimpleSeedProvider
  parameters:
      - seeds: &quot;127.0.0.1, 127.0.0.2, 127.0.0.3&quot;
</code></pre>
<p>So third node will share the few token ranges from node1 and few token ranges from node2.</p>
<p>I hope, we got answers of question 1 and question 2 till now. Let's move to our next tow questions.</p>
<p>When a node goes down, hinted-handoff helps Cassandra maintain consistency . Any one out of remaining 2 nodes keeps the hints of the data which supposed to be written on the node which is down. Once the node goes up, these hints will be replayed and data will be written on target node. There is no need to do repartitioning or  rebalancing kind of fancy things. Hints are stored in a directory which can be configured in cassandra.yaml file. By default 3 hours of hints will be stored, that means a defected node should come up within 3 hours. This value is also configurable in cassandra.yaml file.</p>
<pre><code>hinted_handoff_enabled: true
max_hint_window_in_ms: 10800000 # 3 hours
hints_directory: /home/ubuntu/node1/data/hints
</code></pre>
<p>Murmur3Partitioner calculates the hash by using partition key columns, let's make our peace with that. There are other practitioners as well like RandomPartitioner and ByteOrderedPartitioner.</p>
<p>Below is the sample output of gossip info -
You can go through each field in below protocol data</p>
<pre><code>        ubuntu@ds201-node1:~$ ./node1/bin/nodetool gossipinfo
    /127.0.0.1
      generation:1621506507  -- the tiem at this node is boot strapped.
      heartbeat:2323
      STATUS:28:NORMAL,-1316314773810616606 -----status of the node , NORMAL,LEFT,LEAVING,REMOVED,REMOVING.....
      LOAD:2295:110299.0                    -- Disk space usage
      SCHEMA:64:c5c6bdbd-5916-347a-ab5b-21813ab9d135  -- Changes if schema changes
      DC:37:Cassandra                       --- data center of the NODE
      RACK:18:rack1                         --- Rack of the within the datacenter 
      RELEASE_VERSION:4:4.0.0.2284
      NATIVE_TRANSPORT_ADDRESS:3:127.0.0.1
      X_11_PADDING:2307:{&quot;dse_version&quot;:&quot;6.0.0&quot;,&quot;workloads&quot;:&quot;Cassandra&quot;,&quot;workload&quot;:&quot;Cassandra&quot;,&quot;active&quot;:&quot;true&quot;,&quot;server_id&quot;:&quot;08-00-27-32-1E-DD&quot;,&quot;graph&quot;:false,&quot;health&quot;:0.3}
      NET_VERSION:1:256
      HOST_ID:2:ebd0627a-2491-40d8-ba37-e82a31a95688
      NATIVE_TRANSPORT_READY:66:true
      NATIVE_TRANSPORT_PORT:6:9041
      NATIVE_TRANSPORT_PORT_SSL:7:9041
      STORAGE_PORT:8:7000
      STORAGE_PORT_SSL:9:7001
      JMX_PORT:10:7199
      TOKENS:27:&lt;hidden&gt;
</code></pre>
<p>Gossip is the broadcast protocol spread data across the cluster. No one is a master in cassandra cluster, peers spread data among themselves which helps them to maintain latest information. Nodes communicates with each other randomly using gossip protocol (there is some criteria in this randomness).  Gossip spreads node metadata only and not the client data.</p>
<p>Hope this clears some doubts.</p>
",['initial_token']
68536805,68537872,2021-07-26 22:04:28,What are the differences between wide partition and data skew in Cassandra?,"<p>As I understood both are telling data amount in a specific partition should not be more than other partitions. So we should choose proper partition key(s) to compensate for these problems. But really what are the differences between these two idioms?</p>
",<database><cassandra><nosql>,"<p>While they can occur for the same reasons (Data Model and Partition Key Cardinality), the data imbalance between nodes can occur for others reasons.</p>
<p>If a partition key is not selective enough, there can be situations where the amount of data partition grows, with a maximum recommended amount of 100 Mb per partition, but ideally not more than even 10 Mb.</p>
<p>While having a low cardinality partition key can result in some skew, you can also get a skew in the allocation of the tokens to the ring. The RandomPartitioner has more of a habit of producing an unbalanced result compared to the MurmurPartitioner - but even Murmur can be improved by using the allocate_tokens_for_keyspace / allocate_tokens_for_local_replication_factor - the same setting has different names depending on the C* or DSE version being used, but the idea is to provide the partitioner with more information relating to the intended replication factor, so it produces more of a balanced allocation.</p>
<p>A further way in which data can be unbalanced is from the topology choices - if you create a cluster with keyspaces using NetworkTopologyStrategy (recommended that you should), and multiple racks - unless the number of nodes per rack is the same, then the data will not be balanced.
For example (to demonstrate the result, not that you would do this.)</p>
<ul>
<li>Rack 1 = 5 nodes</li>
<li>Rack 2 = 5 nodes</li>
<li>Rack 3 = 2 nodes.</li>
</ul>
<p>With an RF of 3 and 100 GB of Data, each rack will hold a replica. Nodes in rack 1 and 2 will roughly be 20Gb each, rack 3 will be 50Gb each (roughly).</p>
<p>This is why the normal advice when using racks is you will increase the node count by 3 per DC as it expands.</p>
","['partitioner', 'allocate_tokens_for_local_replication_factor', 'rack', 'allocate_tokens_for_keyspace']"
68824710,68833675,2021-08-17 22:29:42,Configuring cassandra-rackdc and cassandra-topology,"<p>I am configuring 6 nodes Cassandra cluster on AWS EC2,3 nodes in region and 3nodes in other region:</p>
<p>eu-central-1</p>
<ul>
<li>node0   cass-db-0   10.10.37.79   eu-central-1a</li>
<li>node1   cass-db-1   10.10.38.229  eu-central-1b</li>
<li>node2   cass-db-2   10.10.36.76   eu-central-1a</li>
</ul>
<p>eu-west-1</p>
<ul>
<li>node3   cass-db-0   10.10.37.80   eu-west-1a</li>
<li>node4   cass-db-1   10.10.39.177  eu-west-1b</li>
<li>node5   cass-db-2   10.10.37.231  eu-west-1a</li>
</ul>
<p>I have completed the local configuration in cassandra.yaml.</p>
<p>Now I need to configure cassandra-rackdc.properties &amp; cassandra-topology.properties but I don't understand the network topology.</p>
<p>Please Advise.</p>
<p>Thanks</p>
",<cassandra>,"<p>Erick provides some great background here, which should be helpful for you.  In terms of getting to a simple solution, I'd recommend this:</p>
<ul>
<li>Make sure you're using the <code>GossipingPropertyFileSnitch</code> in the <code>cassandra.yaml</code>.</li>
<li>Delete <code>cassandra-topology.properties</code>.</li>
<li>Edit <code>cassandra-rackdc.properties</code> and set <code>dc=eu-west-1</code> for the 3 the west nodes; likewise <code>dc=eu-central-1</code> for the central nodes.</li>
<li>Leave the rack at the default, as you only have 3 nodes across 2 availability zones (AZs 1a and 1b).</li>
</ul>
<p>If you were using AZs 1a, 1b, and 1c I'd say to use that for the <code>rack</code> property.  Erick mentions defining your keyspaces with a RF of 3, which is solid advice.  Typically, you'll want the number of AZs to match your RF for even data distribution and availability, which is why I'd recommend leaving <code>rack</code> at the default value for all.</p>
<p>Likewise, your keyspace definitions would look something like this:</p>
<pre><code>CREATE KEYSPACE keyspace_name WITH REPLICATION = 
    {'class':'NetworkTopologyStrategy',
     'eu-west-1':'3',
     'eu-central-1':'3'};
</code></pre>
<p>The main point to consider, is that your data center names <em>must</em> match between the keyspace definition and the entries in the <code>cassandra-rackdc.properties</code> files.</p>
",['rack']
68839795,71971999,2021-08-18 21:57:57,Error to write dataframe in Cassandra table on Amazon Keyspaces,"<p>I'm trying to write a dataframe on AWS (Keyspace), but I'm getting the following messages below:</p>
<p>Stack:</p>
<pre><code>dfExploded.write.cassandraFormat(table = &quot;table&quot;, keyspace = &quot;hub&quot;).mode(SaveMode.Append).save()
21/08/18 21:45:18 WARN DefaultTokenFactoryRegistry: [s0] Unsupported partitioner 'com.amazonaws.cassandra.DefaultPartitioner', token map will be empty.
java.lang.AssertionError: assertion failed: There are no contact points in the given set of hosts
  at scala.Predef$.assert(Predef.scala:223)
  at com.datastax.spark.connector.cql.LocalNodeFirstLoadBalancingPolicy$.determineDataCenter(LocalNodeFirstLoadBalancingPolicy.scala:195)
  at com.datastax.spark.connector.cql.CassandraConnector$.$anonfun$dataCenterNodes$1(CassandraConnector.scala:192)
  at scala.Option.getOrElse(Option.scala:189)
  at com.datastax.spark.connector.cql.CassandraConnector$.dataCenterNodes(CassandraConnector.scala:192)
  at com.datastax.spark.connector.cql.CassandraConnector$.alternativeConnectionConfigs(CassandraConnector.scala:207)
  at com.datastax.spark.connector.cql.CassandraConnector$.$anonfun$sessionCache$3(CassandraConnector.scala:169)
  at com.datastax.spark.connector.cql.RefCountedCache.createNewValueAndKeys(RefCountedCache.scala:34)
  at com.datastax.spark.connector.cql.RefCountedCache.syncAcquire(RefCountedCache.scala:69)
  at com.datastax.spark.connector.cql.RefCountedCache.acquire(RefCountedCache.scala:57)
  at com.datastax.spark.connector.cql.CassandraConnector.openSession(CassandraConnector.scala:89)
  at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)
  at com.datastax.spark.connector.datasource.CassandraCatalog$.com$datastax$spark$connector$datasource$CassandraCatalog$$getMetadata(CassandraCatalog.scala:455)
  at com.datastax.spark.connector.datasource.CassandraCatalog$.getTableMetaData(CassandraCatalog.scala:421)
  at org.apache.spark.sql.cassandra.DefaultSource.getTable(DefaultSource.scala:68)
  at org.apache.spark.sql.cassandra.DefaultSource.inferSchema(DefaultSource.scala:72)
  at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Utils$.getTableFromProvider(DataSourceV2Utils.scala:81)
  at org.apache.spark.sql.DataFrameWriter.getTable$1(DataFrameWriter.scala:339)
  at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)
  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:301)
</code></pre>
<p>SparkSubmit:</p>
<pre><code>spark-submit --deploy-mode cluster --master yarn  \
--conf=spark.cassandra.connection.port=&quot;9142&quot; \
--conf=spark.cassandra.connection.host=&quot;cassandra.sa-east-1.amazonaws.com&quot; \
--conf=spark.cassandra.auth.username=&quot;BUU&quot; \
--conf=spark.cassandra.auth.password=&quot;123456789&quot; \
--conf=spark.cassandra.connection.ssl.enabled=&quot;true&quot; \
--conf=spark.cassandra.connection.ssl.trustStore.path=&quot;cassandra_truststore.jks&quot;
--conf=spark.cassandra.connection.ssl.trustStore.password=&quot;123456&quot;
</code></pre>
<p>Connection by cqlsh everything ok, but in spark got this error</p>
",<scala><apache-spark><cassandra><spark-cassandra-connector>,"<p>To read and write data between Keyspaces and Apache Spark by using the open-source Spark Cassandra Connector all you have to do is update the partitioner for your Keyspaces account.</p>
<p>Docs: <a href=""https://docs.aws.amazon.com/keyspaces/latest/devguide/spark-integrating.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/keyspaces/latest/devguide/spark-integrating.html</a></p>
",['partitioner']
68979039,68979265,2021-08-30 04:47:19,Elassandra replication information and rack configuration,"<p>I recently started working with an Elassandra cluster with two data centers which have been configured using NetworkTopologyStrategy.</p>
<p>Cluster details : <code>Elassandra 6.2.3.15 = Elasticsearch 6.2.3 + Cassandra 3.11.4</code></p>
<pre><code>Datacenter: DC1
=================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address       Load       Tokens       Owns    Host ID                               Rack
UN  &lt;ip1&gt;         50 GiB  256          ?       6cab1f4c-8937-437d-b010-0a5677443dc3  rack1
UN  &lt;ip2&gt;         48 GiB  256          ?       6c9e7ad5-a642-4c0d-8b77-e78d821d904b  rack1
UN  &lt;ip3&gt;         50 GiB  256          ?       7e493bc6-c8a5-471e-8eee-3f3fe985b90a  rack1
Datacenter: DC2
===============
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address       Load       Tokens       Owns    Host ID                               Rack
UN  &lt;ip4&gt;         47 GiB  256          ?       c49c1203-cc38-41a2-b9c8-2b42bc907c17  rack1
UN  &lt;ip5&gt;         67 GiB  256          ?       0d9f31bc-9690-49b6-9d88-4fb30c1b6c0d  rack1
UN  &lt;ip6&gt;         88 GiB  256          ?       80c4d60d-185f-457a-ae9b-2eb611735f07  rack1
</code></pre>
<p>schema info <br>
<code>CREATE KEYSPACE my_keyspace WITH replication = {'class': 'NetworkTopologyStrategy', 'DC1': '3', 'DC2': '3'}  AND durable_writes = true;</code></p>
<p>The <code>DC2</code> is kind of a Disaster Recovery site and in an ideal world, we should be able to use only that in case of a disaster.</p>
<ol>
<li>With the very limited knowledge I have, I strongly suspect that we need
to modify the rack configuration to have a 'proper' D/R cluster (So
that data in DC1 gets replicated in DC2) or am I getting this
wrong? If so, is there a standard guideline to follow?</li>
<li>When there are multiple DCs, does Cassandra automatically replicate this regardless of rack configurations? (Are racks kind of additional fail proof?)</li>
<li>DC2 has more data than DC1. Is this purely related to hash function?</li>
<li>Is there any other things that can be rectified in this cluster?</li>
</ol>
<p>Many thanks!</p>
",<cassandra><cassandra-3.0><elassandra>,"<p>These replication settings mean that the data for your keyspace is replicated in real time between the 2 DCs with each DC having 3 replicas (copies):</p>
<pre><code>CREATE KEYSPACE my_keyspace WITH replication = {
  'class': 'NetworkTopologyStrategy',
  'DC1': '3',
  'DC2': '3'
}
</code></pre>
<p>Replication in Cassandra happens in real time -- any writes sent to one DC is sent to all other DCs at the same time. Unlike traditional RDBMS or configurations with primary/secondary or active/DR, Cassandra replication is instantaneous and immediate.</p>
<p>The logical Cassandra racks are for additional redundancy mechanism. If you have C* nodes deployed in different (a) physical racks, or (b) public cloud availability zones, Cassandra will distribute the replicas to separate racks so each rack has a full copy of the data. With a replication factor of 3 in the DC, if a rack goes down for whatever reason then there's still full copies of the data in the remaining 2 racks and read/write requests with a consistency of <code>LOCAL_QUORUM</code> (or lower) will not be affected.</p>
<p>I've explained this in a bit more detail in this post -- <a href=""https://community.datastax.com/questions/1128/"" rel=""nofollow noreferrer"">https://community.datastax.com/questions/1128/</a>.</p>
<p>If you're new to Cassandra, we recommend <a href=""https://www.datastax.com/dev"" rel=""nofollow noreferrer"">https://www.datastax.com/dev</a> which has links to short hands-on tutorials where you can quickly learn the basics of Cassandra -- all free. This tutorial is a good place to start -- <a href=""https://www.datastax.com/try-it-out"" rel=""nofollow noreferrer"">https://www.datastax.com/try-it-out</a>. Cheers!</p>
",['rack']
71276247,71306851,2022-02-26 11:27:54,How does peer to peer architecture work in Cassandra?,"<p>How the peer-to-peer Cassandra architecture really works ? I mean :</p>
<p>When the request hits the Cluster, it must hit some machine based on an IP, right ?</p>
<p>So which machine it will hit first ? : one of the nodes, or something in the Cluster who is responsible to balance and redirect the request to the right node ?</p>
<p>Could you describe what it is ? And how this differ from the Master/Folowers architecture ?</p>
",<cassandra>,"<p>For the purposes of my answer, I will use <a href=""https://docs.datastax.com/en/developer/java-driver/latest/"" rel=""nofollow noreferrer"">the Java driver</a> as an example since it is the most popular.</p>
<p>When you connect to a cluster using one of the driver, you need to configure it with details of your cluster including:</p>
<ol>
<li><strong>Contact points</strong> - the entry point to your cluster which is a comma-separated list of IPs/hostnames for some of the nodes in your cluster.</li>
<li>Login credentials - username and password if authentication is enabled on your cluster.</li>
<li>SSL/TLS certificate and credentials - if encryption is enabled on your cluster.</li>
</ol>
<p>When your application starts, <a href=""https://docs.datastax.com/en/developer/java-driver/latest/manual/core/control_connection/"" rel=""nofollow noreferrer"">a <strong>control connection</strong> is established with the first available node</a> in the list of <strong>contact points</strong>. The driver uses this control connection for admin tasks such as:</p>
<ul>
<li>get topology information about the cluster including node IPs, rack placement, network/DC information, etc</li>
<li>get schema information such as keyspaces and tables</li>
<li>subscribe to metadata changes including topology and schema updates</li>
</ul>
<p>When you configure the driver with a <a href=""https://docs.datastax.com/en/developer/java-driver/latest/manual/core/load_balancing/"" rel=""nofollow noreferrer"">load-balancing policy</a> (LBP), the policy will determine which node the driver will pick as the coordinator for each and every single query. By default, the Java driver uses a load balancing policy which picks nodes in the local datacenter. If you don't specify which DC is local to the app, the driver will set the local DC to the DC of the first contact point.</p>
<p>Each time a driver executes a query, it generates a <strong>query plan</strong> or a list of nodes to contact. This list of nodes has the following characteristics:</p>
<ul>
<li>A query plan is different for each query to balance the load across nodes in the cluster.</li>
<li>A query plan only lists available nodes and does not include nodes which are down or temporarily unavailable.</li>
<li>Nodes in the local DC are listed first and if the load-balancing policy allows it, remote nodes are included last.</li>
</ul>
<p>The driver tries to contact each node in the query plan in the order they are listed. If the first node is available then the driver uses it as the coordinator. If the first node does not respond (for whatever reason), the driver tries the next node in the query plan and so on.</p>
<p>Finally, all nodes are equal in Cassandra. There is no active-passive, no leader-follower, no primary-secondary and this makes Cassandra a truly high availability (HA) cluster with no single point-of-failure. Any node can do the work of any other node and the load is distributed equally to all nodes by design.</p>
<p>If you're new to Cassandra, I recommend having a look at <a href=""https://www.datastax.com/dev"" rel=""nofollow noreferrer"">datastax.com/dev</a> which has lots of free hands-on interactive learning resources. In particular, the <a href=""https://www.datastax.com/learn/cassandra-fundamentals"" rel=""nofollow noreferrer"">Cassandra Fundamentals</a> learning series lets you learn the basic concepts quickly.</p>
<p>For what it's worth, you can also use the <a href=""https://stargate.io/"" rel=""nofollow noreferrer"">Stargate.io</a> data platform. It allows you to connect to a Cassandra cluster using APIs you're already familiar with. It is fully open-source so it's free to use. Here are links to the Stargate tutorials on datastax.com/dev: <a href=""https://www.datastax.com/dev/rest"" rel=""nofollow noreferrer"">REST API</a>, <a href=""https://www.datastax.com/dev/documents-api"" rel=""nofollow noreferrer"">Document API</a>, <a href=""https://www.datastax.com/dev/graphql"" rel=""nofollow noreferrer"">GraphQL API</a>, and more recently <a href=""https://www.datastax.com/blog/available-now-grpc-apache-cassandra"" rel=""nofollow noreferrer"">gRPC API</a>. Cheers!</p>
",['rack']
71366492,71366792,2022-03-05 22:46:50,How does partition range repair work in Cassandra?,"<ol>
<li>Will partition range repair (-pr) repairs only the primary token rages a node is responsible for or also the non-primary tokens a node is holding data?</li>
<li>If only primary tokens, then is it mandatory to run partition range repair on all nodes so that non-primary tokens also get repaired?</li>
<li>How do I find non-primary tokens a node is responsible for? The token ranges returned by nodetool ring, does it only show primary token ranges or both primary and non-primary token ranges a node is responsible for?</li>
</ol>
",<cassandra>,"<p>The partitioner range repair (<code>--partitioner-range</code> or <code>-pr</code>)only repair token ranges on a node where the node is the primary replica meaning it is the primary owner of the tokens (see <a href=""https://docs.datastax.com/en/cassandra-oss/3.x/cassandra/operations/opsRepairNodesManualRepair.html#ParallelvsSequentialrepair"" rel=""nofollow noreferrer"">Manual repair in Cassandra</a>).</p>
<p>Since this repair option only repairs the primary range(s) on a node, it needs to be run on all nodes in all DCs otherwise not all token ranges will get repaired.</p>
<p>You can find the token range ownership with <code>nodetool ring</code>. It doesn't list token ranges where the node is a secondary replica.</p>
<p>Partitioner range repairs (also referred to as &quot;primary range repairs&quot;) are designed to be really efficient since it doesn't repair ranges which have already been repaired on other nodes.</p>
<p>Jeremiah Jordan explains this in great detail in his blog post <a href=""https://www.datastax.com/blog/repair-cassandra"" rel=""nofollow noreferrer"">Apache Cassandra Maintenance and Repair</a>.</p>
<p>Patrick McFadin also explains <a href=""https://www.youtube.com/watch?v=5V5rGDTHs20&amp;list=PL2g2h-wyI4SrHMlHBJVe_or_Ryek2THgQ&amp;index=18"" rel=""nofollow noreferrer"">how repairs work and the different types of repairs in this video</a> extracted from the DS210 Cassandra Operations course at <a href=""https://academy.datastax.com/"" rel=""nofollow noreferrer"">DataStax Academy</a>. Cheers!</p>
",['partitioner']
72735204,72767435,2022-06-23 18:46:56,How do I find out right data design and right tools/database/query for below requirement,"<p>I have a kind of requirement but not able to figure out how can I solve it. I have datasets in below format</p>
<pre><code>id, atime, grade
123, time1, A
241, time2, B
123, time3, C
</code></pre>
<p>or if I put in list format:</p>
<pre><code>[[123,time1,A],[124,timeb,C],[123,timec,C],[143,timed,D],[423,timee,P].......]
</code></pre>
<p>Now my use-case is to perform comparison, aggregation and queries over multiple row like</p>
<ol>
<li>time difference between last 2 rows where id=123</li>
<li>time difference between last 2 rows where id=123&amp;GradeA</li>
<li>Time difference between first, 3rd, 5th and latest one</li>
<li>all data (or last 10 records for particular id) should be easily accessible.</li>
</ol>
<p>Also need to further do compute. <strong>What format should I chose for dataset
and what database/tools should I use?</strong>
I don't Relational Database is useful here. I am not able to solve it with Solr/Elastic if you have any ideas, please give a brief.Or any other tool Spark, hadoop, cassandra any heads?
I am trying out things but any help is appreciated.</p>
",<apache-spark><elasticsearch><cassandra><nosql><bigdata>,"<p>Choosing the right technology is highly dependent on things related to your SLA. things like how much can your query have latency? what are your query types? is your data categorized as big data or not? Is data updateable? Do we expect late events? Do we need historical data in the future or we can use techniques like rollup? and things like that. To clarify my answer, probably by using window functions you can solve your problems. For example, you can store your data on any of the tools you mentioned and by using the Presto SQL engine you can query and get your desired result. But not all of them are optimal. Furthermore, usually, these kinds of problems can not be solved with a single tool. A set of tools can cover all requirements.</p>
<p><strong>tl;dr. In the below text we don't find a solution. It introduces a way to think about data modeling and choosing tools.</strong></p>
<p>Let me take try to model the problem to choose a single tool. I assume your data is not updatable, you need a low latency response time, we don't expect any late event and we face a large volume data stream that must be saved as raw data.</p>
<ul>
<li>Based on the first and second requirements, it's crucial to have random access (it seems you wanna query on a particular ID), so solutions like parquet or ORC files are not a good choice.</li>
<li>Based on the last requirement, data must be partitioned based on the ID. Both the first and second requirements and the last requirement, count on ID as an identifier part and it seems there is nothing like join and global ordering based on other fields like time. So we can choose ID as the partitioner (physical or logical) and <code>atime</code> as the cluster part; For each ID, events are ordered based on the time.</li>
<li>The third requirement is a bit vague. You wanna result on all data? or for each ID?</li>
<li>For computing the first three conditions, we need a tool that supports window functions.</li>
</ul>
<p>Based on the mentioned notes, it seems we should choose a tool that has good support for random access queries. Tools like Cassandra, Postgres, Druid, MongoDB, and ElasticSearch are things that currently I can remember them. Let's check them:</p>
<ul>
<li>Cassandra: It's great on response time on random access queries, can handle a huge amount of data easily, and does not have a single point of failure. But sadly it does not support window functions. Also, you should carefully design your data model and it seems it's not a good tool that we can choose (because of future need for raw data). We can bypass some of these limitations by using Spark alongside Cassandra, but for now, we prefer to avoid adding a new tool to our stack.</li>
<li>Postgres: It's great on random access queries and indexed columns. It supports window functions. We can shard data (horizontal partitioning) across multiple servers (and by choosing ID as the shard key, we can have data locality on computations). But there is a problem: ID is not unique; so we can not choose ID as the primary key and we face some problems with random access (We can choose the ID and <code>atime</code> columns (as a timestamp column) as a compound primary key, but it does not save us).</li>
<li>Druid: It's a great OLAP tool. Based on the storing manner (segment files) that Druid follows, by choosing the right data model, you can have analytic queries on a huge volume of data in sub-seconds. It does not support window functions, but with rollup and some other functions (like <code>EARLIEST</code>), we can answer our questions. But by using rollup, we lose raw data and we need them.</li>
<li>MongoDB: It supports random access queries and sharding. Also, we can have some type of window function on its computing framework and we can define some sort of pipelines for doing aggregations. It supports capped collections and we can use it to store the last 10 events for each ID if the cardinality of the ID column is not high. It seems this tool can cover all of our requirements.</li>
<li>ElasticSearch: It's great on random access, maybe the greatest. With some kind of filter aggregations, we can have a type of window function. It can handle a large amount of data with sharding. But its query language is hard. I can imagine we can answer the first and second questions with ES, but for now, I can't make a query in my mind. It takes time to find the right solution with it.</li>
</ul>
<p>So it seems MongoDB and ElasticSearch can answer our requirements, but there is a lot of 'if's on the way. I think we can't find a straightforward solution with a single tool. Maybe we should choose multiple tools and use techniques like duplicating data to find an optimal solution.</p>
",['partitioner']
